{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 합성곱 / 풀링 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.rand(10, 1, 28, 28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26531844, 0.38557199, 0.64528512, 0.35010988, 0.08953701,\n",
       "       0.91861974, 0.7912761 , 0.32583924, 0.63700976, 0.79488025,\n",
       "       0.99745216, 0.60916384, 0.67278501, 0.11149363, 0.94425923,\n",
       "       0.40101133, 0.71768789, 0.880261  , 0.8566326 , 0.88553516,\n",
       "       0.12730108, 0.14647156, 0.2292819 , 0.04694512, 0.75392043,\n",
       "       0.66370834, 0.69684539, 0.54506793])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### im2col = image to column<br>\n",
    "3차원 입력 데이터를 2차원 행렬로 바꿈 !! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2col(input_data, filter_h, filter_w, stride = 1, pad = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "# 배치크기 1, 채널3, 7x7\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = im2col(x1, 5, 5, stride = 1, pad = 0)\n",
    "print(col1.shape) \n",
    "\n",
    "# 배치크기10, 채널3, 7x7\n",
    "x2 = np.random.rand(10, 3, 7, 7)\n",
    "col2 = im2col(x2, 5, 5, stride = 1, pad = 0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱\n",
    "class Convolution:\n",
    "    def __init__(self, W, b, stride = 1, pad = 0):\n",
    "        self.W = W # 필터 (FN, C, FH, FW) 형상\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, F, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T # 필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # 역전파는 col2im 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀링\n",
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride = 1, pad = 0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 데이터 전개\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "        # 최댓값\n",
    "        out = np.max(col, axis = 1)\n",
    "        # 모양 성형\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 CNN 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.298929662865998\n",
      "=== epoch:1, train acc:0.274, test acc:0.316 ===\n",
      "train loss:2.295121370790783\n",
      "train loss:2.291401381697643\n",
      "train loss:2.2868007213114714\n",
      "train loss:2.2822027695485345\n",
      "train loss:2.261545995465575\n",
      "train loss:2.2520884134867836\n",
      "train loss:2.2256575516829655\n",
      "train loss:2.216998910169053\n",
      "train loss:2.1825309333063654\n",
      "train loss:2.153034396953735\n",
      "train loss:2.1283713584589923\n",
      "train loss:2.105437667036912\n",
      "train loss:2.0504922671492265\n",
      "train loss:2.006589071787045\n",
      "train loss:1.9028971763191087\n",
      "train loss:1.8871957233965\n",
      "train loss:1.8162374663088219\n",
      "train loss:1.7122845811020784\n",
      "train loss:1.6651967470998252\n",
      "train loss:1.5820743124802257\n",
      "train loss:1.517555948515778\n",
      "train loss:1.4666514454991437\n",
      "train loss:1.5007505451777183\n",
      "train loss:1.3634180519550538\n",
      "train loss:1.1223625985410843\n",
      "train loss:1.066700073407979\n",
      "train loss:1.0158520691345247\n",
      "train loss:1.1076793685082738\n",
      "train loss:0.9515976301218775\n",
      "train loss:0.8028101082601902\n",
      "train loss:0.850044201729865\n",
      "train loss:0.8362219792376583\n",
      "train loss:0.7457191115293762\n",
      "train loss:0.7310760402178047\n",
      "train loss:0.7448935005319036\n",
      "train loss:0.6099218023258876\n",
      "train loss:0.7176490337367177\n",
      "train loss:0.6375343402573943\n",
      "train loss:0.6501698610005187\n",
      "train loss:0.5706792179386341\n",
      "train loss:0.5903000168851131\n",
      "train loss:0.4624764646333584\n",
      "train loss:0.5469312676260784\n",
      "train loss:0.6988695593361629\n",
      "train loss:0.36121699449275135\n",
      "train loss:0.7384776738249258\n",
      "train loss:0.6658064193964727\n",
      "train loss:0.6800400272048002\n",
      "train loss:0.6596067188934828\n",
      "train loss:0.565844279737231\n",
      "train loss:0.47623575832369514\n",
      "train loss:0.5071285713927172\n",
      "train loss:0.5998117411040947\n",
      "train loss:0.3869788444656792\n",
      "train loss:0.608894976424523\n",
      "train loss:0.5355933287605661\n",
      "train loss:0.6784362802498006\n",
      "train loss:0.3776307281300247\n",
      "train loss:0.624009009204271\n",
      "train loss:0.4008145321890085\n",
      "train loss:0.6195509831178577\n",
      "train loss:0.34083300369292197\n",
      "train loss:0.39449414739534494\n",
      "train loss:0.46896371235046486\n",
      "train loss:0.4622144571728203\n",
      "train loss:0.42796619759723614\n",
      "train loss:0.47922139353176524\n",
      "train loss:0.4614867704072735\n",
      "train loss:0.31277767040271004\n",
      "train loss:0.3346564903784806\n",
      "train loss:0.49576957809676536\n",
      "train loss:0.3708667375737615\n",
      "train loss:0.4817066820030111\n",
      "train loss:0.5057962193051703\n",
      "train loss:0.43968586819939076\n",
      "train loss:0.42666809714415754\n",
      "train loss:0.5099595510085347\n",
      "train loss:0.4116565426242205\n",
      "train loss:0.3019307741596071\n",
      "train loss:0.3144215895467075\n",
      "train loss:0.5229583483031635\n",
      "train loss:0.7196484045416718\n",
      "train loss:0.39886419836928577\n",
      "train loss:0.3782859136435149\n",
      "train loss:0.3268704734609291\n",
      "train loss:0.43355781295372814\n",
      "train loss:0.5439390387116569\n",
      "train loss:0.4216410357144252\n",
      "train loss:0.4586836449342146\n",
      "train loss:0.32175526922540665\n",
      "train loss:0.36049750932431934\n",
      "train loss:0.49458468385225246\n",
      "train loss:0.4515075386384326\n",
      "train loss:0.368398820899389\n",
      "train loss:0.4344793940879546\n",
      "train loss:0.388784234043003\n",
      "train loss:0.29074298581943836\n",
      "train loss:0.5530754436279155\n",
      "train loss:0.4175894505842468\n",
      "train loss:0.4396810415218242\n",
      "train loss:0.4001362419837188\n",
      "train loss:0.4096613869173778\n",
      "train loss:0.4566246236198559\n",
      "train loss:0.24404878308171596\n",
      "train loss:0.3838424713533837\n",
      "train loss:0.44163178867606945\n",
      "train loss:0.33337448476818726\n",
      "train loss:0.4473433711825971\n",
      "train loss:0.4050073207654878\n",
      "train loss:0.3211339508826444\n",
      "train loss:0.30778544884425924\n",
      "train loss:0.41329752788550744\n",
      "train loss:0.32837420551980273\n",
      "train loss:0.38245342557154516\n",
      "train loss:0.24950268726912633\n",
      "train loss:0.20704872445726832\n",
      "train loss:0.42923151967998785\n",
      "train loss:0.42414402075620294\n",
      "train loss:0.47592482011869564\n",
      "train loss:0.28808160994648696\n",
      "train loss:0.2554077063427689\n",
      "train loss:0.27226371613826456\n",
      "train loss:0.4225001630543557\n",
      "train loss:0.26216823427167496\n",
      "train loss:0.40894955597892746\n",
      "train loss:0.526179502872747\n",
      "train loss:0.34001074442813034\n",
      "train loss:0.45449141495151335\n",
      "train loss:0.3305223231186199\n",
      "train loss:0.3213977102227068\n",
      "train loss:0.25020749625372035\n",
      "train loss:0.28406629994343463\n",
      "train loss:0.3177961191903033\n",
      "train loss:0.2576715167442832\n",
      "train loss:0.4297023234052045\n",
      "train loss:0.3934801821661189\n",
      "train loss:0.36591220439572475\n",
      "train loss:0.34568354451360345\n",
      "train loss:0.35288263638938006\n",
      "train loss:0.3180642435639852\n",
      "train loss:0.4416117062580143\n",
      "train loss:0.41127296974222743\n",
      "train loss:0.49932848945604247\n",
      "train loss:0.1993600670651067\n",
      "train loss:0.25297338232110156\n",
      "train loss:0.23007499699117984\n",
      "train loss:0.23833781256922598\n",
      "train loss:0.3582203601568866\n",
      "train loss:0.37646870768896135\n",
      "train loss:0.28889775420431457\n",
      "train loss:0.24996598765486902\n",
      "train loss:0.3154357652791329\n",
      "train loss:0.3549622446105814\n",
      "train loss:0.30989835076694466\n",
      "train loss:0.3074473409545336\n",
      "train loss:0.31165277283366694\n",
      "train loss:0.2946879268933134\n",
      "train loss:0.3915133826454715\n",
      "train loss:0.37853938734056736\n",
      "train loss:0.22337181573605724\n",
      "train loss:0.34171440061958674\n",
      "train loss:0.27241160962622724\n",
      "train loss:0.2746827015720682\n",
      "train loss:0.32490188902888084\n",
      "train loss:0.4650820638055058\n",
      "train loss:0.4119638033750867\n",
      "train loss:0.25985311191776755\n",
      "train loss:0.3462256904694971\n",
      "train loss:0.3761667769775003\n",
      "train loss:0.41412872656617966\n",
      "train loss:0.31272559700725305\n",
      "train loss:0.281463256730088\n",
      "train loss:0.25077940624991085\n",
      "train loss:0.23142524003228168\n",
      "train loss:0.2236978304969113\n",
      "train loss:0.3582738500777423\n",
      "train loss:0.36758203715243043\n",
      "train loss:0.2256782679070167\n",
      "train loss:0.19195374072022214\n",
      "train loss:0.2923028730129975\n",
      "train loss:0.1882215634073451\n",
      "train loss:0.2467800917706467\n",
      "train loss:0.478153321115878\n",
      "train loss:0.49394632525814147\n",
      "train loss:0.2526562125451132\n",
      "train loss:0.25085984536818895\n",
      "train loss:0.3803986469835088\n",
      "train loss:0.4439776932933001\n",
      "train loss:0.2517006832176271\n",
      "train loss:0.2148854918783352\n",
      "train loss:0.22856090338306284\n",
      "train loss:0.17125859766059837\n",
      "train loss:0.2583234544756587\n",
      "train loss:0.3183369367617884\n",
      "train loss:0.23733746696909466\n",
      "train loss:0.2856218789482897\n",
      "train loss:0.25099152761535093\n",
      "train loss:0.33994629274778876\n",
      "train loss:0.1569553677692871\n",
      "train loss:0.31707613745450763\n",
      "train loss:0.35606739882196015\n",
      "train loss:0.26424334396395116\n",
      "train loss:0.23700094534874297\n",
      "train loss:0.2278963505918501\n",
      "train loss:0.33169036411671354\n",
      "train loss:0.23082090835629498\n",
      "train loss:0.15556037743312742\n",
      "train loss:0.286493767276635\n",
      "train loss:0.3341310928843852\n",
      "train loss:0.2794285362644071\n",
      "train loss:0.2738056621901214\n",
      "train loss:0.3271874019803206\n",
      "train loss:0.17769310094914487\n",
      "train loss:0.34132390153310604\n",
      "train loss:0.2850352170239554\n",
      "train loss:0.36216971139773413\n",
      "train loss:0.2261525282819774\n",
      "train loss:0.17574297841501318\n",
      "train loss:0.21642732211197405\n",
      "train loss:0.18589847164580925\n",
      "train loss:0.2491373179868321\n",
      "train loss:0.28954236214434576\n",
      "train loss:0.2274366323851262\n",
      "train loss:0.16962709241568097\n",
      "train loss:0.22906950835033313\n",
      "train loss:0.37460834107476726\n",
      "train loss:0.40089409717547186\n",
      "train loss:0.22748218577000034\n",
      "train loss:0.33381737056404687\n",
      "train loss:0.17531474022270604\n",
      "train loss:0.2215385495274286\n",
      "train loss:0.31631426786754313\n",
      "train loss:0.26925392843416485\n",
      "train loss:0.26544079143251315\n",
      "train loss:0.2564557636431271\n",
      "train loss:0.2378384670060171\n",
      "train loss:0.47345092649773557\n",
      "train loss:0.20487122737501495\n",
      "train loss:0.30893075555440647\n",
      "train loss:0.2387149576021827\n",
      "train loss:0.23862282898170087\n",
      "train loss:0.3885702787741704\n",
      "train loss:0.2848267151580699\n",
      "train loss:0.3538445352313544\n",
      "train loss:0.17147324603765568\n",
      "train loss:0.1990715121853586\n",
      "train loss:0.27207894816911277\n",
      "train loss:0.4080123421267121\n",
      "train loss:0.18394139366356807\n",
      "train loss:0.32377861713232325\n",
      "train loss:0.22610591602025823\n",
      "train loss:0.13878363993314\n",
      "train loss:0.18684984046809128\n",
      "train loss:0.3071446679178649\n",
      "train loss:0.26993589980823623\n",
      "train loss:0.17857781550319252\n",
      "train loss:0.33540092101044705\n",
      "train loss:0.31368935010410104\n",
      "train loss:0.3656559662265788\n",
      "train loss:0.3173247440422827\n",
      "train loss:0.3029133993884749\n",
      "train loss:0.18898353722153957\n",
      "train loss:0.21917260332976768\n",
      "train loss:0.3246822992021476\n",
      "train loss:0.16797158362106973\n",
      "train loss:0.21804127810453428\n",
      "train loss:0.2748439327757014\n",
      "train loss:0.2535049104064797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2308510063489152\n",
      "train loss:0.21630373923784635\n",
      "train loss:0.25391313199148435\n",
      "train loss:0.35000851736193744\n",
      "train loss:0.22653684275558159\n",
      "train loss:0.20459236244604054\n",
      "train loss:0.14704647231814008\n",
      "train loss:0.27044662029388783\n",
      "train loss:0.16051515617236686\n",
      "train loss:0.2075682505862477\n",
      "train loss:0.21572120483866086\n",
      "train loss:0.24492815287459652\n",
      "train loss:0.29163124301377125\n",
      "train loss:0.16784499852893053\n",
      "train loss:0.1321140939678239\n",
      "train loss:0.2003203571047989\n",
      "train loss:0.19491567696389198\n",
      "train loss:0.1967445746974165\n",
      "train loss:0.2343266643165766\n",
      "train loss:0.32131113983341786\n",
      "train loss:0.32653016774050725\n",
      "train loss:0.3388108459482172\n",
      "train loss:0.21661229442195967\n",
      "train loss:0.3300437732408524\n",
      "train loss:0.38975197712244786\n",
      "train loss:0.1761578823189599\n",
      "train loss:0.3445416197590275\n",
      "train loss:0.2574334380539344\n",
      "train loss:0.3144249705445293\n",
      "train loss:0.19966761626462923\n",
      "train loss:0.2667650587370862\n",
      "train loss:0.212472631049243\n",
      "train loss:0.16632470218032847\n",
      "train loss:0.15026232375140977\n",
      "train loss:0.12034181420307254\n",
      "train loss:0.2704590243547138\n",
      "train loss:0.1607018964122442\n",
      "train loss:0.19472028681399153\n",
      "train loss:0.13200778759281848\n",
      "train loss:0.2853635112124831\n",
      "train loss:0.16474251294042105\n",
      "train loss:0.21329760029365488\n",
      "train loss:0.17353216915894765\n",
      "train loss:0.17720516122850716\n",
      "train loss:0.2860750235485012\n",
      "train loss:0.31546582212164714\n",
      "train loss:0.21011121300802243\n",
      "train loss:0.2555599974946497\n",
      "train loss:0.14975248087492166\n",
      "train loss:0.32633461041700007\n",
      "train loss:0.15516269057859028\n",
      "train loss:0.15960537583128498\n",
      "train loss:0.3016788429040228\n",
      "train loss:0.20837973548340663\n",
      "train loss:0.19194771778336392\n",
      "train loss:0.273116085206402\n",
      "train loss:0.20190928039331665\n",
      "train loss:0.22015057574409205\n",
      "train loss:0.17284531950204995\n",
      "train loss:0.11949995254517193\n",
      "train loss:0.21755569309564474\n",
      "train loss:0.1295416476909864\n",
      "train loss:0.24560458207248329\n",
      "train loss:0.20033682653418494\n",
      "train loss:0.14496911466029266\n",
      "train loss:0.3349316292221484\n",
      "train loss:0.23139618109527527\n",
      "train loss:0.11627076584590927\n",
      "train loss:0.19188085014673883\n",
      "train loss:0.1722162450147201\n",
      "train loss:0.2234019229174972\n",
      "train loss:0.1841949106261185\n",
      "train loss:0.14473232293615648\n",
      "train loss:0.36237835514887773\n",
      "train loss:0.08562341965258463\n",
      "train loss:0.16642612596955733\n",
      "train loss:0.25079690124277215\n",
      "train loss:0.23716902684276317\n",
      "train loss:0.2811239867584147\n",
      "train loss:0.17819713940021273\n",
      "train loss:0.1975118031720494\n",
      "train loss:0.16957694471456553\n",
      "train loss:0.21279465425746028\n",
      "train loss:0.20305569706930215\n",
      "train loss:0.21114268383889334\n",
      "train loss:0.09029682523154837\n",
      "train loss:0.19957919297221843\n",
      "train loss:0.18887991686301664\n",
      "train loss:0.1209948598494138\n",
      "train loss:0.15893374012369177\n",
      "train loss:0.16001059219042799\n",
      "train loss:0.11316912775526194\n",
      "train loss:0.1397841869961426\n",
      "train loss:0.20543045009621186\n",
      "train loss:0.3290811174902163\n",
      "train loss:0.13787852115962806\n",
      "train loss:0.17146430372888596\n",
      "train loss:0.14163363356056116\n",
      "train loss:0.38177927423600144\n",
      "train loss:0.20823468737793216\n",
      "train loss:0.1493692419960225\n",
      "train loss:0.13003710549917127\n",
      "train loss:0.1548484178098333\n",
      "train loss:0.16439411074011379\n",
      "train loss:0.23269523555581542\n",
      "train loss:0.18585181971778464\n",
      "train loss:0.16220376099717326\n",
      "train loss:0.1355407612646021\n",
      "train loss:0.1857485250081463\n",
      "train loss:0.14222190581348026\n",
      "train loss:0.2437364238096136\n",
      "train loss:0.1197493898972441\n",
      "train loss:0.3443104473122212\n",
      "train loss:0.17217153687381936\n",
      "train loss:0.25857847656310257\n",
      "train loss:0.19895504449865176\n",
      "train loss:0.17986888346394334\n",
      "train loss:0.22771200111302825\n",
      "train loss:0.15727205565801225\n",
      "train loss:0.20485973024484974\n",
      "train loss:0.12663310431454336\n",
      "train loss:0.2967597632245517\n",
      "train loss:0.39972402123667394\n",
      "train loss:0.11135821933901192\n",
      "train loss:0.22007018475533305\n",
      "train loss:0.14991803724372738\n",
      "train loss:0.21800817636263342\n",
      "train loss:0.08503361339261305\n",
      "train loss:0.17089737707829808\n",
      "train loss:0.32076932773099487\n",
      "train loss:0.12998841767958574\n",
      "train loss:0.13624183407483922\n",
      "train loss:0.1566307446966165\n",
      "train loss:0.3082311378107028\n",
      "train loss:0.3822936493884913\n",
      "train loss:0.16645783127286864\n",
      "train loss:0.14554023297610916\n",
      "train loss:0.14947788885678373\n",
      "train loss:0.13696499238784215\n",
      "train loss:0.1198169046952767\n",
      "train loss:0.3047535077749856\n",
      "train loss:0.26295551359044006\n",
      "train loss:0.12273750101933567\n",
      "train loss:0.18695212052862897\n",
      "train loss:0.14126247211082918\n",
      "train loss:0.19151808734558742\n",
      "train loss:0.20892519241070714\n",
      "train loss:0.20899456016078852\n",
      "train loss:0.2240291353165908\n",
      "train loss:0.15839748144085225\n",
      "train loss:0.2121773675517089\n",
      "train loss:0.08962143365463758\n",
      "train loss:0.10967209398481051\n",
      "train loss:0.15587067675168395\n",
      "train loss:0.1262323001145022\n",
      "train loss:0.13645165422293024\n",
      "train loss:0.22718408987478445\n",
      "train loss:0.17517003800414563\n",
      "train loss:0.15398069777835058\n",
      "train loss:0.09949614811462112\n",
      "train loss:0.17964042721456244\n",
      "train loss:0.14430543463778245\n",
      "train loss:0.21386264817142167\n",
      "train loss:0.10348728445728803\n",
      "train loss:0.20990743117253238\n",
      "train loss:0.27318418936883954\n",
      "train loss:0.1308029871991268\n",
      "train loss:0.2050679547237321\n",
      "train loss:0.12419873664704563\n",
      "train loss:0.13202306652308887\n",
      "train loss:0.10566159068056216\n",
      "train loss:0.23743690132177522\n",
      "train loss:0.1656386619726511\n",
      "train loss:0.1254477465426401\n",
      "train loss:0.08266563210061717\n",
      "train loss:0.17830598704777556\n",
      "train loss:0.12691854020497606\n",
      "train loss:0.161892192812974\n",
      "train loss:0.09435259207726457\n",
      "train loss:0.1324057836811015\n",
      "train loss:0.13934816694764876\n",
      "train loss:0.32083442294973336\n",
      "train loss:0.09427317770256971\n",
      "train loss:0.20759438323370888\n",
      "train loss:0.1306055286793773\n",
      "train loss:0.17032497907861444\n",
      "train loss:0.1571670713368958\n",
      "train loss:0.10890968025065258\n",
      "train loss:0.34392065988901854\n",
      "train loss:0.23235345078436953\n",
      "train loss:0.12743366013710639\n",
      "train loss:0.2589023777470942\n",
      "train loss:0.20056357260532853\n",
      "train loss:0.1886434770768014\n",
      "train loss:0.12132096324264069\n",
      "train loss:0.23530903253077257\n",
      "train loss:0.1524867061383999\n",
      "train loss:0.1978299854455796\n",
      "train loss:0.2592691186764857\n",
      "train loss:0.16222030926927403\n",
      "train loss:0.17314442276661224\n",
      "train loss:0.1937723454253457\n",
      "train loss:0.24019594253385104\n",
      "train loss:0.1392407437175789\n",
      "train loss:0.037421886355354116\n",
      "train loss:0.1977533696364043\n",
      "train loss:0.10585276716097126\n",
      "train loss:0.09571303107289525\n",
      "train loss:0.23837519400917093\n",
      "train loss:0.19470911373880706\n",
      "train loss:0.13265377546264823\n",
      "train loss:0.086127835506149\n",
      "train loss:0.30952003709583276\n",
      "train loss:0.0827569265966126\n",
      "train loss:0.09235476377096992\n",
      "train loss:0.15317823264609345\n",
      "train loss:0.3060652331405736\n",
      "train loss:0.166258463549546\n",
      "train loss:0.09638231692902868\n",
      "train loss:0.13182506100584665\n",
      "train loss:0.14442108336562776\n",
      "train loss:0.21755270263744528\n",
      "train loss:0.14446205399835754\n",
      "train loss:0.18870568101261076\n",
      "train loss:0.11919250254971966\n",
      "train loss:0.1349727995762966\n",
      "train loss:0.15847782931814977\n",
      "train loss:0.17362216225176458\n",
      "train loss:0.09623675365381815\n",
      "train loss:0.12818907989307843\n",
      "train loss:0.19419790802957462\n",
      "train loss:0.09953769020124202\n",
      "train loss:0.08873784341500893\n",
      "train loss:0.08645980845438876\n",
      "train loss:0.12460568500494733\n",
      "train loss:0.06279944498496734\n",
      "train loss:0.18219907065750118\n",
      "train loss:0.14020214769370498\n",
      "train loss:0.12192983523712092\n",
      "train loss:0.17891252316711992\n",
      "train loss:0.09923091856538471\n",
      "train loss:0.13219482497609433\n",
      "train loss:0.18682768761619822\n",
      "train loss:0.2255896381264759\n",
      "train loss:0.19007286870383758\n",
      "train loss:0.07835766642044273\n",
      "train loss:0.06969672347557594\n",
      "train loss:0.21760642401234576\n",
      "train loss:0.10485502497033129\n",
      "train loss:0.12697100029735733\n",
      "train loss:0.21759617652977134\n",
      "train loss:0.20509048828294282\n",
      "train loss:0.21408372909124918\n",
      "train loss:0.16557911748223245\n",
      "train loss:0.16240557287275056\n",
      "train loss:0.1570018084588715\n",
      "train loss:0.1446692244723243\n",
      "train loss:0.09465609502359955\n",
      "train loss:0.07505164455208406\n",
      "train loss:0.20800890613800452\n",
      "train loss:0.297472691641618\n",
      "train loss:0.08879904282263293\n",
      "train loss:0.14491373625788884\n",
      "train loss:0.09026394450629167\n",
      "train loss:0.23236647903466312\n",
      "train loss:0.09979236422477815\n",
      "train loss:0.09630039164183928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09834913357640626\n",
      "train loss:0.1440860084910287\n",
      "train loss:0.12490588309042927\n",
      "train loss:0.15219764994086696\n",
      "train loss:0.18333662554075572\n",
      "train loss:0.09128933776046783\n",
      "train loss:0.1040456232651452\n",
      "train loss:0.10405752911663982\n",
      "train loss:0.09697408242975752\n",
      "train loss:0.17506326071954315\n",
      "train loss:0.1192466926323179\n",
      "train loss:0.14551525803198545\n",
      "train loss:0.10260176812434152\n",
      "train loss:0.09420660664584986\n",
      "train loss:0.10207565923857931\n",
      "train loss:0.10699355750899793\n",
      "train loss:0.09581482093916385\n",
      "train loss:0.08168474077070947\n",
      "train loss:0.14700944732095994\n",
      "train loss:0.1742039543029032\n",
      "train loss:0.14686429048921076\n",
      "train loss:0.12455641714082369\n",
      "train loss:0.1435655877752656\n",
      "train loss:0.222260111681152\n",
      "train loss:0.1938281604678871\n",
      "train loss:0.08643462370976591\n",
      "train loss:0.10255429982888974\n",
      "train loss:0.09880550825849138\n",
      "train loss:0.255742147980257\n",
      "train loss:0.10382813149546596\n",
      "train loss:0.11461101682578566\n",
      "train loss:0.15073150484434975\n",
      "train loss:0.24400869473067946\n",
      "train loss:0.1283431678511681\n",
      "train loss:0.11339022565703866\n",
      "train loss:0.10159724304183554\n",
      "train loss:0.280657041682175\n",
      "train loss:0.13270898488986269\n",
      "train loss:0.13856081960447636\n",
      "train loss:0.13836584618431153\n",
      "train loss:0.11807294262158\n",
      "train loss:0.08902332853581775\n",
      "train loss:0.23436252991965362\n",
      "train loss:0.1541900391034438\n",
      "train loss:0.12942177421356613\n",
      "train loss:0.16966947981375394\n",
      "train loss:0.1402227238083908\n",
      "train loss:0.13723290595527876\n",
      "train loss:0.08145093484600903\n",
      "train loss:0.06585311246461409\n",
      "train loss:0.1636981777299788\n",
      "train loss:0.11416927137155954\n",
      "train loss:0.07596809070845925\n",
      "train loss:0.1672822182840562\n",
      "train loss:0.21421795740323202\n",
      "train loss:0.2140806185863504\n",
      "train loss:0.08921412957731566\n",
      "train loss:0.0671226306511215\n",
      "train loss:0.1943997474216536\n",
      "train loss:0.07303989819626099\n",
      "train loss:0.1694619696341035\n",
      "train loss:0.07316131469781881\n",
      "train loss:0.10315036478028888\n",
      "train loss:0.14597171272810197\n",
      "train loss:0.058477867085607524\n",
      "=== epoch:2, train acc:0.96, test acc:0.961 ===\n",
      "train loss:0.09550537824523292\n",
      "train loss:0.08211512779378459\n",
      "train loss:0.0720266958494029\n",
      "train loss:0.16777071256969578\n",
      "train loss:0.11141026148416497\n",
      "train loss:0.13628244769350645\n",
      "train loss:0.13240196580439162\n",
      "train loss:0.16807308168989327\n",
      "train loss:0.13615002191858452\n",
      "train loss:0.07623544046968404\n",
      "train loss:0.11023033523358855\n",
      "train loss:0.14269628373908952\n",
      "train loss:0.08779211743684709\n",
      "train loss:0.18190237931461672\n",
      "train loss:0.1747577969488189\n",
      "train loss:0.0856501768977556\n",
      "train loss:0.19413798631857077\n",
      "train loss:0.08430821728184933\n",
      "train loss:0.12950490599230652\n",
      "train loss:0.045750851844497654\n",
      "train loss:0.08539485370395881\n",
      "train loss:0.11199855838935752\n",
      "train loss:0.10370703336618935\n",
      "train loss:0.13440523842883212\n",
      "train loss:0.14206066696398614\n",
      "train loss:0.162833625704238\n",
      "train loss:0.16422964154254494\n",
      "train loss:0.04371589279133316\n",
      "train loss:0.20077712115692808\n",
      "train loss:0.0927482990950278\n",
      "train loss:0.23669767217535945\n",
      "train loss:0.12828159603743985\n",
      "train loss:0.07417842195912866\n",
      "train loss:0.1518818040527052\n",
      "train loss:0.06604720133483698\n",
      "train loss:0.11750654804850941\n",
      "train loss:0.057547172360431664\n",
      "train loss:0.1476344683001362\n",
      "train loss:0.08380217307801537\n",
      "train loss:0.1366961699545496\n",
      "train loss:0.0815920557787849\n",
      "train loss:0.1537971926261374\n",
      "train loss:0.08580324813614494\n",
      "train loss:0.156573484081548\n",
      "train loss:0.0742644804547122\n",
      "train loss:0.20944560585610872\n",
      "train loss:0.1767538802038397\n",
      "train loss:0.1041610285690696\n",
      "train loss:0.12706557454870182\n",
      "train loss:0.1623748252780385\n",
      "train loss:0.21008002414017102\n",
      "train loss:0.13679432138046418\n",
      "train loss:0.06335105330863282\n",
      "train loss:0.1260257976370127\n",
      "train loss:0.1333913688252239\n",
      "train loss:0.04692943081029533\n",
      "train loss:0.10850385552615449\n",
      "train loss:0.05314547819356829\n",
      "train loss:0.12325959338530623\n",
      "train loss:0.19718163838590752\n",
      "train loss:0.11143102483965689\n",
      "train loss:0.1003288112028396\n",
      "train loss:0.08230545717509412\n",
      "train loss:0.19350430370621513\n",
      "train loss:0.14938044634739311\n",
      "train loss:0.08307211196382369\n",
      "train loss:0.10479776313023442\n",
      "train loss:0.09200947008228208\n",
      "train loss:0.15349452009851064\n",
      "train loss:0.12768759018060075\n",
      "train loss:0.16203145101288335\n",
      "train loss:0.1365087921465491\n",
      "train loss:0.11963231849562557\n",
      "train loss:0.17303970122335655\n",
      "train loss:0.17249216890984834\n",
      "train loss:0.07835394740575848\n",
      "train loss:0.1782125162771913\n",
      "train loss:0.11453762112402505\n",
      "train loss:0.17065248016597767\n",
      "train loss:0.1133382557990063\n",
      "train loss:0.222568074429751\n",
      "train loss:0.10376494536901733\n",
      "train loss:0.06663435795894058\n",
      "train loss:0.14210758441752766\n",
      "train loss:0.26217253697679493\n",
      "train loss:0.08838301169609859\n",
      "train loss:0.12751477598291033\n",
      "train loss:0.13621471816763006\n",
      "train loss:0.09157450615641034\n",
      "train loss:0.15680745353009187\n",
      "train loss:0.11711661273924513\n",
      "train loss:0.1256017122678412\n",
      "train loss:0.06850086593733437\n",
      "train loss:0.05682306491507272\n",
      "train loss:0.09625764482668901\n",
      "train loss:0.10221874300704233\n",
      "train loss:0.10175780147996441\n",
      "train loss:0.09638368028353574\n",
      "train loss:0.15811279262116892\n",
      "train loss:0.09599599151867272\n",
      "train loss:0.10343877120166471\n",
      "train loss:0.14405088965514778\n",
      "train loss:0.1375949349504843\n",
      "train loss:0.10182740309429508\n",
      "train loss:0.09174443329976041\n",
      "train loss:0.06190297769548257\n",
      "train loss:0.08164706432732755\n",
      "train loss:0.126330948341754\n",
      "train loss:0.02438482872101395\n",
      "train loss:0.0866886537475086\n",
      "train loss:0.11278253370612669\n",
      "train loss:0.10025462011693578\n",
      "train loss:0.06491363704062497\n",
      "train loss:0.164317817379201\n",
      "train loss:0.07494428855034006\n",
      "train loss:0.1694890071995644\n",
      "train loss:0.05828867849421449\n",
      "train loss:0.09254336415612725\n",
      "train loss:0.11022636037374213\n",
      "train loss:0.08925850074764353\n",
      "train loss:0.03189451525793775\n",
      "train loss:0.08634220273073957\n",
      "train loss:0.10082079711310615\n",
      "train loss:0.13687492130322945\n",
      "train loss:0.09420123578467374\n",
      "train loss:0.3195364404169611\n",
      "train loss:0.07516634523779289\n",
      "train loss:0.047599314809415066\n",
      "train loss:0.11186397034047504\n",
      "train loss:0.11346112395087131\n",
      "train loss:0.04556980710801375\n",
      "train loss:0.07742092770882338\n",
      "train loss:0.06666741968239909\n",
      "train loss:0.058799732720437585\n",
      "train loss:0.1302633366933512\n",
      "train loss:0.10778253518169313\n",
      "train loss:0.043624337296530875\n",
      "train loss:0.048460031297977144\n",
      "train loss:0.049013309627719964\n",
      "train loss:0.19882480792416907\n",
      "train loss:0.08368094447753803\n",
      "train loss:0.10915674905501369\n",
      "train loss:0.15173264234512412\n",
      "train loss:0.22487297305208628\n",
      "train loss:0.09671353836570482\n",
      "train loss:0.10123498925583464\n",
      "train loss:0.09723161466531025\n",
      "train loss:0.04276230597074735\n",
      "train loss:0.12366536368645552\n",
      "train loss:0.08557678803654517\n",
      "train loss:0.08013511038290654\n",
      "train loss:0.11747216625019735\n",
      "train loss:0.07637913806430391\n",
      "train loss:0.17073220807599207\n",
      "train loss:0.08761917086022622\n",
      "train loss:0.06896526811670194\n",
      "train loss:0.17635135233621949\n",
      "train loss:0.1898291587273162\n",
      "train loss:0.11611422838445479\n",
      "train loss:0.0594406813964902\n",
      "train loss:0.08907643200808943\n",
      "train loss:0.05140817141201407\n",
      "train loss:0.09381140973537738\n",
      "train loss:0.0953635546766116\n",
      "train loss:0.1591320379492003\n",
      "train loss:0.05869184445975524\n",
      "train loss:0.053958988157651294\n",
      "train loss:0.21940128895399177\n",
      "train loss:0.0650088969170465\n",
      "train loss:0.09976270950260721\n",
      "train loss:0.10474810362103104\n",
      "train loss:0.1623580638584272\n",
      "train loss:0.09235029995800087\n",
      "train loss:0.07391286759084105\n",
      "train loss:0.12048434272113456\n",
      "train loss:0.07965380079872145\n",
      "train loss:0.07017886762605914\n",
      "train loss:0.15763434876426813\n",
      "train loss:0.08187973820317562\n",
      "train loss:0.062171399875924786\n",
      "train loss:0.16767887760114486\n",
      "train loss:0.16078921142725466\n",
      "train loss:0.07625295577440609\n",
      "train loss:0.133419407978057\n",
      "train loss:0.05535582868033803\n",
      "train loss:0.14335756921045822\n",
      "train loss:0.09307303893872108\n",
      "train loss:0.052641013456072534\n",
      "train loss:0.06308154149749058\n",
      "train loss:0.12072479311694621\n",
      "train loss:0.11124193619742893\n",
      "train loss:0.032928251419749706\n",
      "train loss:0.09103546482819537\n",
      "train loss:0.13141670650008241\n",
      "train loss:0.050416985776009005\n",
      "train loss:0.07688967724937018\n",
      "train loss:0.05447036487122043\n",
      "train loss:0.04807894518987252\n",
      "train loss:0.09948879435851843\n",
      "train loss:0.07421678781061289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08316946353888655\n",
      "train loss:0.1396993412816194\n",
      "train loss:0.24238833456004627\n",
      "train loss:0.09988980762113167\n",
      "train loss:0.16629708697339043\n",
      "train loss:0.1746926762868994\n",
      "train loss:0.06223918240339307\n",
      "train loss:0.06433211579982483\n",
      "train loss:0.040744351468065314\n",
      "train loss:0.05767182756221457\n",
      "train loss:0.05718654893698563\n",
      "train loss:0.10710932854151402\n",
      "train loss:0.09081289902884672\n",
      "train loss:0.09386295751876082\n",
      "train loss:0.054794326022923216\n",
      "train loss:0.15746113096955047\n",
      "train loss:0.14219397153461397\n",
      "train loss:0.09302288748184301\n",
      "train loss:0.04639841368495072\n",
      "train loss:0.1292228803824948\n",
      "train loss:0.09492603490170015\n",
      "train loss:0.04237069134447171\n",
      "train loss:0.07194775303593526\n",
      "train loss:0.07632005643765633\n",
      "train loss:0.09202003520064174\n",
      "train loss:0.14663737265557786\n",
      "train loss:0.11921908389531227\n",
      "train loss:0.1004449765142433\n",
      "train loss:0.18666928441435396\n",
      "train loss:0.17435820364719515\n",
      "train loss:0.08805793954513075\n",
      "train loss:0.03345909587007274\n",
      "train loss:0.06211776740081953\n",
      "train loss:0.051797669923726\n",
      "train loss:0.04795640910316882\n",
      "train loss:0.1501002164368033\n",
      "train loss:0.021641234396462802\n",
      "train loss:0.10451093999588242\n",
      "train loss:0.15552535016085667\n",
      "train loss:0.17558650558756064\n",
      "train loss:0.054462410097414204\n",
      "train loss:0.029197177480380327\n",
      "train loss:0.13327641168170756\n",
      "train loss:0.06869145258559081\n",
      "train loss:0.07060080625915578\n",
      "train loss:0.11370276551432398\n",
      "train loss:0.12370829999663713\n",
      "train loss:0.15883523923306503\n",
      "train loss:0.03879425476924011\n",
      "train loss:0.04152966016076074\n",
      "train loss:0.09517174559642799\n",
      "train loss:0.09103143268058146\n",
      "train loss:0.07953920842019806\n",
      "train loss:0.10010019170100234\n",
      "train loss:0.0862384981961712\n",
      "train loss:0.07229512328854047\n",
      "train loss:0.2083248834710301\n",
      "train loss:0.11989771915288816\n",
      "train loss:0.1764305063605277\n",
      "train loss:0.15172020408254686\n",
      "train loss:0.05673368225218803\n",
      "train loss:0.03242205583373951\n",
      "train loss:0.07386272687582564\n",
      "train loss:0.1447421089026482\n",
      "train loss:0.1819862544725554\n",
      "train loss:0.10480775413366768\n",
      "train loss:0.03503223640741205\n",
      "train loss:0.052583185375370455\n",
      "train loss:0.1931620067152659\n",
      "train loss:0.11650773686280927\n",
      "train loss:0.10208710863549506\n",
      "train loss:0.03290129759776189\n",
      "train loss:0.07157969772191705\n",
      "train loss:0.06264031156208022\n",
      "train loss:0.053059121183359245\n",
      "train loss:0.08785514686870155\n",
      "train loss:0.17237172373938614\n",
      "train loss:0.05960939335010774\n",
      "train loss:0.10846625071156334\n",
      "train loss:0.08758083314306107\n",
      "train loss:0.08265097087585689\n",
      "train loss:0.12847513948307376\n",
      "train loss:0.04402961356793431\n",
      "train loss:0.15537964531190399\n",
      "train loss:0.07071480544932218\n",
      "train loss:0.09864188634745177\n",
      "train loss:0.0693203044250365\n",
      "train loss:0.14891940716189134\n",
      "train loss:0.03973097464061455\n",
      "train loss:0.1074564186313669\n",
      "train loss:0.06148559141298712\n",
      "train loss:0.021822656253646433\n",
      "train loss:0.13767034109142295\n",
      "train loss:0.05593381260344004\n",
      "train loss:0.10651797287967804\n",
      "train loss:0.25368462978720335\n",
      "train loss:0.03500021031074145\n",
      "train loss:0.04085236436952958\n",
      "train loss:0.17350860733572696\n",
      "train loss:0.24291940366645345\n",
      "train loss:0.13381565737916762\n",
      "train loss:0.041705358224037814\n",
      "train loss:0.08703834942717535\n",
      "train loss:0.039570139118646486\n",
      "train loss:0.14011914642353582\n",
      "train loss:0.08988950081614977\n",
      "train loss:0.07542076998642405\n",
      "train loss:0.1458994197486841\n",
      "train loss:0.07593166454094159\n",
      "train loss:0.050758196339410526\n",
      "train loss:0.08270241768903577\n",
      "train loss:0.1093006909775129\n",
      "train loss:0.0875945918236977\n",
      "train loss:0.08982264680141809\n",
      "train loss:0.0716528504028647\n",
      "train loss:0.16812598910806018\n",
      "train loss:0.089748581531727\n",
      "train loss:0.08012810685730354\n",
      "train loss:0.12292804805786334\n",
      "train loss:0.06198236166387527\n",
      "train loss:0.04916531476325594\n",
      "train loss:0.07474521194541685\n",
      "train loss:0.1352858773638235\n",
      "train loss:0.1451731336102496\n",
      "train loss:0.05444344505282487\n",
      "train loss:0.06439012351787246\n",
      "train loss:0.16504872102751533\n",
      "train loss:0.06528909381897387\n",
      "train loss:0.02714600438769189\n",
      "train loss:0.1938720398450626\n",
      "train loss:0.042427170442224646\n",
      "train loss:0.06331707166061695\n",
      "train loss:0.06140994283278253\n",
      "train loss:0.07444571880762041\n",
      "train loss:0.14640619381110156\n",
      "train loss:0.2145781834428939\n",
      "train loss:0.04923256816376949\n",
      "train loss:0.10881069216294041\n",
      "train loss:0.1137747891206004\n",
      "train loss:0.10968369945083571\n",
      "train loss:0.05299268213217281\n",
      "train loss:0.062372464864563854\n",
      "train loss:0.10880215286487313\n",
      "train loss:0.09132925053314554\n",
      "train loss:0.04519335661159109\n",
      "train loss:0.12479586836606595\n",
      "train loss:0.08127643866757327\n",
      "train loss:0.13826204553572435\n",
      "train loss:0.1292006989664649\n",
      "train loss:0.034003500047050134\n",
      "train loss:0.039948141979744146\n",
      "train loss:0.11261381181128316\n",
      "train loss:0.10595539323957953\n",
      "train loss:0.10658833703784992\n",
      "train loss:0.08264713814970845\n",
      "train loss:0.18934176194814328\n",
      "train loss:0.04546579187113135\n",
      "train loss:0.022375110291562014\n",
      "train loss:0.12234586584310643\n",
      "train loss:0.06693826305073523\n",
      "train loss:0.04476320094831028\n",
      "train loss:0.08194649705691376\n",
      "train loss:0.07258687809891377\n",
      "train loss:0.10694531506929397\n",
      "train loss:0.11110368881120145\n",
      "train loss:0.09677919029105081\n",
      "train loss:0.07232404263955144\n",
      "train loss:0.026885293005491792\n",
      "train loss:0.09795856812311333\n",
      "train loss:0.07638489634788027\n",
      "train loss:0.06722958329969388\n",
      "train loss:0.06671549372418943\n",
      "train loss:0.06498503153466142\n",
      "train loss:0.06317815804271998\n",
      "train loss:0.04944394867101755\n",
      "train loss:0.04337200979658906\n",
      "train loss:0.08481073581697737\n",
      "train loss:0.03148694796564034\n",
      "train loss:0.07050092876343621\n",
      "train loss:0.10739902006477048\n",
      "train loss:0.05906709684648455\n",
      "train loss:0.025872011620292148\n",
      "train loss:0.09500792236040906\n",
      "train loss:0.18248916431784715\n",
      "train loss:0.0421429920251969\n",
      "train loss:0.03560213672672931\n",
      "train loss:0.05292024476089751\n",
      "train loss:0.10669242080853905\n",
      "train loss:0.08729167529656523\n",
      "train loss:0.07091114223417928\n",
      "train loss:0.07892042216285096\n",
      "train loss:0.07883560519236171\n",
      "train loss:0.05751494618672767\n",
      "train loss:0.04143935014522866\n",
      "train loss:0.05444066995177902\n",
      "train loss:0.14031223138822338\n",
      "train loss:0.03872075839220253\n",
      "train loss:0.06149245234919098\n",
      "train loss:0.07439205431310308\n",
      "train loss:0.0412488184511084\n",
      "train loss:0.03787307562014017\n",
      "train loss:0.10751023706293598\n",
      "train loss:0.06939159822480172\n",
      "train loss:0.044402989984327866\n",
      "train loss:0.04588867172371476\n",
      "train loss:0.06570681923550692\n",
      "train loss:0.04140825341109943\n",
      "train loss:0.10058419198945762\n",
      "train loss:0.09577148576073868\n",
      "train loss:0.05421578675930519\n",
      "train loss:0.07711325333291513\n",
      "train loss:0.11253366746483502\n",
      "train loss:0.1455046045044986\n",
      "train loss:0.09575532664338474\n",
      "train loss:0.05344203945546767\n",
      "train loss:0.14944773722605956\n",
      "train loss:0.028740695243681322\n",
      "train loss:0.03973966788922311\n",
      "train loss:0.10032041795036548\n",
      "train loss:0.02796358470378232\n",
      "train loss:0.06286332656192585\n",
      "train loss:0.10411213751105099\n",
      "train loss:0.09673920892997692\n",
      "train loss:0.02063375814214612\n",
      "train loss:0.05185381281389743\n",
      "train loss:0.09222309510654375\n",
      "train loss:0.08648201176446917\n",
      "train loss:0.0922916740356017\n",
      "train loss:0.08114600318627962\n",
      "train loss:0.04713823268352915\n",
      "train loss:0.17028311485245748\n",
      "train loss:0.0773977423854381\n",
      "train loss:0.05899826301568428\n",
      "train loss:0.051572547626625956\n",
      "train loss:0.06893033098002337\n",
      "train loss:0.1611679226984527\n",
      "train loss:0.036472618741289146\n",
      "train loss:0.08536342155071813\n",
      "train loss:0.0339976472054367\n",
      "train loss:0.16045033610147375\n",
      "train loss:0.06385117227717119\n",
      "train loss:0.08973637072903273\n",
      "train loss:0.1215215993534652\n",
      "train loss:0.15672663686679666\n",
      "train loss:0.14666525792322932\n",
      "train loss:0.021987199802517902\n",
      "train loss:0.06011256693496272\n",
      "train loss:0.16159434345238005\n",
      "train loss:0.13843297051934544\n",
      "train loss:0.11797966011320382\n",
      "train loss:0.06299025489866393\n",
      "train loss:0.11924961641303865\n",
      "train loss:0.04770068792140008\n",
      "train loss:0.02601275869173977\n",
      "train loss:0.07726023304707852\n",
      "train loss:0.06368941185042591\n",
      "train loss:0.10750259414517441\n",
      "train loss:0.03807535320452183\n",
      "train loss:0.0601394447381945\n",
      "train loss:0.05179534488138105\n",
      "train loss:0.04356249898575377\n",
      "train loss:0.05984438087613593\n",
      "train loss:0.05228548651730138\n",
      "train loss:0.044439250053863386\n",
      "train loss:0.1307717994826521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04257574685720034\n",
      "train loss:0.059737616905538235\n",
      "train loss:0.13760535946658645\n",
      "train loss:0.08718970388049302\n",
      "train loss:0.10016248574426352\n",
      "train loss:0.057521895321574326\n",
      "train loss:0.04739694890150899\n",
      "train loss:0.1266469616603304\n",
      "train loss:0.062240638253061205\n",
      "train loss:0.056919787864130905\n",
      "train loss:0.06179272895701526\n",
      "train loss:0.08161472357554246\n",
      "train loss:0.07188400767359457\n",
      "train loss:0.03849846500635378\n",
      "train loss:0.06125865798171601\n",
      "train loss:0.060368863057129234\n",
      "train loss:0.05711736643512036\n",
      "train loss:0.04815405880748265\n",
      "train loss:0.06642634777579054\n",
      "train loss:0.036529534830420936\n",
      "train loss:0.10041233826231304\n",
      "train loss:0.05555413849965021\n",
      "train loss:0.06938418373130123\n",
      "train loss:0.040331543348421324\n",
      "train loss:0.03921553011694183\n",
      "train loss:0.06806135585591454\n",
      "train loss:0.05468834017571794\n",
      "train loss:0.05875489310381425\n",
      "train loss:0.09473660482931326\n",
      "train loss:0.06897421700040673\n",
      "train loss:0.078462142499455\n",
      "train loss:0.0988346481240447\n",
      "train loss:0.08522653882797243\n",
      "train loss:0.04798381392949059\n",
      "train loss:0.049750073374356205\n",
      "train loss:0.08363273704443784\n",
      "train loss:0.09758191148447753\n",
      "train loss:0.05808303795028556\n",
      "train loss:0.057556685128794235\n",
      "train loss:0.06999538185612343\n",
      "train loss:0.09501730564691072\n",
      "train loss:0.022170406901194217\n",
      "train loss:0.08279118129428563\n",
      "train loss:0.05805867067869339\n",
      "train loss:0.07096734510415544\n",
      "train loss:0.04052203500599002\n",
      "train loss:0.12437352572209841\n",
      "train loss:0.09845926860217333\n",
      "train loss:0.15099932896095747\n",
      "train loss:0.1266336681740004\n",
      "train loss:0.06362521388488218\n",
      "train loss:0.03446035334584128\n",
      "train loss:0.054126967527133724\n",
      "train loss:0.045879894404270184\n",
      "train loss:0.05147977237211034\n",
      "train loss:0.040914737088856706\n",
      "train loss:0.05661871320321807\n",
      "train loss:0.036810807749252376\n",
      "train loss:0.12162383519351957\n",
      "train loss:0.12273275146803543\n",
      "train loss:0.06459144029261318\n",
      "train loss:0.08828683559787316\n",
      "train loss:0.06534916107083384\n",
      "train loss:0.05419702520981299\n",
      "train loss:0.07418438090015682\n",
      "train loss:0.0278009506551545\n",
      "train loss:0.07320603514915901\n",
      "train loss:0.10804261875780498\n",
      "train loss:0.040037531080375756\n",
      "train loss:0.03378558619266458\n",
      "train loss:0.06305608080756242\n",
      "train loss:0.046705063144356254\n",
      "train loss:0.04108588596678953\n",
      "train loss:0.054760850823073214\n",
      "train loss:0.10262341321012876\n",
      "train loss:0.11604582552749712\n",
      "train loss:0.12110809167046922\n",
      "train loss:0.10420943944004786\n",
      "train loss:0.05118801435690246\n",
      "train loss:0.06974636854977237\n",
      "train loss:0.023476222101363704\n",
      "train loss:0.08186845942020379\n",
      "train loss:0.11193886724132897\n",
      "train loss:0.05757342102191383\n",
      "train loss:0.0947992222569188\n",
      "train loss:0.039254317361174754\n",
      "train loss:0.026456891685181914\n",
      "train loss:0.12294814795768799\n",
      "train loss:0.17792463792041932\n",
      "train loss:0.05288813077034642\n",
      "train loss:0.04224211075041211\n",
      "train loss:0.0322065449035768\n",
      "train loss:0.07253185912388826\n",
      "train loss:0.08176982886368\n",
      "train loss:0.08226313030716202\n",
      "train loss:0.1227477569868584\n",
      "train loss:0.05345892063978283\n",
      "train loss:0.07846940740348841\n",
      "train loss:0.029884983666257196\n",
      "train loss:0.05495762543532995\n",
      "train loss:0.0779468098111299\n",
      "train loss:0.030619655362752525\n",
      "train loss:0.07153070964290058\n",
      "train loss:0.05472466155591996\n",
      "train loss:0.07845765781359701\n",
      "train loss:0.061161041144055676\n",
      "train loss:0.10268113780829509\n",
      "train loss:0.043643016501226484\n",
      "train loss:0.17634044724146783\n",
      "train loss:0.057741661660553244\n",
      "train loss:0.07732733270078575\n",
      "train loss:0.05569854234364658\n",
      "train loss:0.06173400224668958\n",
      "train loss:0.059165988263185205\n",
      "train loss:0.06551856508271997\n",
      "train loss:0.1332762170511442\n",
      "train loss:0.06619601738227619\n",
      "train loss:0.04722429720049259\n",
      "train loss:0.05259845360762066\n",
      "train loss:0.06527002890944184\n",
      "train loss:0.05255873468301285\n",
      "train loss:0.01861926617665161\n",
      "train loss:0.18574978125607927\n",
      "train loss:0.06969280335262913\n",
      "train loss:0.043211190533209036\n",
      "train loss:0.030114547471432145\n",
      "train loss:0.048705560530885074\n",
      "train loss:0.06499512460740524\n",
      "train loss:0.05974910947806188\n",
      "train loss:0.021599962735353587\n",
      "train loss:0.03250413640731891\n",
      "train loss:0.07618780855369962\n",
      "train loss:0.08152186542033334\n",
      "train loss:0.06558009427261285\n",
      "train loss:0.10837285184814563\n",
      "=== epoch:3, train acc:0.978, test acc:0.973 ===\n",
      "train loss:0.08512972967509601\n",
      "train loss:0.05225803451990146\n",
      "train loss:0.054350861805989144\n",
      "train loss:0.12140352274224014\n",
      "train loss:0.05455661963187718\n",
      "train loss:0.0807617684390199\n",
      "train loss:0.07592549377121222\n",
      "train loss:0.033505606449691146\n",
      "train loss:0.0451231624381286\n",
      "train loss:0.10789476894364906\n",
      "train loss:0.0690659476707483\n",
      "train loss:0.16186559266824374\n",
      "train loss:0.12592958208493774\n",
      "train loss:0.04952014631243526\n",
      "train loss:0.07132444859659487\n",
      "train loss:0.16348612719731995\n",
      "train loss:0.06791815614824273\n",
      "train loss:0.03725724250808221\n",
      "train loss:0.06482292190447458\n",
      "train loss:0.08288724618584699\n",
      "train loss:0.11498059871972548\n",
      "train loss:0.1480134749379871\n",
      "train loss:0.04825819953282547\n",
      "train loss:0.04212534583117054\n",
      "train loss:0.049944323371237054\n",
      "train loss:0.020366401229466466\n",
      "train loss:0.048929194516818895\n",
      "train loss:0.05222707809757435\n",
      "train loss:0.10477479276441189\n",
      "train loss:0.08418685256631031\n",
      "train loss:0.06507555201669231\n",
      "train loss:0.16209502770343154\n",
      "train loss:0.05097857908234762\n",
      "train loss:0.03125765115363844\n",
      "train loss:0.1382670089188135\n",
      "train loss:0.05114669337748995\n",
      "train loss:0.05159464335107547\n",
      "train loss:0.1067931857718498\n",
      "train loss:0.06628528934339996\n",
      "train loss:0.1875236235463179\n",
      "train loss:0.013516071584815189\n",
      "train loss:0.041571859461060824\n",
      "train loss:0.03485454312626499\n",
      "train loss:0.06117050784245837\n",
      "train loss:0.07996651017861658\n",
      "train loss:0.08270287335648244\n",
      "train loss:0.10256919642239704\n",
      "train loss:0.10754493995343713\n",
      "train loss:0.08447441013016814\n",
      "train loss:0.08925062400536038\n",
      "train loss:0.0900719298453448\n",
      "train loss:0.06981584151195537\n",
      "train loss:0.12003869320420758\n",
      "train loss:0.0484719092490354\n",
      "train loss:0.09786977709845271\n",
      "train loss:0.03366270021711909\n",
      "train loss:0.06792776182578027\n",
      "train loss:0.03937676463065588\n",
      "train loss:0.025964848536869856\n",
      "train loss:0.043848644913051335\n",
      "train loss:0.0993246546196946\n",
      "train loss:0.017556035286700033\n",
      "train loss:0.01747342781456697\n",
      "train loss:0.03268604500261318\n",
      "train loss:0.05654733220948258\n",
      "train loss:0.12604406628983533\n",
      "train loss:0.06282922599046278\n",
      "train loss:0.12498783580651258\n",
      "train loss:0.030388785802047354\n",
      "train loss:0.024645418458680065\n",
      "train loss:0.08747676414497761\n",
      "train loss:0.05561622634925475\n",
      "train loss:0.031105848597712243\n",
      "train loss:0.05680383870566014\n",
      "train loss:0.03911393002666384\n",
      "train loss:0.0717463810890429\n",
      "train loss:0.11373223815496791\n",
      "train loss:0.02237268353432472\n",
      "train loss:0.03611347267770939\n",
      "train loss:0.0585393058888229\n",
      "train loss:0.09943182406009221\n",
      "train loss:0.04340551129557253\n",
      "train loss:0.040441751387575824\n",
      "train loss:0.03153558176009644\n",
      "train loss:0.0660626627608946\n",
      "train loss:0.013632273274637674\n",
      "train loss:0.07387685074475345\n",
      "train loss:0.13446212534186336\n",
      "train loss:0.0605459314702328\n",
      "train loss:0.023835235329856506\n",
      "train loss:0.0951704159292991\n",
      "train loss:0.06282400344127839\n",
      "train loss:0.11647905176673365\n",
      "train loss:0.07859276133934619\n",
      "train loss:0.05869497635650149\n",
      "train loss:0.14386243675264077\n",
      "train loss:0.046231079195476504\n",
      "train loss:0.06279253442719063\n",
      "train loss:0.04235444399616196\n",
      "train loss:0.03698569698211521\n",
      "train loss:0.058669200526455564\n",
      "train loss:0.030651752320835505\n",
      "train loss:0.09577102998139359\n",
      "train loss:0.07814522634248858\n",
      "train loss:0.08313610355789487\n",
      "train loss:0.07252002740807685\n",
      "train loss:0.05891462517124548\n",
      "train loss:0.038296977262274996\n",
      "train loss:0.1187372820401322\n",
      "train loss:0.028728087433826408\n",
      "train loss:0.13206909583946003\n",
      "train loss:0.08204550618072283\n",
      "train loss:0.06860657238486359\n",
      "train loss:0.0866163647443655\n",
      "train loss:0.13245596359525802\n",
      "train loss:0.04251167646431467\n",
      "train loss:0.09763062676126757\n",
      "train loss:0.04752439418980197\n",
      "train loss:0.09875215988571251\n",
      "train loss:0.026653887922993343\n",
      "train loss:0.24629471890246168\n",
      "train loss:0.03859581825056469\n",
      "train loss:0.10922745520008341\n",
      "train loss:0.17653216761188975\n",
      "train loss:0.045536001988710745\n",
      "train loss:0.10556390158879168\n",
      "train loss:0.05815103719467375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03952978058908155\n",
      "train loss:0.05559725278528165\n",
      "train loss:0.04802542317372328\n",
      "train loss:0.10019210476784361\n",
      "train loss:0.034771881674226256\n",
      "train loss:0.055531391301056984\n",
      "train loss:0.09552700068791734\n",
      "train loss:0.04904231769680385\n",
      "train loss:0.020035616428408978\n",
      "train loss:0.03526840521748436\n",
      "train loss:0.14018894593343467\n",
      "train loss:0.12095559097925376\n",
      "train loss:0.04098402194795114\n",
      "train loss:0.06313200747050887\n",
      "train loss:0.07905556079040194\n",
      "train loss:0.027447154820806667\n",
      "train loss:0.11696716873786149\n",
      "train loss:0.04844219227698418\n",
      "train loss:0.06159131627354577\n",
      "train loss:0.06945605224260726\n",
      "train loss:0.055420332616796214\n",
      "train loss:0.06541201518419468\n",
      "train loss:0.04236467163622476\n",
      "train loss:0.05220854264917283\n",
      "train loss:0.05466955051171106\n",
      "train loss:0.06292180957004335\n",
      "train loss:0.1304370010473153\n",
      "train loss:0.0721041175806005\n",
      "train loss:0.047461964163836974\n",
      "train loss:0.029311043840427778\n",
      "train loss:0.05507180369856746\n",
      "train loss:0.06269205487992478\n",
      "train loss:0.047807302021685615\n",
      "train loss:0.061734800085420226\n",
      "train loss:0.06145584091910233\n",
      "train loss:0.06158033230471119\n",
      "train loss:0.032747938311238935\n",
      "train loss:0.10225016970085234\n",
      "train loss:0.15571091492109718\n",
      "train loss:0.0556474067414916\n",
      "train loss:0.053205595142424726\n",
      "train loss:0.046244302927226914\n",
      "train loss:0.04801416408436973\n",
      "train loss:0.10554387050825662\n",
      "train loss:0.08510074836214063\n",
      "train loss:0.06599579680582782\n",
      "train loss:0.08816540237865388\n",
      "train loss:0.03958730057960897\n",
      "train loss:0.053765286508274536\n",
      "train loss:0.050143830614969076\n",
      "train loss:0.034648629560819356\n",
      "train loss:0.043931597716465605\n",
      "train loss:0.05517662184742753\n",
      "train loss:0.05135968181443956\n",
      "train loss:0.06597869823992615\n",
      "train loss:0.08476295819139844\n",
      "train loss:0.023942090882404492\n",
      "train loss:0.025170313320005234\n",
      "train loss:0.1509726382520616\n",
      "train loss:0.11314979941989221\n",
      "train loss:0.04226608512598908\n",
      "train loss:0.10484674142646028\n",
      "train loss:0.022861835410287138\n",
      "train loss:0.0777029357025896\n",
      "train loss:0.049755314805638315\n",
      "train loss:0.06037020018830841\n",
      "train loss:0.031314147635296836\n",
      "train loss:0.05694594259231274\n",
      "train loss:0.0613872864658703\n",
      "train loss:0.06809395257500234\n",
      "train loss:0.08092054453529128\n",
      "train loss:0.0793058011894475\n",
      "train loss:0.05289762847727295\n",
      "train loss:0.060028362674154956\n",
      "train loss:0.19865519452484823\n",
      "train loss:0.04457224039396993\n",
      "train loss:0.05344143408265728\n",
      "train loss:0.051270175957823926\n",
      "train loss:0.012195721592087887\n",
      "train loss:0.060195035168646445\n",
      "train loss:0.08623277232353752\n",
      "train loss:0.08502325166215341\n",
      "train loss:0.15398001652361848\n",
      "train loss:0.06687479152907864\n",
      "train loss:0.08090682492830206\n",
      "train loss:0.05954892476078697\n",
      "train loss:0.043160469012480406\n",
      "train loss:0.05273484617648279\n",
      "train loss:0.12253634360683976\n",
      "train loss:0.057049640836725105\n",
      "train loss:0.11960906501846756\n",
      "train loss:0.08398331120120578\n",
      "train loss:0.05825011103335328\n",
      "train loss:0.07425145366401119\n",
      "train loss:0.045044305630247805\n",
      "train loss:0.07606862226192405\n",
      "train loss:0.04407709758750406\n",
      "train loss:0.026953787174193045\n",
      "train loss:0.05643340627577143\n",
      "train loss:0.03587534574498647\n",
      "train loss:0.014208887698407018\n",
      "train loss:0.059806319310241746\n",
      "train loss:0.04565822866925143\n",
      "train loss:0.04073022081641357\n",
      "train loss:0.04245026274805992\n",
      "train loss:0.04696631513880835\n",
      "train loss:0.05041298272724227\n",
      "train loss:0.07297517448504548\n",
      "train loss:0.028100653486817163\n",
      "train loss:0.08503686975508147\n",
      "train loss:0.04786864487788021\n",
      "train loss:0.026942635882982874\n",
      "train loss:0.06187921805448218\n",
      "train loss:0.07457448189716712\n",
      "train loss:0.026066417830408913\n",
      "train loss:0.022398240950709847\n",
      "train loss:0.055592639115894175\n",
      "train loss:0.07135070375425442\n",
      "train loss:0.06346881288409176\n",
      "train loss:0.03320571431589459\n",
      "train loss:0.040427273306193307\n",
      "train loss:0.021602371110745696\n",
      "train loss:0.02847390493722032\n",
      "train loss:0.037816955935545335\n",
      "train loss:0.020204037136432415\n",
      "train loss:0.04502609178021779\n",
      "train loss:0.03291667258064766\n",
      "train loss:0.016783468375511354\n",
      "train loss:0.035084171003463956\n",
      "train loss:0.10143159028322661\n",
      "train loss:0.04308479667807541\n",
      "train loss:0.03015497484748687\n",
      "train loss:0.07484488193803117\n",
      "train loss:0.05222601611483344\n",
      "train loss:0.029283811802014944\n",
      "train loss:0.04479381834208394\n",
      "train loss:0.05575142367365633\n",
      "train loss:0.06419419697520723\n",
      "train loss:0.05621362089757901\n",
      "train loss:0.042375268475068284\n",
      "train loss:0.03682954251420344\n",
      "train loss:0.05789616391219057\n",
      "train loss:0.15881172322855955\n",
      "train loss:0.0215309918812892\n",
      "train loss:0.05486583810791703\n",
      "train loss:0.017989106571327455\n",
      "train loss:0.0537961987274704\n",
      "train loss:0.028198906961814235\n",
      "train loss:0.04455323155629966\n",
      "train loss:0.051257425548475254\n",
      "train loss:0.06105182617818812\n",
      "train loss:0.024438038931305663\n",
      "train loss:0.03862228006151482\n",
      "train loss:0.028481389874056427\n",
      "train loss:0.05477079621432126\n",
      "train loss:0.045888123983714946\n",
      "train loss:0.1039562193340144\n",
      "train loss:0.012886951905546064\n",
      "train loss:0.02884365621251154\n",
      "train loss:0.020205080481064574\n",
      "train loss:0.12177618352431574\n",
      "train loss:0.06977974960656572\n",
      "train loss:0.06212924801745306\n",
      "train loss:0.03616959285509947\n",
      "train loss:0.07411646359659149\n",
      "train loss:0.04693747108154794\n",
      "train loss:0.054126001388890795\n",
      "train loss:0.07171335093537956\n",
      "train loss:0.052862689097033407\n",
      "train loss:0.016531222497545416\n",
      "train loss:0.07014908126699398\n",
      "train loss:0.04610150356580022\n",
      "train loss:0.13775797950870852\n",
      "train loss:0.05853817171898628\n",
      "train loss:0.17601702413476963\n",
      "train loss:0.049137091297907706\n",
      "train loss:0.025934233964403343\n",
      "train loss:0.10279444512863903\n",
      "train loss:0.02643140606260058\n",
      "train loss:0.044616160480735356\n",
      "train loss:0.051612074524035705\n",
      "train loss:0.08518001937413067\n",
      "train loss:0.09329042526840103\n",
      "train loss:0.06773660171417435\n",
      "train loss:0.0708313773793795\n",
      "train loss:0.06360325313064838\n",
      "train loss:0.04419607730332684\n",
      "train loss:0.02581086052263431\n",
      "train loss:0.021023481353361042\n",
      "train loss:0.03647455072092745\n",
      "train loss:0.02774986953884044\n",
      "train loss:0.13492935568523223\n",
      "train loss:0.014101322869388103\n",
      "train loss:0.03248142537369876\n",
      "train loss:0.035700225601600785\n",
      "train loss:0.06653549993790522\n",
      "train loss:0.026611822756198212\n",
      "train loss:0.018635671651066187\n",
      "train loss:0.010830737353620494\n",
      "train loss:0.11346731317969085\n",
      "train loss:0.04321872696511544\n",
      "train loss:0.010401022875980295\n",
      "train loss:0.02662511573119289\n",
      "train loss:0.06451087591640534\n",
      "train loss:0.07728845608070482\n",
      "train loss:0.05244686188601592\n",
      "train loss:0.04571656218710911\n",
      "train loss:0.051709559519046315\n",
      "train loss:0.11714263372040021\n",
      "train loss:0.03719495542389756\n",
      "train loss:0.016818991147925965\n",
      "train loss:0.07818189709227476\n",
      "train loss:0.08477531237444358\n",
      "train loss:0.033561026799879025\n",
      "train loss:0.015929002329105834\n",
      "train loss:0.09796449299477467\n",
      "train loss:0.08037851637890615\n",
      "train loss:0.04548183621474854\n",
      "train loss:0.055746145201394974\n",
      "train loss:0.02321729002745658\n",
      "train loss:0.08685521655430632\n",
      "train loss:0.06729111092948224\n",
      "train loss:0.07928192316540317\n",
      "train loss:0.08532337945914971\n",
      "train loss:0.045930532624722215\n",
      "train loss:0.030158991610527163\n",
      "train loss:0.040699452177723534\n",
      "train loss:0.02553591172549468\n",
      "train loss:0.0727804822706774\n",
      "train loss:0.08317596812416804\n",
      "train loss:0.1382199434221589\n",
      "train loss:0.04382980477039567\n",
      "train loss:0.05773668089947243\n",
      "train loss:0.04119711422826053\n",
      "train loss:0.03250649280765819\n",
      "train loss:0.02356781946767214\n",
      "train loss:0.14395884074588625\n",
      "train loss:0.08204252222653655\n",
      "train loss:0.029913146762729083\n",
      "train loss:0.04099707859653221\n",
      "train loss:0.050333746671425914\n",
      "train loss:0.0608507334965163\n",
      "train loss:0.035353460524271865\n",
      "train loss:0.06987485561125246\n",
      "train loss:0.06313924121992785\n",
      "train loss:0.012832357453271982\n",
      "train loss:0.06701196694153187\n",
      "train loss:0.24651641629853288\n",
      "train loss:0.04105899173284059\n",
      "train loss:0.040541341914428465\n",
      "train loss:0.027605882826200273\n",
      "train loss:0.11919307662078393\n",
      "train loss:0.01770890884949214\n",
      "train loss:0.018921545663770176\n",
      "train loss:0.018404625243987335\n",
      "train loss:0.03283255810376661\n",
      "train loss:0.09649946971940823\n",
      "train loss:0.05984387954997141\n",
      "train loss:0.02249242308438344\n",
      "train loss:0.13455078395779915\n",
      "train loss:0.039230534317691225\n",
      "train loss:0.0714745871085253\n",
      "train loss:0.12865964919998674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026585770315518738\n",
      "train loss:0.07667121352393644\n",
      "train loss:0.016779599382384616\n",
      "train loss:0.06492179466074084\n",
      "train loss:0.03775387876613169\n",
      "train loss:0.0729484103307552\n",
      "train loss:0.11775416865231092\n",
      "train loss:0.02749534229160896\n",
      "train loss:0.04645294325091079\n",
      "train loss:0.09935793601826128\n",
      "train loss:0.03013760708638368\n",
      "train loss:0.03764700907209737\n",
      "train loss:0.01952391251003662\n",
      "train loss:0.04698558304495255\n",
      "train loss:0.05719223147102858\n",
      "train loss:0.07592804467002312\n",
      "train loss:0.046692124453522464\n",
      "train loss:0.04858707912316115\n",
      "train loss:0.07172949703512171\n",
      "train loss:0.02122632408748569\n",
      "train loss:0.03650695236264538\n",
      "train loss:0.09327954103358045\n",
      "train loss:0.0393412276646156\n",
      "train loss:0.06759282847968655\n",
      "train loss:0.058101526717027695\n",
      "train loss:0.10794219196539735\n",
      "train loss:0.09292619838331749\n",
      "train loss:0.05043795363115998\n",
      "train loss:0.09354476741665417\n",
      "train loss:0.029892156268167262\n",
      "train loss:0.10299832618150093\n",
      "train loss:0.04773024318335714\n",
      "train loss:0.023053216885992923\n",
      "train loss:0.09368773037309325\n",
      "train loss:0.04267467858590928\n",
      "train loss:0.027858845474081587\n",
      "train loss:0.1547524536003638\n",
      "train loss:0.06787382497242456\n",
      "train loss:0.045200991832997556\n",
      "train loss:0.022743542476753552\n",
      "train loss:0.03815523318332661\n",
      "train loss:0.018122185064173478\n",
      "train loss:0.10430424405058192\n",
      "train loss:0.03232124302002409\n",
      "train loss:0.08922087437705947\n",
      "train loss:0.04141957831031713\n",
      "train loss:0.049632293224361995\n",
      "train loss:0.07428045833317537\n",
      "train loss:0.028489264484115644\n",
      "train loss:0.014661240677808284\n",
      "train loss:0.03232115339765757\n",
      "train loss:0.03946165280795842\n",
      "train loss:0.02503643877225151\n",
      "train loss:0.04760487769320495\n",
      "train loss:0.011781000743164755\n",
      "train loss:0.03643101017498596\n",
      "train loss:0.016146173384579028\n",
      "train loss:0.07070875475665304\n",
      "train loss:0.07463338772034515\n",
      "train loss:0.07160198403574182\n",
      "train loss:0.05033942168249126\n",
      "train loss:0.021910737289481546\n",
      "train loss:0.24078668306762763\n",
      "train loss:0.019404249490912205\n",
      "train loss:0.04766544485805884\n",
      "train loss:0.014665564681918588\n",
      "train loss:0.048671262297067745\n",
      "train loss:0.028267399313987123\n",
      "train loss:0.06745912255082351\n",
      "train loss:0.05546616589937106\n",
      "train loss:0.011249244313810882\n",
      "train loss:0.02036922831663446\n",
      "train loss:0.04688975189852733\n",
      "train loss:0.029383961583435814\n",
      "train loss:0.04609522822294115\n",
      "train loss:0.0227062084832517\n",
      "train loss:0.06652614834068513\n",
      "train loss:0.01620827855961369\n",
      "train loss:0.025341646911942527\n",
      "train loss:0.04883525244607422\n",
      "train loss:0.05785664473123691\n",
      "train loss:0.15318419361217225\n",
      "train loss:0.02309868231380969\n",
      "train loss:0.014802234671435544\n",
      "train loss:0.013458395318173862\n",
      "train loss:0.08202348889769405\n",
      "train loss:0.02733065102530601\n",
      "train loss:0.036528775007596125\n",
      "train loss:0.013637749573739645\n",
      "train loss:0.029592932314116967\n",
      "train loss:0.0530686838026026\n",
      "train loss:0.04267718517080171\n",
      "train loss:0.04037944999372011\n",
      "train loss:0.061972298722957425\n",
      "train loss:0.0305503039346011\n",
      "train loss:0.014839512603789235\n",
      "train loss:0.14074375645228873\n",
      "train loss:0.025831945042579563\n",
      "train loss:0.018491071265049355\n",
      "train loss:0.029091904004324487\n",
      "train loss:0.020878983057457966\n",
      "train loss:0.055167204377695046\n",
      "train loss:0.07322397125893246\n",
      "train loss:0.022565270455002066\n",
      "train loss:0.03878250126573917\n",
      "train loss:0.029247567519704858\n",
      "train loss:0.024490904759488036\n",
      "train loss:0.08338299984420898\n",
      "train loss:0.05715396491771275\n",
      "train loss:0.01901548214897679\n",
      "train loss:0.06157370597610768\n",
      "train loss:0.0473613453412187\n",
      "train loss:0.0901075274546235\n",
      "train loss:0.039884236813699465\n",
      "train loss:0.10915375211267334\n",
      "train loss:0.06754386030515783\n",
      "train loss:0.02675011355234532\n",
      "train loss:0.05996386636103493\n",
      "train loss:0.10059505737302579\n",
      "train loss:0.04709458732610871\n",
      "train loss:0.042686158681518836\n",
      "train loss:0.0517436238815677\n",
      "train loss:0.1436712575509424\n",
      "train loss:0.05919493014968803\n",
      "train loss:0.01320687862024798\n",
      "train loss:0.055175536211987536\n",
      "train loss:0.1641355363664771\n",
      "train loss:0.03098377944880999\n",
      "train loss:0.05796605735249564\n",
      "train loss:0.052160272687991845\n",
      "train loss:0.08251912990479929\n",
      "train loss:0.01940356639984524\n",
      "train loss:0.011857512436427155\n",
      "train loss:0.0737773583922795\n",
      "train loss:0.02380229647110997\n",
      "train loss:0.04162702209266393\n",
      "train loss:0.059646417109912295\n",
      "train loss:0.013203039279592712\n",
      "train loss:0.021546263085399496\n",
      "train loss:0.07113468021024476\n",
      "train loss:0.04600785576915642\n",
      "train loss:0.02706393028451398\n",
      "train loss:0.04401054788758978\n",
      "train loss:0.014030698016797601\n",
      "train loss:0.08595097932333308\n",
      "train loss:0.028380997094924365\n",
      "train loss:0.02024509727924874\n",
      "train loss:0.025534929627440337\n",
      "train loss:0.015798693960427167\n",
      "train loss:0.045606998922244034\n",
      "train loss:0.017279665334993637\n",
      "train loss:0.015864501398328214\n",
      "train loss:0.02652819404521377\n",
      "train loss:0.1537318340634271\n",
      "train loss:0.060218092145854184\n",
      "train loss:0.030055082067082548\n",
      "train loss:0.11781021378836\n",
      "train loss:0.037048039962568204\n",
      "train loss:0.029047348408336407\n",
      "train loss:0.10611522682328232\n",
      "train loss:0.0812564132809372\n",
      "train loss:0.020210008570943648\n",
      "train loss:0.05813465742168149\n",
      "train loss:0.05117536623883222\n",
      "train loss:0.044173108364441244\n",
      "train loss:0.031736127774040584\n",
      "train loss:0.02782291193483023\n",
      "train loss:0.01700310928439766\n",
      "train loss:0.03350837282302884\n",
      "train loss:0.02646557465249179\n",
      "train loss:0.030084114134595618\n",
      "train loss:0.05109101584213053\n",
      "train loss:0.04776486936225233\n",
      "train loss:0.02101070289878377\n",
      "train loss:0.03184323450707129\n",
      "train loss:0.04235628262785369\n",
      "train loss:0.07263474967616407\n",
      "train loss:0.09399732139003955\n",
      "train loss:0.06873235458571277\n",
      "train loss:0.06546689096159215\n",
      "train loss:0.07377231886052991\n",
      "train loss:0.032375686433881265\n",
      "train loss:0.019913718858781345\n",
      "train loss:0.013643330894409566\n",
      "train loss:0.03351715484883864\n",
      "train loss:0.036598952173062395\n",
      "train loss:0.20869903211068572\n",
      "train loss:0.02549901772308821\n",
      "train loss:0.011572231125523106\n",
      "train loss:0.08840519889413874\n",
      "train loss:0.03565243211378053\n",
      "train loss:0.01678961003588229\n",
      "train loss:0.061078045993186454\n",
      "train loss:0.044394460564811125\n",
      "train loss:0.027342645603257606\n",
      "train loss:0.031624825772102814\n",
      "train loss:0.018721062491373338\n",
      "train loss:0.03650731829719149\n",
      "train loss:0.046193999242315896\n",
      "train loss:0.08511727474123836\n",
      "train loss:0.038628764156490386\n",
      "train loss:0.036355326622122444\n",
      "train loss:0.015313958682318697\n",
      "train loss:0.1177009048045456\n",
      "train loss:0.03564336394567408\n",
      "train loss:0.02494024389673794\n",
      "train loss:0.018947325499437565\n",
      "train loss:0.03075661488385613\n",
      "train loss:0.05841428306699984\n",
      "train loss:0.060099059094694714\n",
      "=== epoch:4, train acc:0.983, test acc:0.979 ===\n",
      "train loss:0.009877123966499474\n",
      "train loss:0.06982617881697185\n",
      "train loss:0.027224485537221215\n",
      "train loss:0.019379148973836604\n",
      "train loss:0.05833751101520664\n",
      "train loss:0.016014427678895656\n",
      "train loss:0.1446908716610468\n",
      "train loss:0.05689171383898373\n",
      "train loss:0.03483233247715969\n",
      "train loss:0.0854679535951015\n",
      "train loss:0.08673340339596415\n",
      "train loss:0.027615589295736563\n",
      "train loss:0.03176213440832379\n",
      "train loss:0.03828979717797803\n",
      "train loss:0.017324006405703554\n",
      "train loss:0.029965300485395682\n",
      "train loss:0.09919112640661011\n",
      "train loss:0.07392580981924989\n",
      "train loss:0.02508448130392988\n",
      "train loss:0.01689216157165069\n",
      "train loss:0.08131201387292865\n",
      "train loss:0.036602741812851634\n",
      "train loss:0.08510484642812818\n",
      "train loss:0.0846563482967094\n",
      "train loss:0.01392053563782339\n",
      "train loss:0.0558327298656025\n",
      "train loss:0.024080937053028727\n",
      "train loss:0.03017455312789411\n",
      "train loss:0.03137793279226652\n",
      "train loss:0.05885625471921871\n",
      "train loss:0.029339166264147464\n",
      "train loss:0.04901268899961352\n",
      "train loss:0.05239890259955241\n",
      "train loss:0.1045087184994316\n",
      "train loss:0.016051996787686644\n",
      "train loss:0.09169344332154244\n",
      "train loss:0.021542131325672512\n",
      "train loss:0.03581039848795384\n",
      "train loss:0.051035493780239666\n",
      "train loss:0.01422364104243935\n",
      "train loss:0.031210153934338954\n",
      "train loss:0.019726047848566606\n",
      "train loss:0.028708653144280928\n",
      "train loss:0.05540141222934465\n",
      "train loss:0.02803458618668493\n",
      "train loss:0.07747906392578523\n",
      "train loss:0.037722678413914294\n",
      "train loss:0.01899301145075406\n",
      "train loss:0.025132495418708368\n",
      "train loss:0.02895685838649598\n",
      "train loss:0.04894096453459688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03196260590650217\n",
      "train loss:0.018405304857437795\n",
      "train loss:0.034896768129384685\n",
      "train loss:0.040361644733725395\n",
      "train loss:0.10407921265586309\n",
      "train loss:0.02278872681867682\n",
      "train loss:0.14374312215838622\n",
      "train loss:0.057495846990010396\n",
      "train loss:0.02349190016287542\n",
      "train loss:0.06460418301182617\n",
      "train loss:0.052508057908252394\n",
      "train loss:0.021160666864437697\n",
      "train loss:0.053704424536408536\n",
      "train loss:0.03669295106864681\n",
      "train loss:0.032235367141156115\n",
      "train loss:0.02164772336450087\n",
      "train loss:0.03271658294912657\n",
      "train loss:0.06444112528239365\n",
      "train loss:0.042163989459826724\n",
      "train loss:0.08126233977244926\n",
      "train loss:0.06707328021814027\n",
      "train loss:0.033757369248358426\n",
      "train loss:0.04244189091069443\n",
      "train loss:0.03236620223312211\n",
      "train loss:0.07065974895982223\n",
      "train loss:0.026185904689774008\n",
      "train loss:0.05910134753118193\n",
      "train loss:0.015326377814519596\n",
      "train loss:0.05812511862782809\n",
      "train loss:0.04177849073968795\n",
      "train loss:0.04917716747656589\n",
      "train loss:0.010516085446949715\n",
      "train loss:0.04598040174294518\n",
      "train loss:0.08018461479725111\n",
      "train loss:0.11035996775985969\n",
      "train loss:0.033122510871688764\n",
      "train loss:0.022390696937724865\n",
      "train loss:0.022260745057466686\n",
      "train loss:0.010077297705862291\n",
      "train loss:0.020205777835147497\n",
      "train loss:0.057868212043877494\n",
      "train loss:0.09057896897082403\n",
      "train loss:0.050684755306357285\n",
      "train loss:0.1316411950300504\n",
      "train loss:0.021499867280672862\n",
      "train loss:0.015035737506863916\n",
      "train loss:0.044939637495322794\n",
      "train loss:0.02243757397990489\n",
      "train loss:0.019173694129057405\n",
      "train loss:0.009510923449420153\n",
      "train loss:0.05242019981852078\n",
      "train loss:0.05074724015093346\n",
      "train loss:0.0631768290436571\n",
      "train loss:0.012311159350028127\n",
      "train loss:0.023154486006284957\n",
      "train loss:0.06341650659853798\n",
      "train loss:0.09051617102738425\n",
      "train loss:0.04116429041631815\n",
      "train loss:0.04008109728078027\n",
      "train loss:0.01343531773028347\n",
      "train loss:0.034671568504621636\n",
      "train loss:0.01612796847319701\n",
      "train loss:0.08660893721454345\n",
      "train loss:0.04504730334500664\n",
      "train loss:0.025042356689475364\n",
      "train loss:0.04811246251002692\n",
      "train loss:0.028374432644119933\n",
      "train loss:0.029567006707940567\n",
      "train loss:0.04082554692537906\n",
      "train loss:0.013352800420529392\n",
      "train loss:0.047171438866778014\n",
      "train loss:0.022071474020795328\n",
      "train loss:0.024978317429686897\n",
      "train loss:0.04886147584116452\n",
      "train loss:0.03518639151818957\n",
      "train loss:0.05252685138649837\n",
      "train loss:0.057731942296675894\n",
      "train loss:0.034084505517949025\n",
      "train loss:0.0597627994890606\n",
      "train loss:0.02106514142143437\n",
      "train loss:0.023603408009363395\n",
      "train loss:0.07425783329439835\n",
      "train loss:0.01513887739224946\n",
      "train loss:0.010685623428718857\n",
      "train loss:0.0477199191621016\n",
      "train loss:0.02750544100359051\n",
      "train loss:0.015086614325237818\n",
      "train loss:0.04389431956675215\n",
      "train loss:0.025873737323207698\n",
      "train loss:0.026956835451609155\n",
      "train loss:0.030615144779058277\n",
      "train loss:0.04523083698716274\n",
      "train loss:0.02486090115096313\n",
      "train loss:0.09957613312506845\n",
      "train loss:0.044169444921418256\n",
      "train loss:0.014581894178578796\n",
      "train loss:0.02224049097698614\n",
      "train loss:0.010105701384135832\n",
      "train loss:0.03727598412442817\n",
      "train loss:0.08388531769584356\n",
      "train loss:0.09137372236846089\n",
      "train loss:0.013793853325355541\n",
      "train loss:0.13045837156705656\n",
      "train loss:0.036668216678985316\n",
      "train loss:0.05144349233531939\n",
      "train loss:0.03399446868757176\n",
      "train loss:0.02396260343480781\n",
      "train loss:0.010154604070477405\n",
      "train loss:0.022029300599363033\n",
      "train loss:0.03317240313062029\n",
      "train loss:0.015400976653856004\n",
      "train loss:0.06348214168325875\n",
      "train loss:0.05131524435589469\n",
      "train loss:0.06446820553948714\n",
      "train loss:0.03513784644564733\n",
      "train loss:0.060512292073697925\n",
      "train loss:0.03833439006031044\n",
      "train loss:0.019790306420608587\n",
      "train loss:0.024866754232724043\n",
      "train loss:0.05349721195167377\n",
      "train loss:0.05415889976350557\n",
      "train loss:0.021256318147276413\n",
      "train loss:0.009310945135606664\n",
      "train loss:0.018102991671576318\n",
      "train loss:0.04138571997293906\n",
      "train loss:0.013037237248426266\n",
      "train loss:0.019479571720607925\n",
      "train loss:0.08902950678148698\n",
      "train loss:0.03820129237193767\n",
      "train loss:0.02820390141228102\n",
      "train loss:0.029397734397922128\n",
      "train loss:0.02179407917318348\n",
      "train loss:0.13919613770428974\n",
      "train loss:0.016101764182292925\n",
      "train loss:0.012437737017394916\n",
      "train loss:0.016182126345647738\n",
      "train loss:0.03649780850325128\n",
      "train loss:0.05288222921012412\n",
      "train loss:0.01505739515603767\n",
      "train loss:0.018639871066853657\n",
      "train loss:0.07916825525561298\n",
      "train loss:0.03996001196625774\n",
      "train loss:0.03146739284065732\n",
      "train loss:0.025388640557142614\n",
      "train loss:0.041272342695455454\n",
      "train loss:0.04903351962862071\n",
      "train loss:0.04067734044687912\n",
      "train loss:0.05437604835365769\n",
      "train loss:0.024704067156526247\n",
      "train loss:0.056748815835780106\n",
      "train loss:0.05751391231343967\n",
      "train loss:0.031234546741305422\n",
      "train loss:0.08828563534998163\n",
      "train loss:0.028584657775311512\n",
      "train loss:0.038921470798805924\n",
      "train loss:0.03716124361137256\n",
      "train loss:0.045058585312645505\n",
      "train loss:0.026104857151704023\n",
      "train loss:0.031465582680977676\n",
      "train loss:0.02728637157047345\n",
      "train loss:0.04467385292767112\n",
      "train loss:0.06603918380556874\n",
      "train loss:0.06974552435070754\n",
      "train loss:0.01571420152918519\n",
      "train loss:0.03384406750897686\n",
      "train loss:0.040167693067774665\n",
      "train loss:0.021485706078307815\n",
      "train loss:0.014778046616079323\n",
      "train loss:0.03100919630585743\n",
      "train loss:0.032775523428359016\n",
      "train loss:0.024056228353870647\n",
      "train loss:0.0247627678343317\n",
      "train loss:0.02665895687123763\n",
      "train loss:0.06593945095804446\n",
      "train loss:0.05399423012243048\n",
      "train loss:0.03707366327925435\n",
      "train loss:0.019549653343327547\n",
      "train loss:0.04180257842040727\n",
      "train loss:0.0485987929922581\n",
      "train loss:0.1130401414095867\n",
      "train loss:0.07342536915244902\n",
      "train loss:0.047165888236278146\n",
      "train loss:0.026560491846551182\n",
      "train loss:0.0155074582514956\n",
      "train loss:0.0955234771397895\n",
      "train loss:0.01784537453177988\n",
      "train loss:0.00824072601884463\n",
      "train loss:0.026200781023983852\n",
      "train loss:0.029730492786522112\n",
      "train loss:0.048759093256904903\n",
      "train loss:0.030603815745222227\n",
      "train loss:0.09180968491795195\n",
      "train loss:0.005367842976233873\n",
      "train loss:0.011920769172941237\n",
      "train loss:0.02556384421592699\n",
      "train loss:0.06029159765943569\n",
      "train loss:0.04152128459077274\n",
      "train loss:0.04005362151497758\n",
      "train loss:0.03696575782887732\n",
      "train loss:0.04064008773223387\n",
      "train loss:0.11169303514301171\n",
      "train loss:0.02577271549940408\n",
      "train loss:0.040681355977101444\n",
      "train loss:0.021545661303728595\n",
      "train loss:0.05026615659498619\n",
      "train loss:0.023918884426591226\n",
      "train loss:0.022108688627578102\n",
      "train loss:0.021512668249747288\n",
      "train loss:0.05476855007252441\n",
      "train loss:0.03735832841808182\n",
      "train loss:0.08965993039524817\n",
      "train loss:0.02050230695412396\n",
      "train loss:0.02653675840030213\n",
      "train loss:0.04288643105370271\n",
      "train loss:0.07447031554289638\n",
      "train loss:0.04540218645002561\n",
      "train loss:0.017954444587493092\n",
      "train loss:0.020605741706276742\n",
      "train loss:0.029641191299952498\n",
      "train loss:0.02753230654798806\n",
      "train loss:0.0605923331915485\n",
      "train loss:0.012501098534899079\n",
      "train loss:0.02037309119808341\n",
      "train loss:0.05171748072789616\n",
      "train loss:0.00906385077561082\n",
      "train loss:0.04845112201425632\n",
      "train loss:0.008511257746030282\n",
      "train loss:0.10701506513613956\n",
      "train loss:0.05821486286633998\n",
      "train loss:0.03727004323543817\n",
      "train loss:0.010025039596545913\n",
      "train loss:0.013097019134934702\n",
      "train loss:0.04684588777524235\n",
      "train loss:0.030859188211029825\n",
      "train loss:0.025671764874919803\n",
      "train loss:0.05283514292641055\n",
      "train loss:0.02746347252309854\n",
      "train loss:0.022183332448638318\n",
      "train loss:0.048603163475847116\n",
      "train loss:0.09402827788634464\n",
      "train loss:0.0690901886882947\n",
      "train loss:0.034543207411737484\n",
      "train loss:0.008637691783558034\n",
      "train loss:0.01325502359784111\n",
      "train loss:0.005842377924938777\n",
      "train loss:0.055025899139315354\n",
      "train loss:0.027137808579682173\n",
      "train loss:0.08340828456230938\n",
      "train loss:0.021031271156348924\n",
      "train loss:0.045004685443259584\n",
      "train loss:0.017879758422829597\n",
      "train loss:0.08123195787239239\n",
      "train loss:0.015208600694150181\n",
      "train loss:0.10646931689362575\n",
      "train loss:0.01869306878721894\n",
      "train loss:0.025011952154098332\n",
      "train loss:0.02124069594460543\n",
      "train loss:0.022967634504945895\n",
      "train loss:0.010086646124462431\n",
      "train loss:0.04539442700208029\n",
      "train loss:0.050460901772893856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10958000229097842\n",
      "train loss:0.05115388578638382\n",
      "train loss:0.013155321550727532\n",
      "train loss:0.05539187763143236\n",
      "train loss:0.008783180539989903\n",
      "train loss:0.02298126038629218\n",
      "train loss:0.045713482019948556\n",
      "train loss:0.02693451375730679\n",
      "train loss:0.04422681388078179\n",
      "train loss:0.023268655120835122\n",
      "train loss:0.028734843046981977\n",
      "train loss:0.019970142677498616\n",
      "train loss:0.018623916437570675\n",
      "train loss:0.034533677103067976\n",
      "train loss:0.07417036095754327\n",
      "train loss:0.04686250583675605\n",
      "train loss:0.06355341702720997\n",
      "train loss:0.02770483985684594\n",
      "train loss:0.02290368393707687\n",
      "train loss:0.003940465201359597\n",
      "train loss:0.026751788758218032\n",
      "train loss:0.004144329391945967\n",
      "train loss:0.05422343689800163\n",
      "train loss:0.02470075950044051\n",
      "train loss:0.01926896315060153\n",
      "train loss:0.011496688375707793\n",
      "train loss:0.06097381302185582\n",
      "train loss:0.02476576433560127\n",
      "train loss:0.014038786817599071\n",
      "train loss:0.057562184099936235\n",
      "train loss:0.049739972688500715\n",
      "train loss:0.07729953808496189\n",
      "train loss:0.016161590778078726\n",
      "train loss:0.07993982841554637\n",
      "train loss:0.033536588601715656\n",
      "train loss:0.007453320862897973\n",
      "train loss:0.023830852847559387\n",
      "train loss:0.08723333193445808\n",
      "train loss:0.06579226879408412\n",
      "train loss:0.01063492827363121\n",
      "train loss:0.033409567304380675\n",
      "train loss:0.032590606897572164\n",
      "train loss:0.0547881805254433\n",
      "train loss:0.04903963719549131\n",
      "train loss:0.06847651104194791\n",
      "train loss:0.04250526376447308\n",
      "train loss:0.016511284492966866\n",
      "train loss:0.01815825591555891\n",
      "train loss:0.023663023543534084\n",
      "train loss:0.008961280894466435\n",
      "train loss:0.027996463580299728\n",
      "train loss:0.06497530097732887\n",
      "train loss:0.03442975612893924\n",
      "train loss:0.020200322903112758\n",
      "train loss:0.03269330581410124\n",
      "train loss:0.010770781168661505\n",
      "train loss:0.008279717420709933\n",
      "train loss:0.03300694656986407\n",
      "train loss:0.050893200268139996\n",
      "train loss:0.02821595968250458\n",
      "train loss:0.05801121143676495\n",
      "train loss:0.018169608219180556\n",
      "train loss:0.03767412707551539\n",
      "train loss:0.00528088394291067\n",
      "train loss:0.009773088422709752\n",
      "train loss:0.05616109354593333\n",
      "train loss:0.021305474394102478\n",
      "train loss:0.0132573254874879\n",
      "train loss:0.01019446680198323\n",
      "train loss:0.019352996799930414\n",
      "train loss:0.05181803454770097\n",
      "train loss:0.020022568095616148\n",
      "train loss:0.005522796554863486\n",
      "train loss:0.012530344586077491\n",
      "train loss:0.012258429369150482\n",
      "train loss:0.022995207849217138\n",
      "train loss:0.07965393887528222\n",
      "train loss:0.006344599355021681\n",
      "train loss:0.025978423396985476\n",
      "train loss:0.010187716296586744\n",
      "train loss:0.12154221814993332\n",
      "train loss:0.05521362560822762\n",
      "train loss:0.007322228838753232\n",
      "train loss:0.0919085289482599\n",
      "train loss:0.037148285820409035\n",
      "train loss:0.018818028147767892\n",
      "train loss:0.05695406857056063\n",
      "train loss:0.019462687775742896\n",
      "train loss:0.07741151261198465\n",
      "train loss:0.020003549300698493\n",
      "train loss:0.028522291029246083\n",
      "train loss:0.05038801933754998\n",
      "train loss:0.05256568725716636\n",
      "train loss:0.023302849427841093\n",
      "train loss:0.0443443849768007\n",
      "train loss:0.026016550040559985\n",
      "train loss:0.04611200523230264\n",
      "train loss:0.02844020459241384\n",
      "train loss:0.018842319048354043\n",
      "train loss:0.03351986316054948\n",
      "train loss:0.03305251407473452\n",
      "train loss:0.08606069650290102\n",
      "train loss:0.024835371757059143\n",
      "train loss:0.018324899742235216\n",
      "train loss:0.020161221573422802\n",
      "train loss:0.11659640793788396\n",
      "train loss:0.028645214598235224\n",
      "train loss:0.02230971753623745\n",
      "train loss:0.095300707275726\n",
      "train loss:0.06047396338285575\n",
      "train loss:0.1185842244071828\n",
      "train loss:0.08258851608811944\n",
      "train loss:0.017651493489851268\n",
      "train loss:0.007722127050111029\n",
      "train loss:0.13197278641760418\n",
      "train loss:0.11694986353876814\n",
      "train loss:0.021273819478947745\n",
      "train loss:0.006256151177414004\n",
      "train loss:0.004732366199736322\n",
      "train loss:0.02938865945840558\n",
      "train loss:0.021653831752878255\n",
      "train loss:0.018235118945981857\n",
      "train loss:0.028293227564684297\n",
      "train loss:0.0664543580938545\n",
      "train loss:0.04660991303291663\n",
      "train loss:0.021130261016412515\n",
      "train loss:0.03638784540260137\n",
      "train loss:0.015219333222294797\n",
      "train loss:0.057063443971587274\n",
      "train loss:0.049387814227131066\n",
      "train loss:0.011361950514603682\n",
      "train loss:0.02939641882149494\n",
      "train loss:0.0045520972239413175\n",
      "train loss:0.02879166118719878\n",
      "train loss:0.008700385463977183\n",
      "train loss:0.024374371503881966\n",
      "train loss:0.03128172543172467\n",
      "train loss:0.010441757997468664\n",
      "train loss:0.01764988924514783\n",
      "train loss:0.017091506861072383\n",
      "train loss:0.036529396173066185\n",
      "train loss:0.08969556677137057\n",
      "train loss:0.02085570136598261\n",
      "train loss:0.018091936639593173\n",
      "train loss:0.0822654977910115\n",
      "train loss:0.06221269163952883\n",
      "train loss:0.19745985044271552\n",
      "train loss:0.02985078328773846\n",
      "train loss:0.020385734655211766\n",
      "train loss:0.011690102858086346\n",
      "train loss:0.03136665404322161\n",
      "train loss:0.06922272104925214\n",
      "train loss:0.020237644338359343\n",
      "train loss:0.05767138332251049\n",
      "train loss:0.02590524224802085\n",
      "train loss:0.06981612284605332\n",
      "train loss:0.009552540570269285\n",
      "train loss:0.036148677513361274\n",
      "train loss:0.07822891633756854\n",
      "train loss:0.014275086710651608\n",
      "train loss:0.010536875807077756\n",
      "train loss:0.030216238943949026\n",
      "train loss:0.013539641695269158\n",
      "train loss:0.024891214503313584\n",
      "train loss:0.05878828638016773\n",
      "train loss:0.06511583097717007\n",
      "train loss:0.0464332757148229\n",
      "train loss:0.022431188343413226\n",
      "train loss:0.02528767511779348\n",
      "train loss:0.0350448568387628\n",
      "train loss:0.023011296560618514\n",
      "train loss:0.037490037752174514\n",
      "train loss:0.100821921190212\n",
      "train loss:0.01720240599514673\n",
      "train loss:0.016804999439728213\n",
      "train loss:0.023863508147427423\n",
      "train loss:0.050610518372415696\n",
      "train loss:0.028399741189796962\n",
      "train loss:0.023706321448544274\n",
      "train loss:0.039293098475948425\n",
      "train loss:0.012151630788331915\n",
      "train loss:0.013388287996417057\n",
      "train loss:0.04152120644834933\n",
      "train loss:0.026030000846366502\n",
      "train loss:0.028485199517659047\n",
      "train loss:0.010990344903231348\n",
      "train loss:0.041964246850901825\n",
      "train loss:0.01336798391261282\n",
      "train loss:0.046258813219656185\n",
      "train loss:0.1542264907647097\n",
      "train loss:0.022865002938953737\n",
      "train loss:0.04329120521125022\n",
      "train loss:0.01275179255736443\n",
      "train loss:0.03577148883831028\n",
      "train loss:0.054673691765295\n",
      "train loss:0.015076532998680513\n",
      "train loss:0.03842390027298587\n",
      "train loss:0.06701658965422755\n",
      "train loss:0.019342638585931948\n",
      "train loss:0.01445487254870839\n",
      "train loss:0.017954882933197053\n",
      "train loss:0.09872300119007106\n",
      "train loss:0.019889244603576925\n",
      "train loss:0.017932114946706122\n",
      "train loss:0.02481835027862675\n",
      "train loss:0.010644708293252248\n",
      "train loss:0.021678923906059983\n",
      "train loss:0.01893119401604192\n",
      "train loss:0.009891013541221816\n",
      "train loss:0.008243166046597474\n",
      "train loss:0.06757396007516235\n",
      "train loss:0.05916548069764469\n",
      "train loss:0.06255693840633858\n",
      "train loss:0.007348756125237677\n",
      "train loss:0.009042895456694957\n",
      "train loss:0.042747123410114114\n",
      "train loss:0.09107082953750406\n",
      "train loss:0.020945293373212225\n",
      "train loss:0.03892149275197367\n",
      "train loss:0.0638597196492206\n",
      "train loss:0.04212505120949008\n",
      "train loss:0.04684591149127602\n",
      "train loss:0.0346030431831474\n",
      "train loss:0.011406024234364818\n",
      "train loss:0.1014244968812741\n",
      "train loss:0.03552981688987469\n",
      "train loss:0.018729842238559388\n",
      "train loss:0.04450555515352031\n",
      "train loss:0.02961290235249219\n",
      "train loss:0.1279214082940611\n",
      "train loss:0.007708747439017934\n",
      "train loss:0.04489098210073533\n",
      "train loss:0.009830057793684005\n",
      "train loss:0.03322098971971695\n",
      "train loss:0.054167076955031986\n",
      "train loss:0.02338393559000451\n",
      "train loss:0.05253557601717349\n",
      "train loss:0.00861568471943857\n",
      "train loss:0.02144282938347876\n",
      "train loss:0.02064926150878152\n",
      "train loss:0.010959291547576702\n",
      "train loss:0.03230473541312872\n",
      "train loss:0.058498263629171696\n",
      "train loss:0.025167601518661344\n",
      "train loss:0.013685791624178432\n",
      "train loss:0.07642066435035397\n",
      "train loss:0.05901794677561225\n",
      "train loss:0.03209984254010636\n",
      "train loss:0.014138112280099941\n",
      "train loss:0.004248961767068152\n",
      "train loss:0.018070600298111222\n",
      "train loss:0.06464445629700113\n",
      "train loss:0.039306827959647093\n",
      "train loss:0.02800609024267232\n",
      "train loss:0.016415085018989174\n",
      "train loss:0.024794806516904116\n",
      "train loss:0.01908963106487126\n",
      "train loss:0.06712423406026898\n",
      "train loss:0.044500052651810694\n",
      "train loss:0.05038422758852972\n",
      "train loss:0.0115281566556703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00915488530603309\n",
      "train loss:0.008257991993931586\n",
      "train loss:0.057683141494418354\n",
      "train loss:0.048272428254726385\n",
      "train loss:0.013593977728115277\n",
      "train loss:0.06406185846485885\n",
      "train loss:0.03444708183908311\n",
      "train loss:0.017893567996562307\n",
      "train loss:0.040870230918513474\n",
      "train loss:0.026949194732851747\n",
      "train loss:0.005733554319243014\n",
      "train loss:0.04853980264349986\n",
      "train loss:0.03969105469804096\n",
      "train loss:0.019328352729414265\n",
      "train loss:0.04488515658637865\n",
      "train loss:0.030026021860556366\n",
      "train loss:0.0334759698461667\n",
      "train loss:0.028466795538455866\n",
      "train loss:0.008395974962603702\n",
      "train loss:0.021040113385494292\n",
      "train loss:0.02119028888923808\n",
      "train loss:0.09589831546298899\n",
      "train loss:0.029689363171261883\n",
      "train loss:0.06966773172767673\n",
      "train loss:0.029715605062561257\n",
      "train loss:0.03719487911654639\n",
      "train loss:0.02704303647165142\n",
      "=== epoch:5, train acc:0.981, test acc:0.985 ===\n",
      "train loss:0.05376256371837512\n",
      "train loss:0.01128760879037516\n",
      "train loss:0.024378326916914977\n",
      "train loss:0.027086610821773546\n",
      "train loss:0.014690212514460328\n",
      "train loss:0.007437363611459701\n",
      "train loss:0.04618398579812851\n",
      "train loss:0.014172304961568896\n",
      "train loss:0.005304152048460666\n",
      "train loss:0.016982801196870817\n",
      "train loss:0.05785592125682165\n",
      "train loss:0.01864627674808476\n",
      "train loss:0.01052937048880322\n",
      "train loss:0.05589162175857323\n",
      "train loss:0.014240866918515666\n",
      "train loss:0.024016997944868498\n",
      "train loss:0.10887349844822003\n",
      "train loss:0.024676210422792524\n",
      "train loss:0.019837389370368056\n",
      "train loss:0.11168738937516468\n",
      "train loss:0.09656049210910761\n",
      "train loss:0.07384158323629751\n",
      "train loss:0.060078661594671096\n",
      "train loss:0.018054448138113622\n",
      "train loss:0.025896544620576126\n",
      "train loss:0.05252791956853039\n",
      "train loss:0.017630740803880746\n",
      "train loss:0.02101655592837602\n",
      "train loss:0.011276562193200121\n",
      "train loss:0.014873687281081651\n",
      "train loss:0.00819219846656308\n",
      "train loss:0.01710389829004226\n",
      "train loss:0.028801179657419008\n",
      "train loss:0.017152909627200882\n",
      "train loss:0.02887111480405191\n",
      "train loss:0.021399033923254932\n",
      "train loss:0.00814310340457427\n",
      "train loss:0.09665100255727122\n",
      "train loss:0.01251522421379644\n",
      "train loss:0.02865812972654383\n",
      "train loss:0.011630096455234275\n",
      "train loss:0.009093991585848196\n",
      "train loss:0.047130158708292506\n",
      "train loss:0.025254459102924554\n",
      "train loss:0.014115929622045506\n",
      "train loss:0.09290263023832873\n",
      "train loss:0.01527590360204892\n",
      "train loss:0.05263442932107074\n",
      "train loss:0.023141304537109292\n",
      "train loss:0.03295518854196117\n",
      "train loss:0.10129873416791715\n",
      "train loss:0.016940960189516806\n",
      "train loss:0.03520389217590452\n",
      "train loss:0.06925356145059125\n",
      "train loss:0.01958147901034939\n",
      "train loss:0.020424150439115024\n",
      "train loss:0.03814029296484591\n",
      "train loss:0.006011323218961494\n",
      "train loss:0.03770154352602111\n",
      "train loss:0.05002777783363392\n",
      "train loss:0.007113847863262368\n",
      "train loss:0.014617022643665512\n",
      "train loss:0.02360684050016026\n",
      "train loss:0.013311574027873283\n",
      "train loss:0.03605578524621406\n",
      "train loss:0.011448892753803229\n",
      "train loss:0.020481288219288803\n",
      "train loss:0.029272888770937762\n",
      "train loss:0.1239349792069391\n",
      "train loss:0.02717330741957677\n",
      "train loss:0.03434653259033975\n",
      "train loss:0.017338824684211676\n",
      "train loss:0.025027869278506577\n",
      "train loss:0.015601914816175275\n",
      "train loss:0.04990012129059038\n",
      "train loss:0.029944981289922797\n",
      "train loss:0.0044543678868735545\n",
      "train loss:0.10721673377094586\n",
      "train loss:0.01663905857914242\n",
      "train loss:0.10317016126268286\n",
      "train loss:0.04130758037356955\n",
      "train loss:0.011043038725188064\n",
      "train loss:0.08469691501984823\n",
      "train loss:0.02461030031765905\n",
      "train loss:0.0395538833302447\n",
      "train loss:0.033499515884201234\n",
      "train loss:0.019745092976183466\n",
      "train loss:0.0098519475893453\n",
      "train loss:0.03831644791789245\n",
      "train loss:0.025510379234164212\n",
      "train loss:0.038418751999992194\n",
      "train loss:0.026593609995640387\n",
      "train loss:0.02802464917111112\n",
      "train loss:0.041003715115438925\n",
      "train loss:0.006607087930830606\n",
      "train loss:0.03112489273025952\n",
      "train loss:0.024528361896597958\n",
      "train loss:0.02943192029323315\n",
      "train loss:0.0068811699725883765\n",
      "train loss:0.03606439729161525\n",
      "train loss:0.03554951237397131\n",
      "train loss:0.012215960765893001\n",
      "train loss:0.020468345980323675\n",
      "train loss:0.09252734956022055\n",
      "train loss:0.04123180616263933\n",
      "train loss:0.02411411113560431\n",
      "train loss:0.02393464845315531\n",
      "train loss:0.014797746451951373\n",
      "train loss:0.015326230264909795\n",
      "train loss:0.026045714121692903\n",
      "train loss:0.03259294355129741\n",
      "train loss:0.008471304290345014\n",
      "train loss:0.01206739897287115\n",
      "train loss:0.04342284476213495\n",
      "train loss:0.012205895382373051\n",
      "train loss:0.03167666301655506\n",
      "train loss:0.016000213035162435\n",
      "train loss:0.039726433058094354\n",
      "train loss:0.0783863271265262\n",
      "train loss:0.03428622291865086\n",
      "train loss:0.02276704373759047\n",
      "train loss:0.004326242117464866\n",
      "train loss:0.012485030072628108\n",
      "train loss:0.015829265707849486\n",
      "train loss:0.026006329888093517\n",
      "train loss:0.015435201822507471\n",
      "train loss:0.022670716152125833\n",
      "train loss:0.019065464219756315\n",
      "train loss:0.05889505108710816\n",
      "train loss:0.03353082465318717\n",
      "train loss:0.11193116390079304\n",
      "train loss:0.02062817653512452\n",
      "train loss:0.01325705514771129\n",
      "train loss:0.006995790819541949\n",
      "train loss:0.015984947357812945\n",
      "train loss:0.021018085378456383\n",
      "train loss:0.03800986874281298\n",
      "train loss:0.016038607440828866\n",
      "train loss:0.1131693703634022\n",
      "train loss:0.017001024312249487\n",
      "train loss:0.038008497300889434\n",
      "train loss:0.01572022232667015\n",
      "train loss:0.02856088087972649\n",
      "train loss:0.015501136906395062\n",
      "train loss:0.025933809735941626\n",
      "train loss:0.046645153384954174\n",
      "train loss:0.01362805974655026\n",
      "train loss:0.015477989453635448\n",
      "train loss:0.0749134788579633\n",
      "train loss:0.04599702134576179\n",
      "train loss:0.018650247711144884\n",
      "train loss:0.06424311760898219\n",
      "train loss:0.030474131618311365\n",
      "train loss:0.029365289318469427\n",
      "train loss:0.09190074417640359\n",
      "train loss:0.016598220973984404\n",
      "train loss:0.03632392698745946\n",
      "train loss:0.06227212885511507\n",
      "train loss:0.017543064628679283\n",
      "train loss:0.016602332513375832\n",
      "train loss:0.07179993164254211\n",
      "train loss:0.015570378607563874\n",
      "train loss:0.03646883533111562\n",
      "train loss:0.05729446394761739\n",
      "train loss:0.05040325705923099\n",
      "train loss:0.01727680473279511\n",
      "train loss:0.02201951449585858\n",
      "train loss:0.08025590373604027\n",
      "train loss:0.008863622349200555\n",
      "train loss:0.03271951900716818\n",
      "train loss:0.008521450170749999\n",
      "train loss:0.05325484131102872\n",
      "train loss:0.0491457897229934\n",
      "train loss:0.017055006459918802\n",
      "train loss:0.019682541690950076\n",
      "train loss:0.031628592329899986\n",
      "train loss:0.026551337622206118\n",
      "train loss:0.018727583312239834\n",
      "train loss:0.047947942868170106\n",
      "train loss:0.04918479901325682\n",
      "train loss:0.06620469235858054\n",
      "train loss:0.02821423247420406\n",
      "train loss:0.028696810882359945\n",
      "train loss:0.010399056689709316\n",
      "train loss:0.05318192211742785\n",
      "train loss:0.03514965091539048\n",
      "train loss:0.02236176803317248\n",
      "train loss:0.08222528248262914\n",
      "train loss:0.030929605901418085\n",
      "train loss:0.04796039140928246\n",
      "train loss:0.041137470312437856\n",
      "train loss:0.010609796546139163\n",
      "train loss:0.032275414928277686\n",
      "train loss:0.01133504218862589\n",
      "train loss:0.040149589999518474\n",
      "train loss:0.07457850507055167\n",
      "train loss:0.015114604484694228\n",
      "train loss:0.11041685678235826\n",
      "train loss:0.010915957457029231\n",
      "train loss:0.0069427800267212285\n",
      "train loss:0.06469391728873773\n",
      "train loss:0.022741422845665268\n",
      "train loss:0.011235502254327533\n",
      "train loss:0.013888629456444024\n",
      "train loss:0.013176718698931524\n",
      "train loss:0.022284811520074353\n",
      "train loss:0.026716800082008708\n",
      "train loss:0.008926918762360615\n",
      "train loss:0.011443370482986086\n",
      "train loss:0.02786910949623747\n",
      "train loss:0.00863094510533797\n",
      "train loss:0.009885247543972249\n",
      "train loss:0.00287142086558506\n",
      "train loss:0.02446864180712884\n",
      "train loss:0.11152626730908749\n",
      "train loss:0.09436774302641156\n",
      "train loss:0.0291062757867953\n",
      "train loss:0.017284579043656653\n",
      "train loss:0.07354185612749123\n",
      "train loss:0.11790974046451558\n",
      "train loss:0.017041646970425074\n",
      "train loss:0.007762720739548017\n",
      "train loss:0.023787395683306324\n",
      "train loss:0.019860816457985497\n",
      "train loss:0.02798932510460379\n",
      "train loss:0.04028196567574974\n",
      "train loss:0.035660375053831704\n",
      "train loss:0.018106870662352566\n",
      "train loss:0.08319881271861426\n",
      "train loss:0.018771517155054797\n",
      "train loss:0.021678555229589138\n",
      "train loss:0.010467944040120103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02539244518296139\n",
      "train loss:0.01950841182220626\n",
      "train loss:0.00187554049603416\n",
      "train loss:0.020740847047144864\n",
      "train loss:0.016261561375949998\n",
      "train loss:0.0433194266560586\n",
      "train loss:0.06605932759991254\n",
      "train loss:0.04499107270210577\n",
      "train loss:0.029840042203444102\n",
      "train loss:0.01956862544049569\n",
      "train loss:0.09176863021236786\n",
      "train loss:0.003955598725411526\n",
      "train loss:0.004067595743031952\n",
      "train loss:0.055873205908445626\n",
      "train loss:0.009130002167161021\n",
      "train loss:0.018029087505061617\n",
      "train loss:0.026839242147532864\n",
      "train loss:0.01396608619685469\n",
      "train loss:0.04967872916671984\n",
      "train loss:0.027202220358501575\n",
      "train loss:0.19733425262148344\n",
      "train loss:0.0051222322230325325\n",
      "train loss:0.08738995115083968\n",
      "train loss:0.011699185818717397\n",
      "train loss:0.033385137514301125\n",
      "train loss:0.06477330380125228\n",
      "train loss:0.03424315707529555\n",
      "train loss:0.01519305077197615\n",
      "train loss:0.05284631670003478\n",
      "train loss:0.04444665691679059\n",
      "train loss:0.008917259956158474\n",
      "train loss:0.04055251265360698\n",
      "train loss:0.025902470562986543\n",
      "train loss:0.06042875399522567\n",
      "train loss:0.023403499920215672\n",
      "train loss:0.014718321840506914\n",
      "train loss:0.006267922909181812\n",
      "train loss:0.03364189514389479\n",
      "train loss:0.011716630854589722\n",
      "train loss:0.01868955311108131\n",
      "train loss:0.037739054430363315\n",
      "train loss:0.006207857797898933\n",
      "train loss:0.02402464223588078\n",
      "train loss:0.036950311363345305\n",
      "train loss:0.09939244647055084\n",
      "train loss:0.034663691724185\n",
      "train loss:0.01861781880481916\n",
      "train loss:0.05674239946686737\n",
      "train loss:0.018119812389960792\n",
      "train loss:0.01673203943341488\n",
      "train loss:0.016830793444878103\n",
      "train loss:0.00544790265381386\n",
      "train loss:0.03860630580372016\n",
      "train loss:0.017496751244058785\n",
      "train loss:0.005893629797374617\n",
      "train loss:0.023137904088818807\n",
      "train loss:0.021745162744121086\n",
      "train loss:0.02545449958646197\n",
      "train loss:0.03320828154459286\n",
      "train loss:0.020842536001253034\n",
      "train loss:0.008764036352814959\n",
      "train loss:0.0071032934111756605\n",
      "train loss:0.023836568421880887\n",
      "train loss:0.03431801898831413\n",
      "train loss:0.017462183888397112\n",
      "train loss:0.009767007486246487\n",
      "train loss:0.019745560120056654\n",
      "train loss:0.037882977746621464\n",
      "train loss:0.01865004697491336\n",
      "train loss:0.008557021360167335\n",
      "train loss:0.016077280672549665\n",
      "train loss:0.043057758776536253\n",
      "train loss:0.03791994794312385\n",
      "train loss:0.003332912002857497\n",
      "train loss:0.023811634000324003\n",
      "train loss:0.02223078038356726\n",
      "train loss:0.018647779558030226\n",
      "train loss:0.02257418158693433\n",
      "train loss:0.009324787728961188\n",
      "train loss:0.02566319452272293\n",
      "train loss:0.01659327457268285\n",
      "train loss:0.046658311241708536\n",
      "train loss:0.023792800811195964\n",
      "train loss:0.03159296052517525\n",
      "train loss:0.042350938055566355\n",
      "train loss:0.048538568178551504\n",
      "train loss:0.0171579941492939\n",
      "train loss:0.006418810314642036\n",
      "train loss:0.025466512683163644\n",
      "train loss:0.016218527469563693\n",
      "train loss:0.004723837265405542\n",
      "train loss:0.045927925126590434\n",
      "train loss:0.02159456971213909\n",
      "train loss:0.016076566229099996\n",
      "train loss:0.005539213182871365\n",
      "train loss:0.013243060986538727\n",
      "train loss:0.037464976273262195\n",
      "train loss:0.013555921280287275\n",
      "train loss:0.05659637349963154\n",
      "train loss:0.0615136468154129\n",
      "train loss:0.04812023236063109\n",
      "train loss:0.02860765043923443\n",
      "train loss:0.019451603540384985\n",
      "train loss:0.04292590317597849\n",
      "train loss:0.04252559926081572\n",
      "train loss:0.04401523396274858\n",
      "train loss:0.012741641021776667\n",
      "train loss:0.0789849193794812\n",
      "train loss:0.013582944621672373\n",
      "train loss:0.0056452149729694315\n",
      "train loss:0.012347770744320315\n",
      "train loss:0.019157760270385894\n",
      "train loss:0.007936528455818489\n",
      "train loss:0.00797541243298888\n",
      "train loss:0.021661985775088995\n",
      "train loss:0.05381520809134972\n",
      "train loss:0.025440478427164886\n",
      "train loss:0.05123324456527018\n",
      "train loss:0.04044182025142035\n",
      "train loss:0.06382256343150298\n",
      "train loss:0.003843658391459534\n",
      "train loss:0.009800732145769733\n",
      "train loss:0.04033725498715406\n",
      "train loss:0.038045671840739904\n",
      "train loss:0.02821765798762247\n",
      "train loss:0.010584618406683058\n",
      "train loss:0.03032369024409712\n",
      "train loss:0.016049062275241197\n",
      "train loss:0.055462459038406145\n",
      "train loss:0.009211163781068718\n",
      "train loss:0.022748329196838068\n",
      "train loss:0.146723955933719\n",
      "train loss:0.007726783328713294\n",
      "train loss:0.025389497201699016\n",
      "train loss:0.004778464663370671\n",
      "train loss:0.02018075230018987\n",
      "train loss:0.032006661359172774\n",
      "train loss:0.023928254091603898\n",
      "train loss:0.05702461965155632\n",
      "train loss:0.028661682156426154\n",
      "train loss:0.019084159747293158\n",
      "train loss:0.01103662161783056\n",
      "train loss:0.02726999712406516\n",
      "train loss:0.027358017554973416\n",
      "train loss:0.10368858733406969\n",
      "train loss:0.01945759891807075\n",
      "train loss:0.008695564359461744\n",
      "train loss:0.01699931042631153\n",
      "train loss:0.033478418579449616\n",
      "train loss:0.004123736528058042\n",
      "train loss:0.029798190773382558\n",
      "train loss:0.027175952406300902\n",
      "train loss:0.03828364818414485\n",
      "train loss:0.023147058186382692\n",
      "train loss:0.035864166803990655\n",
      "train loss:0.04327219162780144\n",
      "train loss:0.007618024888734266\n",
      "train loss:0.018745199369774996\n",
      "train loss:0.016737424957924973\n",
      "train loss:0.026563953405663258\n",
      "train loss:0.026102936130121015\n",
      "train loss:0.04326016154380418\n",
      "train loss:0.019116139007513834\n",
      "train loss:0.04596221205433996\n",
      "train loss:0.009229336044158154\n",
      "train loss:0.03630948190353753\n",
      "train loss:0.019470601298572546\n",
      "train loss:0.026104447050033074\n",
      "train loss:0.01937766705061644\n",
      "train loss:0.014162821474567615\n",
      "train loss:0.01842794982264332\n",
      "train loss:0.023853423772054932\n",
      "train loss:0.008904427868100523\n",
      "train loss:0.022755804721490032\n",
      "train loss:0.015096374152014438\n",
      "train loss:0.016414477199364275\n",
      "train loss:0.018349113832991554\n",
      "train loss:0.03172583909470906\n",
      "train loss:0.01875161833181758\n",
      "train loss:0.059221802035792\n",
      "train loss:0.011568214448525894\n",
      "train loss:0.013986464328508069\n",
      "train loss:0.007927863377088949\n",
      "train loss:0.03316663774961265\n",
      "train loss:0.011230537701087626\n",
      "train loss:0.06893174727910824\n",
      "train loss:0.03417097499920682\n",
      "train loss:0.03436148810972304\n",
      "train loss:0.08771492576465857\n",
      "train loss:0.04901567231415447\n",
      "train loss:0.015356311762587647\n",
      "train loss:0.010708126803620148\n",
      "train loss:0.013272204228051303\n",
      "train loss:0.011848830023665546\n",
      "train loss:0.008829267100025103\n",
      "train loss:0.03447714481931951\n",
      "train loss:0.06367318982630628\n",
      "train loss:0.026372314609186716\n",
      "train loss:0.004537226656311292\n",
      "train loss:0.012723050518040109\n",
      "train loss:0.052625614828994326\n",
      "train loss:0.01181437031988765\n",
      "train loss:0.04620259281379149\n",
      "train loss:0.024418111222772442\n",
      "train loss:0.012136861718767055\n",
      "train loss:0.02784861405799782\n",
      "train loss:0.0553938763799896\n",
      "train loss:0.014023569626650873\n",
      "train loss:0.013408948074048996\n",
      "train loss:0.03944276352912453\n",
      "train loss:0.027453033891378324\n",
      "train loss:0.03132689796563469\n",
      "train loss:0.035664661490253526\n",
      "train loss:0.01258656216299242\n",
      "train loss:0.04848358378637033\n",
      "train loss:0.05985154280650911\n",
      "train loss:0.022081398017552725\n",
      "train loss:0.018812071343835828\n",
      "train loss:0.01539103542272889\n",
      "train loss:0.011402804692946284\n",
      "train loss:0.00624074245299312\n",
      "train loss:0.01996420083359869\n",
      "train loss:0.014773477647432556\n",
      "train loss:0.025015044658442162\n",
      "train loss:0.003494970272932895\n",
      "train loss:0.005585913409035093\n",
      "train loss:0.012334790413003196\n",
      "train loss:0.038880267976381847\n",
      "train loss:0.047197876557588454\n",
      "train loss:0.0642869375008037\n",
      "train loss:0.00511773268846092\n",
      "train loss:0.026323711791595178\n",
      "train loss:0.06788593193728927\n",
      "train loss:0.01962763138800379\n",
      "train loss:0.007084155056966059\n",
      "train loss:0.010325234845225286\n",
      "train loss:0.02029475701677279\n",
      "train loss:0.01343050368789995\n",
      "train loss:0.027494016014022855\n",
      "train loss:0.029040522797958455\n",
      "train loss:0.002936959666776122\n",
      "train loss:0.04884673395740889\n",
      "train loss:0.025754913129291533\n",
      "train loss:0.027761517122645688\n",
      "train loss:0.006352713912272484\n",
      "train loss:0.01039450843902422\n",
      "train loss:0.0030208671697275367\n",
      "train loss:0.007885078331342507\n",
      "train loss:0.04485364435401844\n",
      "train loss:0.0111434635644595\n",
      "train loss:0.025344151119489743\n",
      "train loss:0.006754615771239677\n",
      "train loss:0.01371037737704015\n",
      "train loss:0.10299490588012018\n",
      "train loss:0.01040300289325436\n",
      "train loss:0.02039451292115216\n",
      "train loss:0.008638956535497672\n",
      "train loss:0.020008711599369965\n",
      "train loss:0.011675350526211596\n",
      "train loss:0.020297197163185295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06084629410521418\n",
      "train loss:0.003009243451016596\n",
      "train loss:0.013496974864599807\n",
      "train loss:0.048239397709641675\n",
      "train loss:0.008255869237427393\n",
      "train loss:0.005059413439172189\n",
      "train loss:0.051081376981853485\n",
      "train loss:0.07514154478706735\n",
      "train loss:0.021566290199814344\n",
      "train loss:0.09852197236712175\n",
      "train loss:0.05110873745266785\n",
      "train loss:0.011243292645898722\n",
      "train loss:0.02261177666146348\n",
      "train loss:0.031204178810002783\n",
      "train loss:0.021273765203581697\n",
      "train loss:0.03250591896196598\n",
      "train loss:0.014082045766697143\n",
      "train loss:0.009650536191614217\n",
      "train loss:0.0828032956632283\n",
      "train loss:0.01237315963792059\n",
      "train loss:0.022142337951101397\n",
      "train loss:0.009427239420899252\n",
      "train loss:0.00730791260576048\n",
      "train loss:0.06708341211780829\n",
      "train loss:0.002512463098874875\n",
      "train loss:0.029759185707128256\n",
      "train loss:0.018392669321690105\n",
      "train loss:0.01169926233787657\n",
      "train loss:0.037580413286437485\n",
      "train loss:0.057629373847710434\n",
      "train loss:0.00482150022361786\n",
      "train loss:0.02481935177389205\n",
      "train loss:0.043446691032674824\n",
      "train loss:0.025581352404996403\n",
      "train loss:0.006951121521947331\n",
      "train loss:0.012225422031675448\n",
      "train loss:0.04357861921383254\n",
      "train loss:0.08081207881372503\n",
      "train loss:0.037511447649158314\n",
      "train loss:0.009819072467135193\n",
      "train loss:0.02567238814404277\n",
      "train loss:0.017993332262832343\n",
      "train loss:0.028530895878191492\n",
      "train loss:0.026461075435059555\n",
      "train loss:0.005856237185528114\n",
      "train loss:0.010186868603219015\n",
      "train loss:0.008897095104110263\n",
      "train loss:0.01537059403264362\n",
      "train loss:0.046262634281554554\n",
      "train loss:0.07204900118120951\n",
      "train loss:0.030011679458454253\n",
      "train loss:0.035612506437426326\n",
      "train loss:0.00748770694145705\n",
      "train loss:0.013748328542582105\n",
      "train loss:0.03334487652891772\n",
      "train loss:0.02381339870078591\n",
      "train loss:0.08250281456195639\n",
      "train loss:0.031661180539211256\n",
      "train loss:0.006578194195351733\n",
      "train loss:0.016299563312487955\n",
      "train loss:0.038271323202850496\n",
      "train loss:0.011910840440993702\n",
      "train loss:0.01531394642294824\n",
      "train loss:0.02137819635293785\n",
      "train loss:0.0043407296243752145\n",
      "train loss:0.018384751110109652\n",
      "train loss:0.026305272014262568\n",
      "train loss:0.01389908612487336\n",
      "train loss:0.011455386311192004\n",
      "train loss:0.03034167490379537\n",
      "train loss:0.006110583239103752\n",
      "train loss:0.04697232957605238\n",
      "train loss:0.012660662491447774\n",
      "train loss:0.009639917986606232\n",
      "train loss:0.01021503142630509\n",
      "train loss:0.005773348110225365\n",
      "train loss:0.02305763674089886\n",
      "train loss:0.03565123435525024\n",
      "train loss:0.009824091574778758\n",
      "train loss:0.011524116676835458\n",
      "train loss:0.005452269028024306\n",
      "train loss:0.04774319544966631\n",
      "train loss:0.011914577229293344\n",
      "train loss:0.019369770270483425\n",
      "train loss:0.009499782734508418\n",
      "train loss:0.008573044736907776\n",
      "train loss:0.011614817837910464\n",
      "train loss:0.026795086846380253\n",
      "train loss:0.010528980245680697\n",
      "train loss:0.03395964598196195\n",
      "train loss:0.01202288803042944\n",
      "train loss:0.017891997848984993\n",
      "train loss:0.05410764322970753\n",
      "train loss:0.011924460445892564\n",
      "train loss:0.004859152442871667\n",
      "train loss:0.008004690597364843\n",
      "train loss:0.019440001906006595\n",
      "train loss:0.007769970290962829\n",
      "train loss:0.022282653180341835\n",
      "train loss:0.009971559640273795\n",
      "train loss:0.006638265382522258\n",
      "train loss:0.008436984126374322\n",
      "train loss:0.018282333269389522\n",
      "train loss:0.010500353495946062\n",
      "train loss:0.039734658330230425\n",
      "train loss:0.0494101880421697\n",
      "train loss:0.033221494641981236\n",
      "train loss:0.005533629605981213\n",
      "=== epoch:6, train acc:0.984, test acc:0.982 ===\n",
      "train loss:0.02446189266946809\n",
      "train loss:0.021473880186450654\n",
      "train loss:0.0025720139941847447\n",
      "train loss:0.01881821822488792\n",
      "train loss:0.01538071513735429\n",
      "train loss:0.023255874854594932\n",
      "train loss:0.005982298622754998\n",
      "train loss:0.016412876509339983\n",
      "train loss:0.01131204949578708\n",
      "train loss:0.013384661514167067\n",
      "train loss:0.011424179995195866\n",
      "train loss:0.05491030898187818\n",
      "train loss:0.012250109242528834\n",
      "train loss:0.026334213423284455\n",
      "train loss:0.005921390602779936\n",
      "train loss:0.004054571888520186\n",
      "train loss:0.021505162590819825\n",
      "train loss:0.027214661301659858\n",
      "train loss:0.027874517708800905\n",
      "train loss:0.01475461171444709\n",
      "train loss:0.011724184466822059\n",
      "train loss:0.015212094458379963\n",
      "train loss:0.013778554419424556\n",
      "train loss:0.022938237697850864\n",
      "train loss:0.011813667840055008\n",
      "train loss:0.014912863225115265\n",
      "train loss:0.05571772005779493\n",
      "train loss:0.005936385799802458\n",
      "train loss:0.006263818977150658\n",
      "train loss:0.052012851488456864\n",
      "train loss:0.014188702899749338\n",
      "train loss:0.040181854105319964\n",
      "train loss:0.06978053907348686\n",
      "train loss:0.005509442952030331\n",
      "train loss:0.026469612697512638\n",
      "train loss:0.01967128308327611\n",
      "train loss:0.00529363338916352\n",
      "train loss:0.004150985445939407\n",
      "train loss:0.011837267195401506\n",
      "train loss:0.035007171586008703\n",
      "train loss:0.005417969191940161\n",
      "train loss:0.02510561052812863\n",
      "train loss:0.027383635002319627\n",
      "train loss:0.021844005194409034\n",
      "train loss:0.03386778219058535\n",
      "train loss:0.03525726143518786\n",
      "train loss:0.02204217793935902\n",
      "train loss:0.07342491737823627\n",
      "train loss:0.03117247881600352\n",
      "train loss:0.07574101703736043\n",
      "train loss:0.008993797261793503\n",
      "train loss:0.02299091380962177\n",
      "train loss:0.13163889826227818\n",
      "train loss:0.037395154518241325\n",
      "train loss:0.08539289197972211\n",
      "train loss:0.008754115229901471\n",
      "train loss:0.016234763872206317\n",
      "train loss:0.01757066847482499\n",
      "train loss:0.02685595081711328\n",
      "train loss:0.05821759819947941\n",
      "train loss:0.03895766693984963\n",
      "train loss:0.011468172243791548\n",
      "train loss:0.014882125852522288\n",
      "train loss:0.02953003222286696\n",
      "train loss:0.019966100955158324\n",
      "train loss:0.037316530812798544\n",
      "train loss:0.029254586852978676\n",
      "train loss:0.008149032887477382\n",
      "train loss:0.009276231112660231\n",
      "train loss:0.013576369613070106\n",
      "train loss:0.025797875252856664\n",
      "train loss:0.01715273720022598\n",
      "train loss:0.06879715396758504\n",
      "train loss:0.01910593879517392\n",
      "train loss:0.038972753223572805\n",
      "train loss:0.0054657272846489946\n",
      "train loss:0.004135228490460309\n",
      "train loss:0.008241796233568788\n",
      "train loss:0.006301658705134075\n",
      "train loss:0.08668506045406506\n",
      "train loss:0.015536500849749606\n",
      "train loss:0.01625823840224124\n",
      "train loss:0.010469154202009499\n",
      "train loss:0.06420121678172663\n",
      "train loss:0.003757452275220335\n",
      "train loss:0.0260574004946105\n",
      "train loss:0.042660820342366776\n",
      "train loss:0.0580773340845506\n",
      "train loss:0.009994820984444224\n",
      "train loss:0.07398322604114363\n",
      "train loss:0.055355721259531226\n",
      "train loss:0.03753564977121279\n",
      "train loss:0.020898544303818677\n",
      "train loss:0.02949587773677307\n",
      "train loss:0.04251081332348572\n",
      "train loss:0.01433308258796669\n",
      "train loss:0.09341848995844032\n",
      "train loss:0.0032777352898250554\n",
      "train loss:0.02065433996673843\n",
      "train loss:0.05941472613912949\n",
      "train loss:0.006628961538509346\n",
      "train loss:0.0531997984571749\n",
      "train loss:0.030444604781445995\n",
      "train loss:0.005359243759387991\n",
      "train loss:0.04188444755977354\n",
      "train loss:0.03319145708456275\n",
      "train loss:0.009619489384823193\n",
      "train loss:0.016945705061190676\n",
      "train loss:0.008979898448257763\n",
      "train loss:0.02894300622383375\n",
      "train loss:0.04759864285421365\n",
      "train loss:0.00792815977940669\n",
      "train loss:0.005347944971533529\n",
      "train loss:0.023154724929717388\n",
      "train loss:0.0235665256937507\n",
      "train loss:0.006300810850146738\n",
      "train loss:0.07557343124879588\n",
      "train loss:0.020871257300912348\n",
      "train loss:0.024709330451684646\n",
      "train loss:0.019954729556252784\n",
      "train loss:0.026771387315704852\n",
      "train loss:0.01704168643796569\n",
      "train loss:0.00440348340823156\n",
      "train loss:0.016772691390169136\n",
      "train loss:0.016322037563777182\n",
      "train loss:0.015697571690198264\n",
      "train loss:0.025101772593956326\n",
      "train loss:0.048988620775672925\n",
      "train loss:0.00696144197485687\n",
      "train loss:0.022445014719088996\n",
      "train loss:0.041079330145838686\n",
      "train loss:0.007057768874055871\n",
      "train loss:0.008103879459827724\n",
      "train loss:0.0076608626951200996\n",
      "train loss:0.026913741880777855\n",
      "train loss:0.033203619631681267\n",
      "train loss:0.018960710385987525\n",
      "train loss:0.0344063463541717\n",
      "train loss:0.04181406424445267\n",
      "train loss:0.020617828370691673\n",
      "train loss:0.007700543809729415\n",
      "train loss:0.04046954227615981\n",
      "train loss:0.021276494346986922\n",
      "train loss:0.029433721031116144\n",
      "train loss:0.010734350160756956\n",
      "train loss:0.007475225085781323\n",
      "train loss:0.010615405784310816\n",
      "train loss:0.00577475437343656\n",
      "train loss:0.009823987230211297\n",
      "train loss:0.021963546353698047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06544995095950945\n",
      "train loss:0.02469223938905164\n",
      "train loss:0.07120625672029583\n",
      "train loss:0.0038341452333200765\n",
      "train loss:0.0223168433727448\n",
      "train loss:0.07201865486383306\n",
      "train loss:0.02262059879371916\n",
      "train loss:0.018486555172386444\n",
      "train loss:0.016182869479111222\n",
      "train loss:0.009066849313955875\n",
      "train loss:0.01500575764820607\n",
      "train loss:0.07821008706547995\n",
      "train loss:0.040827688310001164\n",
      "train loss:0.010896192807163535\n",
      "train loss:0.007325010056897901\n",
      "train loss:0.01722373043014831\n",
      "train loss:0.04092888020061657\n",
      "train loss:0.02704673941852184\n",
      "train loss:0.03542007757718166\n",
      "train loss:0.021409413072871968\n",
      "train loss:0.004971957537801875\n",
      "train loss:0.01291490331676426\n",
      "train loss:0.025261180155514807\n",
      "train loss:0.039449047656463405\n",
      "train loss:0.01369142645098897\n",
      "train loss:0.02935933078140504\n",
      "train loss:0.08698660031648434\n",
      "train loss:0.015960954345923373\n",
      "train loss:0.023661163819458632\n",
      "train loss:0.007263226742729275\n",
      "train loss:0.02238668561170382\n",
      "train loss:0.041919496410909717\n",
      "train loss:0.01830237354655161\n",
      "train loss:0.017277843937307018\n",
      "train loss:0.017781250499773995\n",
      "train loss:0.02898678100998507\n",
      "train loss:0.010625243715485505\n",
      "train loss:0.017079306124714432\n",
      "train loss:0.005052998734645045\n",
      "train loss:0.013919202237880632\n",
      "train loss:0.004413400940035273\n",
      "train loss:0.008729210911473875\n",
      "train loss:0.015140949233750325\n",
      "train loss:0.08952626075405251\n",
      "train loss:0.019214530285123835\n",
      "train loss:0.09072656205351164\n",
      "train loss:0.018906512888978474\n",
      "train loss:0.006009464538551849\n",
      "train loss:0.029511923326057357\n",
      "train loss:0.016936893176953047\n",
      "train loss:0.013247955776315556\n",
      "train loss:0.03587651280854981\n",
      "train loss:0.012418461008648202\n",
      "train loss:0.07362292777985141\n",
      "train loss:0.026160908092702714\n",
      "train loss:0.023169227289708716\n",
      "train loss:0.013804834229098131\n",
      "train loss:0.06473792852042055\n",
      "train loss:0.0139241799673916\n",
      "train loss:0.020838391380355686\n",
      "train loss:0.0497409027212124\n",
      "train loss:0.015535227394362519\n",
      "train loss:0.0649391695171658\n",
      "train loss:0.013301347863296543\n",
      "train loss:0.013689922001023792\n",
      "train loss:0.015125989088204022\n",
      "train loss:0.011488127930057414\n",
      "train loss:0.015207665958062949\n",
      "train loss:0.013433809457694153\n",
      "train loss:0.016568109485195423\n",
      "train loss:0.07890621557980537\n",
      "train loss:0.010475589412651485\n",
      "train loss:0.010782847050402002\n",
      "train loss:0.004392265261773599\n",
      "train loss:0.011778132508809429\n",
      "train loss:0.028884534942630925\n",
      "train loss:0.01858556800138797\n",
      "train loss:0.012898229147804571\n",
      "train loss:0.003199936162589439\n",
      "train loss:0.01640598740368497\n",
      "train loss:0.018484751739767193\n",
      "train loss:0.014380205026086107\n",
      "train loss:0.01302903437828408\n",
      "train loss:0.047256959994560095\n",
      "train loss:0.024492209860625058\n",
      "train loss:0.011748266326836176\n",
      "train loss:0.024071041034093233\n",
      "train loss:0.024744819441385145\n",
      "train loss:0.01805907852522853\n",
      "train loss:0.07780262898888111\n",
      "train loss:0.02811685760399264\n",
      "train loss:0.023968574230553544\n",
      "train loss:0.03394091546439524\n",
      "train loss:0.01306805805927707\n",
      "train loss:0.008356702994624281\n",
      "train loss:0.006695394410374039\n",
      "train loss:0.037299483520837\n",
      "train loss:0.014036328199096608\n",
      "train loss:0.033214247260970844\n",
      "train loss:0.035463266469715926\n",
      "train loss:0.003646169175900973\n",
      "train loss:0.01143594380211265\n",
      "train loss:0.018719361268590567\n",
      "train loss:0.0105088978641231\n",
      "train loss:0.012705147892869669\n",
      "train loss:0.015364589206413265\n",
      "train loss:0.06572206615483722\n",
      "train loss:0.027042892138931074\n",
      "train loss:0.008395217304175267\n",
      "train loss:0.016192606323323824\n",
      "train loss:0.0649031692143958\n",
      "train loss:0.06277549119941697\n",
      "train loss:0.01580515374813953\n",
      "train loss:0.02637859079720206\n",
      "train loss:0.0223173894701124\n",
      "train loss:0.009274972199954351\n",
      "train loss:0.06803282805171201\n",
      "train loss:0.016597198379185135\n",
      "train loss:0.013843202167287249\n",
      "train loss:0.010532755639741298\n",
      "train loss:0.008328990003766027\n",
      "train loss:0.030218516144644828\n",
      "train loss:0.02306727348875163\n",
      "train loss:0.022230270484824864\n",
      "train loss:0.021497559526173084\n",
      "train loss:0.016878989962386768\n",
      "train loss:0.008083028016005578\n",
      "train loss:0.007185989297712344\n",
      "train loss:0.04641656932832052\n",
      "train loss:0.01374181331890081\n",
      "train loss:0.03949994335850735\n",
      "train loss:0.014163810289265878\n",
      "train loss:0.014812063162409746\n",
      "train loss:0.008790964275530805\n",
      "train loss:0.006750308942895446\n",
      "train loss:0.03511163906672592\n",
      "train loss:0.015521384983707542\n",
      "train loss:0.005281048920364256\n",
      "train loss:0.050396448593485396\n",
      "train loss:0.02208078055374492\n",
      "train loss:0.08046530141850726\n",
      "train loss:0.009292484451253198\n",
      "train loss:0.038008629052267325\n",
      "train loss:0.006048394235937219\n",
      "train loss:0.0023198150564449575\n",
      "train loss:0.02472105079422458\n",
      "train loss:0.02850656531736915\n",
      "train loss:0.025024220314859152\n",
      "train loss:0.029079751182215587\n",
      "train loss:0.026804703784678908\n",
      "train loss:0.013954862787391269\n",
      "train loss:0.03587257335844362\n",
      "train loss:0.053362298313902025\n",
      "train loss:0.02593167933050828\n",
      "train loss:0.03755633555735155\n",
      "train loss:0.04294969780622143\n",
      "train loss:0.02103347427428289\n",
      "train loss:0.0015362960252324651\n",
      "train loss:0.046854771672748624\n",
      "train loss:0.014010388209020617\n",
      "train loss:0.020466282107216974\n",
      "train loss:0.017992917888389345\n",
      "train loss:0.0122343738287893\n",
      "train loss:0.038714553854371316\n",
      "train loss:0.01400130650183072\n",
      "train loss:0.0478877798972469\n",
      "train loss:0.007663963724283113\n",
      "train loss:0.010072669364838433\n",
      "train loss:0.007885903148848685\n",
      "train loss:0.029271490870305415\n",
      "train loss:0.05951565131618696\n",
      "train loss:0.011648852360430952\n",
      "train loss:0.07692085465519881\n",
      "train loss:0.03389398663616344\n",
      "train loss:0.035396033451319094\n",
      "train loss:0.0069218918343640105\n",
      "train loss:0.004304578956971154\n",
      "train loss:0.00952633546923506\n",
      "train loss:0.03892320481576032\n",
      "train loss:0.0740856865298604\n",
      "train loss:0.027342471283605552\n",
      "train loss:0.017433765486574257\n",
      "train loss:0.0683519932609339\n",
      "train loss:0.044852243420075516\n",
      "train loss:0.020307947218648016\n",
      "train loss:0.04074630552985421\n",
      "train loss:0.04651357164688959\n",
      "train loss:0.019819111408269453\n",
      "train loss:0.011129815425584309\n",
      "train loss:0.04381159611949555\n",
      "train loss:0.0626143699327288\n",
      "train loss:0.008449791003597093\n",
      "train loss:0.0045501511366312225\n",
      "train loss:0.008945498660008148\n",
      "train loss:0.025750823155460997\n",
      "train loss:0.0074819405429633725\n",
      "train loss:0.009336488104816272\n",
      "train loss:0.020896900214575135\n",
      "train loss:0.009879953620997339\n",
      "train loss:0.01073131850883915\n",
      "train loss:0.03177981718342811\n",
      "train loss:0.017805136856554268\n",
      "train loss:0.016823708566594864\n",
      "train loss:0.15870258337308082\n",
      "train loss:0.02041914244364886\n",
      "train loss:0.015287389410110337\n",
      "train loss:0.023978629028949552\n",
      "train loss:0.010159840499232282\n",
      "train loss:0.02843660547556789\n",
      "train loss:0.020988273936603536\n",
      "train loss:0.0179394670283154\n",
      "train loss:0.008229501489835134\n",
      "train loss:0.10050846084166593\n",
      "train loss:0.022171231503880715\n",
      "train loss:0.016908215762180955\n",
      "train loss:0.011701846959641986\n",
      "train loss:0.040055872649539595\n",
      "train loss:0.028958698382522085\n",
      "train loss:0.01791498940604574\n",
      "train loss:0.023868286254277348\n",
      "train loss:0.023901368723150056\n",
      "train loss:0.007244793710204047\n",
      "train loss:0.026733066836810013\n",
      "train loss:0.009862836031474946\n",
      "train loss:0.011618580799775558\n",
      "train loss:0.014605299922169676\n",
      "train loss:0.009314564762163795\n",
      "train loss:0.024464739666360216\n",
      "train loss:0.03163687333682495\n",
      "train loss:0.008840110999439285\n",
      "train loss:0.002468651673190298\n",
      "train loss:0.01671433628473232\n",
      "train loss:0.020421641881350525\n",
      "train loss:0.0017414330419867538\n",
      "train loss:0.009251817994740895\n",
      "train loss:0.0034738242895772462\n",
      "train loss:0.009885212105674878\n",
      "train loss:0.006888031576299255\n",
      "train loss:0.017251289862332854\n",
      "train loss:0.05437493197300766\n",
      "train loss:0.011323898023723362\n",
      "train loss:0.01586196924329098\n",
      "train loss:0.029128766673231114\n",
      "train loss:0.0045188118771477956\n",
      "train loss:0.011293908882441013\n",
      "train loss:0.008112634183021506\n",
      "train loss:0.012518948672287892\n",
      "train loss:0.00952517865670133\n",
      "train loss:0.05102070291826443\n",
      "train loss:0.013575009130491039\n",
      "train loss:0.010815589351497052\n",
      "train loss:0.011844504223278443\n",
      "train loss:0.01523771766881452\n",
      "train loss:0.031257111314771394\n",
      "train loss:0.0056454322919883525\n",
      "train loss:0.05306451111232847\n",
      "train loss:0.017534448516245707\n",
      "train loss:0.010423370467247619\n",
      "train loss:0.01055701559595993\n",
      "train loss:0.08498044165125951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02514368588167442\n",
      "train loss:0.01313760512089532\n",
      "train loss:0.03498544810773904\n",
      "train loss:0.006502952154629141\n",
      "train loss:0.0058926869307325495\n",
      "train loss:0.07653432780454159\n",
      "train loss:0.0047929906771181155\n",
      "train loss:0.012785222882915863\n",
      "train loss:0.014976954930236\n",
      "train loss:0.00537129325392954\n",
      "train loss:0.01488889151992983\n",
      "train loss:0.023585404131046622\n",
      "train loss:0.021089596577543633\n",
      "train loss:0.00818743486543202\n",
      "train loss:0.01093108705717456\n",
      "train loss:0.005585802360370528\n",
      "train loss:0.002623344826385157\n",
      "train loss:0.017124488909411668\n",
      "train loss:0.004359580721779766\n",
      "train loss:0.021823299433731028\n",
      "train loss:0.0032629572852207094\n",
      "train loss:0.028975818322408805\n",
      "train loss:0.0548811860425517\n",
      "train loss:0.019565051475108338\n",
      "train loss:0.03321452043424183\n",
      "train loss:0.010771046067030752\n",
      "train loss:0.013942197215941289\n",
      "train loss:0.008101218976429014\n",
      "train loss:0.02212605228136813\n",
      "train loss:0.029513030768121177\n",
      "train loss:0.02357640448500559\n",
      "train loss:0.03515102413227219\n",
      "train loss:0.004203445582826641\n",
      "train loss:0.008492332014349948\n",
      "train loss:0.004127583482864075\n",
      "train loss:0.012907480746842403\n",
      "train loss:0.018572101422874136\n",
      "train loss:0.010175642977610198\n",
      "train loss:0.02733494820666874\n",
      "train loss:0.022130245555503865\n",
      "train loss:0.05492790061127086\n",
      "train loss:0.007015223928216884\n",
      "train loss:0.0183041451808021\n",
      "train loss:0.02341548983381381\n",
      "train loss:0.009501721876831248\n",
      "train loss:0.02430234482774084\n",
      "train loss:0.0639124274657899\n",
      "train loss:0.06614556079732253\n",
      "train loss:0.05690597525180027\n",
      "train loss:0.01793097399613982\n",
      "train loss:0.012802645212843031\n",
      "train loss:0.026689835726669192\n",
      "train loss:0.013203752052690967\n",
      "train loss:0.007213116862340151\n",
      "train loss:0.007121928395220499\n",
      "train loss:0.018339934368471277\n",
      "train loss:0.01917340610665026\n",
      "train loss:0.005103671913342362\n",
      "train loss:0.011733941768534152\n",
      "train loss:0.03117887541186366\n",
      "train loss:0.002400422407580207\n",
      "train loss:0.0441788364795809\n",
      "train loss:0.022948961569437556\n",
      "train loss:0.022229526602480648\n",
      "train loss:0.008186266949776899\n",
      "train loss:0.006144648422234063\n",
      "train loss:0.02872388589922765\n",
      "train loss:0.039218498295206856\n",
      "train loss:0.03622879358692083\n",
      "train loss:0.013186265295609963\n",
      "train loss:0.0025254124863360976\n",
      "train loss:0.013743481897357128\n",
      "train loss:0.030365659610771333\n",
      "train loss:0.010103123464443437\n",
      "train loss:0.03975767707676999\n",
      "train loss:0.019358152335266124\n",
      "train loss:0.02452234313558728\n",
      "train loss:0.015827088010466825\n",
      "train loss:0.013872920286287789\n",
      "train loss:0.012494494265730705\n",
      "train loss:0.0043945703770619324\n",
      "train loss:0.0012378456142515177\n",
      "train loss:0.018024758817390373\n",
      "train loss:0.022992530739102176\n",
      "train loss:0.0598431795596349\n",
      "train loss:0.010687257769459581\n",
      "train loss:0.007546897193078752\n",
      "train loss:0.09319609502447891\n",
      "train loss:0.011584249118360894\n",
      "train loss:0.01584001944213787\n",
      "train loss:0.014644372527649448\n",
      "train loss:0.00862599201962597\n",
      "train loss:0.023603122067723067\n",
      "train loss:0.08552662927809558\n",
      "train loss:0.043546058694290866\n",
      "train loss:0.11596630891364876\n",
      "train loss:0.008505421177200052\n",
      "train loss:0.010200079205825168\n",
      "train loss:0.017164853730330453\n",
      "train loss:0.012407015775056667\n",
      "train loss:0.09655668401736138\n",
      "train loss:0.004618594875868281\n",
      "train loss:0.0044061594388174925\n",
      "train loss:0.03186074184624184\n",
      "train loss:0.028160945669820123\n",
      "train loss:0.005732781395563633\n",
      "train loss:0.0052521000442757315\n",
      "train loss:0.035400210561619835\n",
      "train loss:0.039985822377957926\n",
      "train loss:0.026152660729278937\n",
      "train loss:0.008826844427256493\n",
      "train loss:0.005225123621326795\n",
      "train loss:0.03303213602749127\n",
      "train loss:0.02697522216903511\n",
      "train loss:0.013021346590189158\n",
      "train loss:0.015934078870375307\n",
      "train loss:0.020322811526205346\n",
      "train loss:0.008026020303790892\n",
      "train loss:0.010076886085142966\n",
      "train loss:0.005112811605671868\n",
      "train loss:0.0031412287872436607\n",
      "train loss:0.04098654831375404\n",
      "train loss:0.008281722049151482\n",
      "train loss:0.013269560526176352\n",
      "train loss:0.004787113421576601\n",
      "train loss:0.1277341439801739\n",
      "train loss:0.035234307083097285\n",
      "train loss:0.004722912622330479\n",
      "train loss:0.004391366515712887\n",
      "train loss:0.012138939184045511\n",
      "train loss:0.014812848631293635\n",
      "train loss:0.01259497628200927\n",
      "train loss:0.11217492785227982\n",
      "train loss:0.02348540019955164\n",
      "train loss:0.0023217458753505248\n",
      "train loss:0.018606243168276443\n",
      "train loss:0.02094525342266323\n",
      "train loss:0.011519350795747074\n",
      "train loss:0.012001680893086574\n",
      "train loss:0.00975695725048614\n",
      "train loss:0.015573907557849764\n",
      "train loss:0.03435148617292652\n",
      "train loss:0.027068576318053067\n",
      "train loss:0.0012884575102373528\n",
      "train loss:0.02638881460769043\n",
      "train loss:0.05109186802550289\n",
      "train loss:0.005427851006752776\n",
      "train loss:0.007453891543627281\n",
      "train loss:0.0493898268270144\n",
      "train loss:0.0046720366889598805\n",
      "train loss:0.03692050764593585\n",
      "train loss:0.01587074838907937\n",
      "train loss:0.06660471539183405\n",
      "train loss:0.02508571642079339\n",
      "train loss:0.030992265524744905\n",
      "train loss:0.0018882155657254103\n",
      "train loss:0.007567277584061285\n",
      "train loss:0.029428299841757453\n",
      "train loss:0.012194923495595516\n",
      "train loss:0.04178278537255371\n",
      "train loss:0.006414383000992872\n",
      "train loss:0.08455881470718168\n",
      "train loss:0.05022891319285314\n",
      "train loss:0.00535919497196701\n",
      "train loss:0.026806075415522\n",
      "train loss:0.046371117358190245\n",
      "train loss:0.0008728740463300551\n",
      "train loss:0.0014335448883201008\n",
      "train loss:0.03667730253974368\n",
      "train loss:0.020261418443086588\n",
      "train loss:0.05639554490886222\n",
      "train loss:0.0026311091501436635\n",
      "train loss:0.003988626678232332\n",
      "train loss:0.020440096551499524\n",
      "train loss:0.0182340463244597\n",
      "train loss:0.020302462149795676\n",
      "train loss:0.03890492966192909\n",
      "train loss:0.03788331943680222\n",
      "train loss:0.011898966500513294\n",
      "train loss:0.005813525019048221\n",
      "train loss:0.0783300589468319\n",
      "train loss:0.0033456653900282855\n",
      "train loss:0.03561433586643902\n",
      "train loss:0.0057983389304757\n",
      "train loss:0.050182686795041634\n",
      "train loss:0.0036581369353440806\n",
      "train loss:0.006044846797172887\n",
      "train loss:0.02812330453360728\n",
      "train loss:0.014902104719312543\n",
      "train loss:0.01318739155136017\n",
      "=== epoch:7, train acc:0.987, test acc:0.979 ===\n",
      "train loss:0.031463377868286346\n",
      "train loss:0.04376630696662857\n",
      "train loss:0.03605599477465518\n",
      "train loss:0.013480532679201254\n",
      "train loss:0.030300236462545996\n",
      "train loss:0.030874809627949338\n",
      "train loss:0.04735851873576828\n",
      "train loss:0.015420383082440361\n",
      "train loss:0.01882887812004603\n",
      "train loss:0.015933806415078786\n",
      "train loss:0.011442272752337643\n",
      "train loss:0.012310297117329293\n",
      "train loss:0.032921091373022376\n",
      "train loss:0.021899007468346388\n",
      "train loss:0.030669688788095156\n",
      "train loss:0.02635856195676255\n",
      "train loss:0.010739764079202267\n",
      "train loss:0.011870664603874748\n",
      "train loss:0.006701786629564836\n",
      "train loss:0.014809065989574466\n",
      "train loss:0.005325780052227916\n",
      "train loss:0.013970387947085711\n",
      "train loss:0.0370991339692349\n",
      "train loss:0.02135395045163607\n",
      "train loss:0.010585755096293137\n",
      "train loss:0.017192477055228753\n",
      "train loss:0.0024970903238943484\n",
      "train loss:0.05710277621526053\n",
      "train loss:0.03214458644728784\n",
      "train loss:0.11197873244272652\n",
      "train loss:0.0022335558161084013\n",
      "train loss:0.011967142343694469\n",
      "train loss:0.008557493181626043\n",
      "train loss:0.017317332927525998\n",
      "train loss:0.01006920278750138\n",
      "train loss:0.009131187743913869\n",
      "train loss:0.024786515184081037\n",
      "train loss:0.02542485278246075\n",
      "train loss:0.017387348403633495\n",
      "train loss:0.015583929260480111\n",
      "train loss:0.08167223958093638\n",
      "train loss:0.01611094412917487\n",
      "train loss:0.01123614108430955\n",
      "train loss:0.010985475264829426\n",
      "train loss:0.010655018232148993\n",
      "train loss:0.058345830943395474\n",
      "train loss:0.01576573905849775\n",
      "train loss:0.04656369826350157\n",
      "train loss:0.0044477656812903915\n",
      "train loss:0.002236247419472566\n",
      "train loss:0.03076556347727011\n",
      "train loss:0.008410572338012241\n",
      "train loss:0.010944683752094985\n",
      "train loss:0.007154001937337424\n",
      "train loss:0.03894376890826309\n",
      "train loss:0.012855781245899787\n",
      "train loss:0.025283740440942882\n",
      "train loss:0.011648655430220927\n",
      "train loss:0.007955629842067024\n",
      "train loss:0.008691233132216874\n",
      "train loss:0.011697571015852882\n",
      "train loss:0.05141148871811367\n",
      "train loss:0.01660948740961465\n",
      "train loss:0.024968540000007377\n",
      "train loss:0.015335109472502145\n",
      "train loss:0.04122859055625174\n",
      "train loss:0.006124741885372042\n",
      "train loss:0.0020234663385957103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004716778882761218\n",
      "train loss:0.02210909672081302\n",
      "train loss:0.010955231034011319\n",
      "train loss:0.017397137251617532\n",
      "train loss:0.02809148292941948\n",
      "train loss:0.0035026105264311207\n",
      "train loss:0.013345364061930922\n",
      "train loss:0.022849681104066443\n",
      "train loss:0.07074882257990064\n",
      "train loss:0.02205657457050184\n",
      "train loss:0.00472638414975365\n",
      "train loss:0.010868406016696874\n",
      "train loss:0.005493207449875152\n",
      "train loss:0.022037056904104704\n",
      "train loss:0.006823936909412999\n",
      "train loss:0.007269781441863397\n",
      "train loss:0.025980801282016505\n",
      "train loss:0.015558217929035738\n",
      "train loss:0.009672610606645678\n",
      "train loss:0.005900627745899346\n",
      "train loss:0.0034442398934966547\n",
      "train loss:0.007018220370625878\n",
      "train loss:0.0062352672358710745\n",
      "train loss:0.007794482025139506\n",
      "train loss:0.007241910303204863\n",
      "train loss:0.014384487860326057\n",
      "train loss:0.022819316631208997\n",
      "train loss:0.03607968166969237\n",
      "train loss:0.012569196303579819\n",
      "train loss:0.016437627269469617\n",
      "train loss:0.0015391525436513891\n",
      "train loss:0.01048623626165527\n",
      "train loss:0.008775699097483915\n",
      "train loss:0.014542725138028463\n",
      "train loss:0.04624607113279061\n",
      "train loss:0.027363363662600563\n",
      "train loss:0.004085225480102936\n",
      "train loss:0.004978511186695822\n",
      "train loss:0.014961697750998737\n",
      "train loss:0.021686251139087544\n",
      "train loss:0.061596010406045794\n",
      "train loss:0.007542796670595788\n",
      "train loss:0.07783708510002937\n",
      "train loss:0.04712338136401513\n",
      "train loss:0.007275353836990016\n",
      "train loss:0.0029950472801191143\n",
      "train loss:0.026498448794613827\n",
      "train loss:0.004176529321765312\n",
      "train loss:0.012912707657666974\n",
      "train loss:0.021592928219362654\n",
      "train loss:0.01667906474043989\n",
      "train loss:0.030033719981713992\n",
      "train loss:0.02219015399339941\n",
      "train loss:0.031769080863222075\n",
      "train loss:0.007426637505395143\n",
      "train loss:0.023163728068176726\n",
      "train loss:0.018694028941302145\n",
      "train loss:0.012018548561675564\n",
      "train loss:0.15218507669129708\n",
      "train loss:0.01430754534984137\n",
      "train loss:0.026328353673808036\n",
      "train loss:0.03221944284907157\n",
      "train loss:0.019997133792400094\n",
      "train loss:0.011273194297942995\n",
      "train loss:0.06065075546001768\n",
      "train loss:0.022609540124881155\n",
      "train loss:0.008511761948267742\n",
      "train loss:0.00814630021145288\n",
      "train loss:0.01637145420439433\n",
      "train loss:0.02932635541088005\n",
      "train loss:0.02086953554958423\n",
      "train loss:0.05351431459291527\n",
      "train loss:0.039561945649243146\n",
      "train loss:0.0021001974669150477\n",
      "train loss:0.03448079620194472\n",
      "train loss:0.02744364589807074\n",
      "train loss:0.006835571187492245\n",
      "train loss:0.012293915593877512\n",
      "train loss:0.009089027216541567\n",
      "train loss:0.010710935867567977\n",
      "train loss:0.02572691667547582\n",
      "train loss:0.03678535432807042\n",
      "train loss:0.0384994054880299\n",
      "train loss:0.07832733764894267\n",
      "train loss:0.012260036822159653\n",
      "train loss:0.020697429449372293\n",
      "train loss:0.024509163011099126\n",
      "train loss:0.023774850768119693\n",
      "train loss:0.011768562125001976\n",
      "train loss:0.03623802035535507\n",
      "train loss:0.007248359676336076\n",
      "train loss:0.03430116362293167\n",
      "train loss:0.014173181789051333\n",
      "train loss:0.023181338812688006\n",
      "train loss:0.001989756196640172\n",
      "train loss:0.05725041131896178\n",
      "train loss:0.0013818543632980306\n",
      "train loss:0.02114173222596452\n",
      "train loss:0.025815636894331445\n",
      "train loss:0.03785257652670666\n",
      "train loss:0.014320343202747056\n",
      "train loss:0.0018979977836356228\n",
      "train loss:0.015076808434616017\n",
      "train loss:0.01039417814922729\n",
      "train loss:0.00844838435512492\n",
      "train loss:0.0023104059171401487\n",
      "train loss:0.011178692412551261\n",
      "train loss:0.0032287387532378368\n",
      "train loss:0.030945352996442382\n",
      "train loss:0.010362789128409954\n",
      "train loss:0.02032950813067141\n",
      "train loss:0.026053124555093635\n",
      "train loss:0.0034177555037915334\n",
      "train loss:0.04023278053957209\n",
      "train loss:0.0506501839132176\n",
      "train loss:0.03602174458326367\n",
      "train loss:0.02039442308960926\n",
      "train loss:0.032801751572389314\n",
      "train loss:0.020468187909481145\n",
      "train loss:0.020965553771598016\n",
      "train loss:0.01400633882804039\n",
      "train loss:0.01872776408959673\n",
      "train loss:0.010806943056876827\n",
      "train loss:0.05865509610746995\n",
      "train loss:0.03522503358216221\n",
      "train loss:0.019633099971754803\n",
      "train loss:0.028714320362548267\n",
      "train loss:0.07782124750292185\n",
      "train loss:0.026152990281224312\n",
      "train loss:0.02559603695534535\n",
      "train loss:0.03251548353851002\n",
      "train loss:0.015519915343362434\n",
      "train loss:0.008737682399024222\n",
      "train loss:0.019257238208439734\n",
      "train loss:0.0461232623340844\n",
      "train loss:0.007853287869942945\n",
      "train loss:0.004551310916490637\n",
      "train loss:0.007611921321874972\n",
      "train loss:0.0025137782045811757\n",
      "train loss:0.01828946994862994\n",
      "train loss:0.0069280356293585175\n",
      "train loss:0.03238338942872444\n",
      "train loss:0.004890650128553341\n",
      "train loss:0.08194884737801544\n",
      "train loss:0.012929599769838786\n",
      "train loss:0.025686588030846197\n",
      "train loss:0.001589101093943042\n",
      "train loss:0.038101316720773645\n",
      "train loss:0.0066233743804538555\n",
      "train loss:0.019815350020291368\n",
      "train loss:0.0062571698693962615\n",
      "train loss:0.004084367582085116\n",
      "train loss:0.016585418431843805\n",
      "train loss:0.005509898187309674\n",
      "train loss:0.005992459544218748\n",
      "train loss:0.021818331738415516\n",
      "train loss:0.009833557102839794\n",
      "train loss:0.01923915985110691\n",
      "train loss:0.02491222077346861\n",
      "train loss:0.01927481216467802\n",
      "train loss:0.0032586451793322176\n",
      "train loss:0.020407902056849787\n",
      "train loss:0.00692803398432496\n",
      "train loss:0.007308159931459719\n",
      "train loss:0.013589588548434067\n",
      "train loss:0.05335351277211282\n",
      "train loss:0.02010747500894107\n",
      "train loss:0.027282979549269254\n",
      "train loss:0.08535967121277283\n",
      "train loss:0.008102728164805818\n",
      "train loss:0.02753989973235918\n",
      "train loss:0.014856173111437044\n",
      "train loss:0.036797417465953004\n",
      "train loss:0.010466868497694798\n",
      "train loss:0.04321893775354538\n",
      "train loss:0.009671522716032945\n",
      "train loss:0.012780263204808889\n",
      "train loss:0.02010103765471845\n",
      "train loss:0.008975440633263722\n",
      "train loss:0.008114447370227214\n",
      "train loss:0.00669061894224415\n",
      "train loss:0.055080831173149235\n",
      "train loss:0.01583579085297456\n",
      "train loss:0.036319036795099124\n",
      "train loss:0.03873082147924511\n",
      "train loss:0.020882247180956392\n",
      "train loss:0.001698112116499173\n",
      "train loss:0.011299721326789048\n",
      "train loss:0.02964816043859742\n",
      "train loss:0.01822045141784825\n",
      "train loss:0.010811709731771195\n",
      "train loss:0.039162678573005226\n",
      "train loss:0.0310150876316804\n",
      "train loss:0.07583914127440598\n",
      "train loss:0.007189586819629373\n",
      "train loss:0.002447113374453155\n",
      "train loss:0.0043276693607704605\n",
      "train loss:0.014910323509799808\n",
      "train loss:0.006563522926493237\n",
      "train loss:0.024718879280173196\n",
      "train loss:0.018560455587595982\n",
      "train loss:0.010520847386892235\n",
      "train loss:0.01028811493429461\n",
      "train loss:0.04151122691728868\n",
      "train loss:0.01573579291745125\n",
      "train loss:0.020598533552668143\n",
      "train loss:0.015934418566462594\n",
      "train loss:0.08196327827302007\n",
      "train loss:0.0060297933825550435\n",
      "train loss:0.04834161313528717\n",
      "train loss:0.014629970665416799\n",
      "train loss:0.02357596577456181\n",
      "train loss:0.008141309971045672\n",
      "train loss:0.010801190891671223\n",
      "train loss:0.00922615346865015\n",
      "train loss:0.014549197660865897\n",
      "train loss:0.010783681930842344\n",
      "train loss:0.012308048522714294\n",
      "train loss:0.010678104678559015\n",
      "train loss:0.005260385761503593\n",
      "train loss:0.008330678632483228\n",
      "train loss:0.009696334213997177\n",
      "train loss:0.026764694138863402\n",
      "train loss:0.02655111058039026\n",
      "train loss:0.004514585162013097\n",
      "train loss:0.0025187906301693905\n",
      "train loss:0.01335754438548369\n",
      "train loss:0.01801854510493755\n",
      "train loss:0.016946560452439783\n",
      "train loss:0.045563506224237986\n",
      "train loss:0.06963811142590835\n",
      "train loss:0.005823013036845282\n",
      "train loss:0.005485944703554719\n",
      "train loss:0.01865321601181938\n",
      "train loss:0.04842686971654029\n",
      "train loss:0.003611280992122631\n",
      "train loss:0.0023447601634394417\n",
      "train loss:0.005217128029811811\n",
      "train loss:0.1183290484168803\n",
      "train loss:0.03401835641665059\n",
      "train loss:0.01514691509596921\n",
      "train loss:0.011249106243311189\n",
      "train loss:0.016774905037608867\n",
      "train loss:0.00482230854785994\n",
      "train loss:0.014440244525102133\n",
      "train loss:0.007018597232701809\n",
      "train loss:0.015625046780590245\n",
      "train loss:0.016863412006647614\n",
      "train loss:0.01168697020857689\n",
      "train loss:0.015895516860385244\n",
      "train loss:0.04275485780192187\n",
      "train loss:0.03571209352430488\n",
      "train loss:0.007617641911888017\n",
      "train loss:0.007722080128133975\n",
      "train loss:0.004379733426328647\n",
      "train loss:0.006168148824283328\n",
      "train loss:0.003798807242256223\n",
      "train loss:0.0041233299420718635\n",
      "train loss:0.013384742643982296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.012965641408267677\n",
      "train loss:0.010113959101169858\n",
      "train loss:0.004209913439382621\n",
      "train loss:0.004618579382267621\n",
      "train loss:0.015551226056775953\n",
      "train loss:0.00914109890905486\n",
      "train loss:0.008806086393520941\n",
      "train loss:0.0016803924532372968\n",
      "train loss:0.03595490303138532\n",
      "train loss:0.00697695865650613\n",
      "train loss:0.007518590180302323\n",
      "train loss:0.007736119340105071\n",
      "train loss:0.014095292195537465\n",
      "train loss:0.04845753322856754\n",
      "train loss:0.011612523582488252\n",
      "train loss:0.014724524798962508\n",
      "train loss:0.02923608408163424\n",
      "train loss:0.004144938246189805\n",
      "train loss:0.004002591439990549\n",
      "train loss:0.0037044377214526304\n",
      "train loss:0.012171283557617561\n",
      "train loss:0.03858138255553349\n",
      "train loss:0.009558606715315976\n",
      "train loss:0.0016908308921794605\n",
      "train loss:0.014120406450899908\n",
      "train loss:0.0125978973923117\n",
      "train loss:0.0015144249561794684\n",
      "train loss:0.008025498828651159\n",
      "train loss:0.004669239795634202\n",
      "train loss:0.012098130795431155\n",
      "train loss:0.01739435711811561\n",
      "train loss:0.017357649296218785\n",
      "train loss:0.02151992106498558\n",
      "train loss:0.01815641583163341\n",
      "train loss:0.0185598987637681\n",
      "train loss:0.00383582789286198\n",
      "train loss:0.029628404393922073\n",
      "train loss:0.0027114985645892518\n",
      "train loss:0.023202190132519725\n",
      "train loss:0.011127800555365736\n",
      "train loss:0.004740520456912064\n",
      "train loss:0.0040231025472140655\n",
      "train loss:0.03645383402251915\n",
      "train loss:0.007957333595675499\n",
      "train loss:0.002633116581111146\n",
      "train loss:0.015033576079833222\n",
      "train loss:0.028217524035363963\n",
      "train loss:0.02894488155368404\n",
      "train loss:0.004178718082081027\n",
      "train loss:0.0022862314002641965\n",
      "train loss:0.004985740737872607\n",
      "train loss:0.01282197142885391\n",
      "train loss:0.07414935377733416\n",
      "train loss:0.02979201516820042\n",
      "train loss:0.016217404688877925\n",
      "train loss:0.0033580069967809483\n",
      "train loss:0.0026801566293495945\n",
      "train loss:0.009662593461695302\n",
      "train loss:0.01852331819825035\n",
      "train loss:0.001607777967497649\n",
      "train loss:0.005861837472041203\n",
      "train loss:0.00658431830109392\n",
      "train loss:0.004636768841000242\n",
      "train loss:0.0011016784923946652\n",
      "train loss:0.002319347813315541\n",
      "train loss:0.022812017744452774\n",
      "train loss:0.017310344599658477\n",
      "train loss:0.006060719027704104\n",
      "train loss:0.02064622097877171\n",
      "train loss:0.0050078697574033795\n",
      "train loss:0.02610167894358198\n",
      "train loss:0.012267044061714649\n",
      "train loss:0.012857004473525857\n",
      "train loss:0.0022178082960822155\n",
      "train loss:0.008358343928518175\n",
      "train loss:0.020958869787385793\n",
      "train loss:0.019415029345562447\n",
      "train loss:0.012812112046674434\n",
      "train loss:0.00334194723206543\n",
      "train loss:0.002407092811883881\n",
      "train loss:0.005389509315924834\n",
      "train loss:0.017422519133939746\n",
      "train loss:0.007116699170132134\n",
      "train loss:0.043115645407990816\n",
      "train loss:0.021955762732807763\n",
      "train loss:0.00911687179785298\n",
      "train loss:0.001120536167680707\n",
      "train loss:0.07647595592826895\n",
      "train loss:0.03932966556039552\n",
      "train loss:0.026524396028685514\n",
      "train loss:0.042323713073870194\n",
      "train loss:0.006402283369400567\n",
      "train loss:0.006322585415824727\n",
      "train loss:0.004293427278378415\n",
      "train loss:0.030454019586838698\n",
      "train loss:0.011210241160316315\n",
      "train loss:0.005428773879695307\n",
      "train loss:0.009664324014186184\n",
      "train loss:0.003070233410827796\n",
      "train loss:0.009382152351329083\n",
      "train loss:0.004644895543364125\n",
      "train loss:0.012352969393177364\n",
      "train loss:0.009280910127228075\n",
      "train loss:0.0032518255903836997\n",
      "train loss:0.004642493995652668\n",
      "train loss:0.004291532956248785\n",
      "train loss:0.005247474146488164\n",
      "train loss:0.013070842795629931\n",
      "train loss:0.03130004442279942\n",
      "train loss:0.004528123976733527\n",
      "train loss:0.006574431169721352\n",
      "train loss:0.002135550860382717\n",
      "train loss:0.0021704062875459525\n",
      "train loss:0.003054989769703951\n",
      "train loss:0.005314802283531681\n",
      "train loss:0.0031841714728476312\n",
      "train loss:0.004742178329998739\n",
      "train loss:0.007556930013338823\n",
      "train loss:0.048321751912026666\n",
      "train loss:0.0057067939434733185\n",
      "train loss:0.006750120206450295\n",
      "train loss:0.029009575211644763\n",
      "train loss:0.015836698569254307\n",
      "train loss:0.0025405649899016016\n",
      "train loss:0.007945172555395837\n",
      "train loss:0.0027506153694058988\n",
      "train loss:0.009647608350172364\n",
      "train loss:0.053355077576124926\n",
      "train loss:0.06488842613117464\n",
      "train loss:0.00424333040817275\n",
      "train loss:0.023736852647604115\n",
      "train loss:0.005203696877358585\n",
      "train loss:0.10056783924231416\n",
      "train loss:0.011168961916457332\n",
      "train loss:0.11106128371786694\n",
      "train loss:0.03590864971372458\n",
      "train loss:0.011156038398783904\n",
      "train loss:0.006164003462309911\n",
      "train loss:0.0064405532279393374\n",
      "train loss:0.038861948375802674\n",
      "train loss:0.02264595773674785\n",
      "train loss:0.0022626849971009643\n",
      "train loss:0.016646199312064527\n",
      "train loss:0.019868333086986538\n",
      "train loss:0.0093194435430281\n",
      "train loss:0.022891967368024714\n",
      "train loss:0.03143216620329331\n",
      "train loss:0.006008585264141454\n",
      "train loss:0.009625057456501548\n",
      "train loss:0.016113104236347223\n",
      "train loss:0.009399753356603016\n",
      "train loss:0.019248310055954742\n",
      "train loss:0.036271984392058546\n",
      "train loss:0.01203021368205326\n",
      "train loss:0.01986006650894931\n",
      "train loss:0.013065640451654165\n",
      "train loss:0.010657821922160518\n",
      "train loss:0.0031808062799690267\n",
      "train loss:0.02330509547971453\n",
      "train loss:0.007169593486971518\n",
      "train loss:0.021903910803566577\n",
      "train loss:0.0333195743477112\n",
      "train loss:0.011520742555342038\n",
      "train loss:0.03394962039632309\n",
      "train loss:0.009243556875947365\n",
      "train loss:0.0012862120229581572\n",
      "train loss:0.05342926991288853\n",
      "train loss:0.015657911711379063\n",
      "train loss:0.040007354246807764\n",
      "train loss:0.08689753969387784\n",
      "train loss:0.018213833720237892\n",
      "train loss:0.015203466595450814\n",
      "train loss:0.010653328240071267\n",
      "train loss:0.03543761902469377\n",
      "train loss:0.0724657619373348\n",
      "train loss:0.010578171231892046\n",
      "train loss:0.028450246268500144\n",
      "train loss:0.01251465419587675\n",
      "train loss:0.007205841053126275\n",
      "train loss:0.017783421128848766\n",
      "train loss:0.009401005141843093\n",
      "train loss:0.053091804531398515\n",
      "train loss:0.08311333801054901\n",
      "train loss:0.010412542523428223\n",
      "train loss:0.007987571096115588\n",
      "train loss:0.007923193623954598\n",
      "train loss:0.012686383940315292\n",
      "train loss:0.02126305144347421\n",
      "train loss:0.02730453637982958\n",
      "train loss:0.009539972428631454\n",
      "train loss:0.010203892448784896\n",
      "train loss:0.016887685046473103\n",
      "train loss:0.04102753010484995\n",
      "train loss:0.018331870482502025\n",
      "train loss:0.013403229971941755\n",
      "train loss:0.05087567298659573\n",
      "train loss:0.014907474266687227\n",
      "train loss:0.012187993722529355\n",
      "train loss:0.009352580226159389\n",
      "train loss:0.009003543157457935\n",
      "train loss:0.04952815909316357\n",
      "train loss:0.005005941795374208\n",
      "train loss:0.006842143977704917\n",
      "train loss:0.001851335162396372\n",
      "train loss:0.0069179421720299535\n",
      "train loss:0.0054829785918398795\n",
      "train loss:0.009878709778792518\n",
      "train loss:0.005411220007313366\n",
      "train loss:0.014084627705345274\n",
      "train loss:0.014099370964095961\n",
      "train loss:0.010620316561819287\n",
      "train loss:0.0073507786750876955\n",
      "train loss:0.016056186380394032\n",
      "train loss:0.011287857906308395\n",
      "train loss:0.001334292417795977\n",
      "train loss:0.004891432244109841\n",
      "train loss:0.021625329603784625\n",
      "train loss:0.0034922352386852155\n",
      "train loss:0.0017787146787009624\n",
      "train loss:0.008419354782511157\n",
      "train loss:0.03943264771978778\n",
      "train loss:0.01775566959959342\n",
      "train loss:0.010821479720259439\n",
      "train loss:0.0020960596530991203\n",
      "train loss:0.010474670330955378\n",
      "train loss:0.05569933890525075\n",
      "train loss:0.030717985448321144\n",
      "train loss:0.010759636981689462\n",
      "train loss:0.029786480901364046\n",
      "train loss:0.028158492568201344\n",
      "train loss:0.02097541586516705\n",
      "train loss:0.006482008362258245\n",
      "train loss:0.010103035504028279\n",
      "train loss:0.006974608786999787\n",
      "train loss:0.013755906570180948\n",
      "train loss:0.011188534244513236\n",
      "train loss:0.004688055547808625\n",
      "train loss:0.008221459557563987\n",
      "train loss:0.008079242607527442\n",
      "train loss:0.00485972123156786\n",
      "train loss:0.005362636422791538\n",
      "train loss:0.004143543894664676\n",
      "train loss:0.014381898970147028\n",
      "train loss:0.0034095937215840627\n",
      "train loss:0.00541241844659646\n",
      "train loss:0.022396162299285077\n",
      "train loss:0.026598419421348378\n",
      "train loss:0.004171517815212556\n",
      "train loss:0.010131862025704352\n",
      "train loss:0.010521074131714653\n",
      "train loss:0.043704660673950436\n",
      "train loss:0.00589088718011951\n",
      "train loss:0.01723469511964052\n",
      "train loss:0.028182303623262513\n",
      "train loss:0.03216685150726345\n",
      "train loss:0.007935151230833363\n",
      "train loss:0.005506084577743531\n",
      "train loss:0.05929609525913237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0023864557357447225\n",
      "train loss:0.005802065678927564\n",
      "train loss:0.032700244183847704\n",
      "train loss:0.013183910529639891\n",
      "train loss:0.08320364048635304\n",
      "train loss:0.01369261839122542\n",
      "train loss:0.04435874853928845\n",
      "train loss:0.0627656787158138\n",
      "train loss:0.03689136260591435\n",
      "train loss:0.005038079770530627\n",
      "train loss:0.05421754566849759\n",
      "train loss:0.003208075363415228\n",
      "train loss:0.003569945576583019\n",
      "train loss:0.028262981503489503\n",
      "train loss:0.043899154830814566\n",
      "=== epoch:8, train acc:0.988, test acc:0.98 ===\n",
      "train loss:0.019968490825388027\n",
      "train loss:0.010330808647634677\n",
      "train loss:0.16385693138432791\n",
      "train loss:0.006927344286802899\n",
      "train loss:0.008842778306021282\n",
      "train loss:0.013729542057820484\n",
      "train loss:0.10816026520163695\n",
      "train loss:0.010211607119072673\n",
      "train loss:0.01802666659564194\n",
      "train loss:0.015142743381216765\n",
      "train loss:0.013440556947771133\n",
      "train loss:0.005870906230955478\n",
      "train loss:0.05837745226617153\n",
      "train loss:0.13338870274297965\n",
      "train loss:0.0062437852401508245\n",
      "train loss:0.012367166285455344\n",
      "train loss:0.025218616665736673\n",
      "train loss:0.01638088382931317\n",
      "train loss:0.0032457984597032835\n",
      "train loss:0.013864117627028237\n",
      "train loss:0.014583536704063553\n",
      "train loss:0.011737504008069832\n",
      "train loss:0.03903510983150966\n",
      "train loss:0.06015861304509671\n",
      "train loss:0.024169618311938063\n",
      "train loss:0.026040749897265684\n",
      "train loss:0.004708417881454159\n",
      "train loss:0.07428183294733458\n",
      "train loss:0.0016981355984823753\n",
      "train loss:0.008852784661214608\n",
      "train loss:0.009189959271442309\n",
      "train loss:0.006686305635062711\n",
      "train loss:0.00866349881289682\n",
      "train loss:0.009421621001578485\n",
      "train loss:0.04543334155725109\n",
      "train loss:0.0066028247809843885\n",
      "train loss:0.007150877895015592\n",
      "train loss:0.006870874916085644\n",
      "train loss:0.01936868389484382\n",
      "train loss:0.0126645691590462\n",
      "train loss:0.005990394803150389\n",
      "train loss:0.017588401711867638\n",
      "train loss:0.017968702485871534\n",
      "train loss:0.024262535150358953\n",
      "train loss:0.004953801909411234\n",
      "train loss:0.032616302729550475\n",
      "train loss:0.014069620526062232\n",
      "train loss:0.007012388743670503\n",
      "train loss:0.027437726808248613\n",
      "train loss:0.00564384073243313\n",
      "train loss:0.0024575322984517105\n",
      "train loss:0.046696725670957846\n",
      "train loss:0.042595815372995956\n",
      "train loss:0.01098789411899746\n",
      "train loss:0.011775594651623445\n",
      "train loss:0.0049523764753494435\n",
      "train loss:0.007727823590802054\n",
      "train loss:0.011672098611703905\n",
      "train loss:0.012757108922562665\n",
      "train loss:0.012283696083657219\n",
      "train loss:0.024764663487327122\n",
      "train loss:0.004326600247423436\n",
      "train loss:0.004267866225629188\n",
      "train loss:0.021920179460072874\n",
      "train loss:0.01338116042090889\n",
      "train loss:0.007860038288656914\n",
      "train loss:0.006632740994172866\n",
      "train loss:0.0025803517270833526\n",
      "train loss:0.010862482904794447\n",
      "train loss:0.005210401252119721\n",
      "train loss:0.02432034118812479\n",
      "train loss:0.00833280244093903\n",
      "train loss:0.013717617785984008\n",
      "train loss:0.03296594914164429\n",
      "train loss:0.021704623528048982\n",
      "train loss:0.023613195160829853\n",
      "train loss:0.007132415791923462\n",
      "train loss:0.018062433502219054\n",
      "train loss:0.031379202559689914\n",
      "train loss:0.03833546847318113\n",
      "train loss:0.016324123697826962\n",
      "train loss:0.018075167792710223\n",
      "train loss:0.00238423178522346\n",
      "train loss:0.0023136188164347158\n",
      "train loss:0.012658911732751871\n",
      "train loss:0.007145149682879853\n",
      "train loss:0.001367475397243631\n",
      "train loss:0.00859898969093153\n",
      "train loss:0.008828333905751674\n",
      "train loss:0.008198546996665133\n",
      "train loss:0.05508813009980011\n",
      "train loss:0.005352521264719415\n",
      "train loss:0.0258141749672174\n",
      "train loss:0.019554507231158546\n",
      "train loss:0.010737068899906275\n",
      "train loss:0.040182354126685575\n",
      "train loss:0.00473178206945786\n",
      "train loss:0.011455775569145753\n",
      "train loss:0.017265374768389408\n",
      "train loss:0.004473172681004586\n",
      "train loss:0.003145974518327715\n",
      "train loss:0.01623349600895994\n",
      "train loss:0.010956735004304996\n",
      "train loss:0.0208563931209141\n",
      "train loss:0.01730531119497204\n",
      "train loss:0.00606039398240947\n",
      "train loss:0.020541224168760915\n",
      "train loss:0.02465962225894155\n",
      "train loss:0.005858395525193243\n",
      "train loss:0.004826562752461363\n",
      "train loss:0.024482000187563076\n",
      "train loss:0.030665841286503258\n",
      "train loss:0.0034478844232346843\n",
      "train loss:0.010177760294787343\n",
      "train loss:0.0006833080493058584\n",
      "train loss:0.06092630842488747\n",
      "train loss:0.03707626518226171\n",
      "train loss:0.036893549162835104\n",
      "train loss:0.02609061174802534\n",
      "train loss:0.0071841541215965435\n",
      "train loss:0.02030679386477469\n",
      "train loss:0.012015665256633471\n",
      "train loss:0.012896081044431598\n",
      "train loss:0.03520806894221019\n",
      "train loss:0.013728847004402252\n",
      "train loss:0.01346676112262202\n",
      "train loss:0.020858978845737876\n",
      "train loss:0.016718140866123672\n",
      "train loss:0.037867663356456784\n",
      "train loss:0.003744977150954392\n",
      "train loss:0.022026789233013055\n",
      "train loss:0.024373612144292484\n",
      "train loss:0.002589201791980146\n",
      "train loss:0.005290824808647842\n",
      "train loss:0.005298359255822698\n",
      "train loss:0.0039347553348997606\n",
      "train loss:0.013760207972185882\n",
      "train loss:0.02103390053058134\n",
      "train loss:0.0028116342681478246\n",
      "train loss:0.02552425791425901\n",
      "train loss:0.006327640458975398\n",
      "train loss:0.004396196299266894\n",
      "train loss:0.007370335902995688\n",
      "train loss:0.055986539008273536\n",
      "train loss:0.00807185015460497\n",
      "train loss:0.03703201213943313\n",
      "train loss:0.0029459936752640964\n",
      "train loss:0.011433018753656701\n",
      "train loss:0.017189027553347863\n",
      "train loss:0.014293813715752359\n",
      "train loss:0.046911330421493924\n",
      "train loss:0.006119686616535263\n",
      "train loss:0.06780741456266179\n",
      "train loss:0.0321644590319559\n",
      "train loss:0.00839426853719423\n",
      "train loss:0.006282288676416464\n",
      "train loss:0.012622213663623913\n",
      "train loss:0.08743817284028356\n",
      "train loss:0.006503376009390969\n",
      "train loss:0.0064495584906154\n",
      "train loss:0.015334244633995386\n",
      "train loss:0.0011549774432800775\n",
      "train loss:0.005585701336031681\n",
      "train loss:0.007984434211928544\n",
      "train loss:0.032896360728092794\n",
      "train loss:0.0008806342191058761\n",
      "train loss:0.04154737155206455\n",
      "train loss:0.015673337037731844\n",
      "train loss:0.010215475213090878\n",
      "train loss:0.0129006253541371\n",
      "train loss:0.01095905240676394\n",
      "train loss:0.004650145722558085\n",
      "train loss:0.009042960679945413\n",
      "train loss:0.007498658497012727\n",
      "train loss:0.0075263429797921754\n",
      "train loss:0.006663911591886888\n",
      "train loss:0.004272300746955602\n",
      "train loss:0.020858263805895637\n",
      "train loss:0.004440531486239487\n",
      "train loss:0.005342029066343381\n",
      "train loss:0.007430012553108655\n",
      "train loss:0.007018105367779564\n",
      "train loss:0.0015472777874554757\n",
      "train loss:0.021551236864660272\n",
      "train loss:0.01631416201501512\n",
      "train loss:0.008285926811198397\n",
      "train loss:0.03264742751959873\n",
      "train loss:0.003281261962637002\n",
      "train loss:0.00255288781893384\n",
      "train loss:0.016356143099557668\n",
      "train loss:0.009347239261193713\n",
      "train loss:0.01977896175745809\n",
      "train loss:0.00565738715197271\n",
      "train loss:0.05082958150999145\n",
      "train loss:0.008815942801206074\n",
      "train loss:0.005528973699232078\n",
      "train loss:0.00627780664992136\n",
      "train loss:0.012932676139125618\n",
      "train loss:0.04159570674874582\n",
      "train loss:0.013810578541472805\n",
      "train loss:0.0040889574919838875\n",
      "train loss:0.0022649081378751036\n",
      "train loss:0.020140923142023596\n",
      "train loss:0.010018780705148125\n",
      "train loss:0.0023675016074279544\n",
      "train loss:0.00804899725124476\n",
      "train loss:0.020930030076695423\n",
      "train loss:0.0112384182190193\n",
      "train loss:0.04215372947203727\n",
      "train loss:0.026541154618351288\n",
      "train loss:0.0063342646539267244\n",
      "train loss:0.014310269170347006\n",
      "train loss:0.01945019996199568\n",
      "train loss:0.13660428802656865\n",
      "train loss:0.00583571907334006\n",
      "train loss:0.019516399927795955\n",
      "train loss:0.004173050076002779\n",
      "train loss:0.00283108606683097\n",
      "train loss:0.006842931075025157\n",
      "train loss:0.00219842981380456\n",
      "train loss:0.005108131675332344\n",
      "train loss:0.016374516240742428\n",
      "train loss:0.008387803539940404\n",
      "train loss:0.01190171750360124\n",
      "train loss:0.0017175969207871625\n",
      "train loss:0.021632025021756488\n",
      "train loss:0.007297490465629133\n",
      "train loss:0.0051044501204188\n",
      "train loss:0.0027174420552341307\n",
      "train loss:0.019447132921355147\n",
      "train loss:0.00861561939073935\n",
      "train loss:0.01269512256050019\n",
      "train loss:0.004056848491267636\n",
      "train loss:0.019598935851802782\n",
      "train loss:0.055614528711537776\n",
      "train loss:0.06327697369450606\n",
      "train loss:0.023805211185445204\n",
      "train loss:0.008085231210091588\n",
      "train loss:0.011342065356240678\n",
      "train loss:0.09488615352864584\n",
      "train loss:0.02505449879365301\n",
      "train loss:0.010737660787606344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04312553580492842\n",
      "train loss:0.016201683153086108\n",
      "train loss:0.010966757437524035\n",
      "train loss:0.011405932979363168\n",
      "train loss:0.005734574620511544\n",
      "train loss:0.0024101317657861023\n",
      "train loss:0.00873463277201456\n",
      "train loss:0.008193208897514735\n",
      "train loss:0.01277981042911731\n",
      "train loss:0.01589691345179915\n",
      "train loss:0.00619808917724728\n",
      "train loss:0.006079991143397134\n",
      "train loss:0.0013542579635941194\n",
      "train loss:0.01825331662265307\n",
      "train loss:0.04297140254696047\n",
      "train loss:0.012219813686540742\n",
      "train loss:0.00876895589071244\n",
      "train loss:0.0028473072338673845\n",
      "train loss:0.002888765597719922\n",
      "train loss:0.011353295470000947\n",
      "train loss:0.010347802422784502\n",
      "train loss:0.01284082329840683\n",
      "train loss:0.008939838044197082\n",
      "train loss:0.038387105347077594\n",
      "train loss:0.0019027457010047395\n",
      "train loss:0.009233267090407307\n",
      "train loss:0.005186456970873038\n",
      "train loss:0.011200775166423893\n",
      "train loss:0.014607213231700455\n",
      "train loss:0.0020517251989212067\n",
      "train loss:0.021005478982000197\n",
      "train loss:0.009514756018808433\n",
      "train loss:0.0022270106360349263\n",
      "train loss:0.02535815070108118\n",
      "train loss:0.04363688137083857\n",
      "train loss:0.004896731236468771\n",
      "train loss:0.005486885274265876\n",
      "train loss:0.02496890139701778\n",
      "train loss:0.0065893224790062755\n",
      "train loss:0.02190321994249563\n",
      "train loss:0.002387465096598575\n",
      "train loss:0.013591522618512153\n",
      "train loss:0.0022281282549693427\n",
      "train loss:0.0041153652456383015\n",
      "train loss:0.014012599938284787\n",
      "train loss:0.0348874482065666\n",
      "train loss:0.0031373864412045844\n",
      "train loss:0.0030519558007112407\n",
      "train loss:0.007771937023776968\n",
      "train loss:0.0015145300478875993\n",
      "train loss:0.004612681686990449\n",
      "train loss:0.003082131968379291\n",
      "train loss:0.024629454824919805\n",
      "train loss:0.009820942193411819\n",
      "train loss:0.006162051347343506\n",
      "train loss:0.004696633638331974\n",
      "train loss:0.003829808783239268\n",
      "train loss:0.02936422822688819\n",
      "train loss:0.029418047594250377\n",
      "train loss:0.0033614161722837405\n",
      "train loss:0.015905799514637848\n",
      "train loss:0.006926242184547309\n",
      "train loss:0.007184167123134943\n",
      "train loss:0.04363504065290799\n",
      "train loss:0.02882234242087028\n",
      "train loss:0.013234059155105142\n",
      "train loss:0.014579695275527311\n",
      "train loss:0.016297002853953798\n",
      "train loss:0.00860803847943528\n",
      "train loss:0.010781636748119725\n",
      "train loss:0.03337404303447147\n",
      "train loss:0.010401880425829811\n",
      "train loss:0.0015527519583772777\n",
      "train loss:0.0038925290315339335\n",
      "train loss:0.011627999983236222\n",
      "train loss:0.007616160121863781\n",
      "train loss:0.009727207375683673\n",
      "train loss:0.00406643227888636\n",
      "train loss:0.005084592971324068\n",
      "train loss:0.06578682890073866\n",
      "train loss:0.00843588289484398\n",
      "train loss:0.016151303055576768\n",
      "train loss:0.009688534301783536\n",
      "train loss:0.015962836909577397\n",
      "train loss:0.015530169145249897\n",
      "train loss:0.0020369599874057033\n",
      "train loss:0.0029229908107514637\n",
      "train loss:0.031177504387461648\n",
      "train loss:0.030184355736575588\n",
      "train loss:0.008165586375495368\n",
      "train loss:0.015462286420211128\n",
      "train loss:0.020225437910973233\n",
      "train loss:0.021577713457665973\n",
      "train loss:0.0012094040633604836\n",
      "train loss:0.004611949851825386\n",
      "train loss:0.005333839429557126\n",
      "train loss:0.007358119916615316\n",
      "train loss:0.003994735026443836\n",
      "train loss:0.014045869906061747\n",
      "train loss:0.011176666589394509\n",
      "train loss:0.004960049734863374\n",
      "train loss:0.0253087979218828\n",
      "train loss:0.011498673181887907\n",
      "train loss:0.006397965869893064\n",
      "train loss:0.013517798584251124\n",
      "train loss:0.04198964675995828\n",
      "train loss:0.01004171390005748\n",
      "train loss:0.006817491061768936\n",
      "train loss:0.039091241972120536\n",
      "train loss:0.023187829043125413\n",
      "train loss:0.015369564317563518\n",
      "train loss:0.021799716779078215\n",
      "train loss:0.006618999925312046\n",
      "train loss:0.0033156273921868666\n",
      "train loss:0.002810556597404035\n",
      "train loss:0.03471095003849073\n",
      "train loss:0.0025337918536945335\n",
      "train loss:0.009860591739940071\n",
      "train loss:0.0069883263594230395\n",
      "train loss:0.0007117963202982716\n",
      "train loss:0.0038642102609171996\n",
      "train loss:0.01070815431287731\n",
      "train loss:0.009394372889322789\n",
      "train loss:0.012335869198459972\n",
      "train loss:0.0020625938402771683\n",
      "train loss:0.00568528525379816\n",
      "train loss:0.002856488314700568\n",
      "train loss:0.01509905827361937\n",
      "train loss:0.0012176950465907865\n",
      "train loss:0.009588376264172933\n",
      "train loss:0.021841073023728903\n",
      "train loss:0.007730740600583488\n",
      "train loss:0.005143603029862962\n",
      "train loss:0.01000826144732051\n",
      "train loss:0.005354243728331804\n",
      "train loss:0.012084776626904714\n",
      "train loss:0.015147620032067953\n",
      "train loss:0.0019208356097395866\n",
      "train loss:0.013440545437713645\n",
      "train loss:0.003004968857260617\n",
      "train loss:0.015901748592309962\n",
      "train loss:0.004122761828736253\n",
      "train loss:0.0023924300826279636\n",
      "train loss:0.002472633442936699\n",
      "train loss:0.0016829481637774385\n",
      "train loss:0.0063920971617401155\n",
      "train loss:0.022384847935370003\n",
      "train loss:0.027689442265616954\n",
      "train loss:0.03432347796618755\n",
      "train loss:0.015732228116710826\n",
      "train loss:0.017643594441305147\n",
      "train loss:0.00778329213883018\n",
      "train loss:0.005922089579799193\n",
      "train loss:0.008911112467556947\n",
      "train loss:0.0035298579845065947\n",
      "train loss:0.004752535512704786\n",
      "train loss:0.0077247329450231324\n",
      "train loss:0.01236846838668886\n",
      "train loss:0.002626106049200431\n",
      "train loss:0.05119763818254764\n",
      "train loss:0.012796527944053728\n",
      "train loss:0.014637685771905953\n",
      "train loss:0.007323616271834391\n",
      "train loss:0.0024056634455413856\n",
      "train loss:0.0137618156892962\n",
      "train loss:0.017420355193506324\n",
      "train loss:0.03214618468287994\n",
      "train loss:0.0013417776103461397\n",
      "train loss:0.005187231325825968\n",
      "train loss:0.002710330804606351\n",
      "train loss:0.008565960014451176\n",
      "train loss:0.015561854533139297\n",
      "train loss:0.004075038364653021\n",
      "train loss:0.004708525441368471\n",
      "train loss:0.038219360802970774\n",
      "train loss:0.01668015651994878\n",
      "train loss:0.012132338317138393\n",
      "train loss:0.019228722929721293\n",
      "train loss:0.0008972722389769741\n",
      "train loss:0.014220352472404487\n",
      "train loss:0.01038004741367459\n",
      "train loss:0.08570641421300701\n",
      "train loss:0.005072321736209266\n",
      "train loss:0.008373066982400302\n",
      "train loss:0.02862131622027347\n",
      "train loss:0.011132727774391539\n",
      "train loss:0.006695725465508509\n",
      "train loss:0.00371611116600042\n",
      "train loss:0.016058357280392704\n",
      "train loss:0.01249807832667173\n",
      "train loss:0.0008158199338664068\n",
      "train loss:0.01193647688188576\n",
      "train loss:0.010695388824682659\n",
      "train loss:0.006328593938638049\n",
      "train loss:0.002814443300153434\n",
      "train loss:0.011641623138378623\n",
      "train loss:0.001967619092245095\n",
      "train loss:0.00822914436692555\n",
      "train loss:0.0009872214704464066\n",
      "train loss:0.04733833731879703\n",
      "train loss:0.0078826787921309\n",
      "train loss:0.014458264920462842\n",
      "train loss:0.02027320853997907\n",
      "train loss:0.0049409271523057005\n",
      "train loss:0.02902869825566975\n",
      "train loss:0.005469017059828809\n",
      "train loss:0.0602183120359196\n",
      "train loss:0.0028550175190231375\n",
      "train loss:0.013366827442406111\n",
      "train loss:0.0261421289499531\n",
      "train loss:0.007013134209157124\n",
      "train loss:0.014425569115523477\n",
      "train loss:0.02979433980922692\n",
      "train loss:0.01678250241293432\n",
      "train loss:0.005302195378766348\n",
      "train loss:0.03227612146074749\n",
      "train loss:0.013302059689418676\n",
      "train loss:0.010935412086872763\n",
      "train loss:0.012844673070882738\n",
      "train loss:0.011316129528790157\n",
      "train loss:0.00923307317791529\n",
      "train loss:0.011003996696077174\n",
      "train loss:0.003921599566826592\n",
      "train loss:0.022531309256933297\n",
      "train loss:0.003162740475734786\n",
      "train loss:0.0074165122371853895\n",
      "train loss:0.0042136583413221115\n",
      "train loss:0.02433979989369596\n",
      "train loss:0.010503494009454549\n",
      "train loss:0.023982423359322817\n",
      "train loss:0.005311015055676052\n",
      "train loss:0.009429865970049748\n",
      "train loss:0.013434845043560996\n",
      "train loss:0.016061539507188027\n",
      "train loss:0.007310483440499655\n",
      "train loss:0.002181545132755311\n",
      "train loss:0.014838503454137937\n",
      "train loss:0.01686451965315952\n",
      "train loss:0.004903883639671074\n",
      "train loss:0.00550461300661461\n",
      "train loss:0.006066896944358198\n",
      "train loss:0.01592707355780639\n",
      "train loss:0.0034530946457696165\n",
      "train loss:0.02229821367504417\n",
      "train loss:0.0038926932879974783\n",
      "train loss:0.002152684552567673\n",
      "train loss:0.003321897419582761\n",
      "train loss:0.03636693507784245\n",
      "train loss:0.004364314107633955\n",
      "train loss:0.0937317929592128\n",
      "train loss:0.010361350139387932\n",
      "train loss:0.0059428416235405125\n",
      "train loss:0.018363523614356926\n",
      "train loss:0.007200928842808834\n",
      "train loss:0.005230224891208335\n",
      "train loss:0.008042558390494243\n",
      "train loss:0.0159330849280023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0163909617407253\n",
      "train loss:0.0739017652145632\n",
      "train loss:0.03982678746180021\n",
      "train loss:0.010206446136155855\n",
      "train loss:0.005092950408395994\n",
      "train loss:0.004412854935862272\n",
      "train loss:0.01699128857537211\n",
      "train loss:0.010379875553636248\n",
      "train loss:0.060615680140705716\n",
      "train loss:0.006546644458046531\n",
      "train loss:0.020654564151938913\n",
      "train loss:0.005601365844331828\n",
      "train loss:0.005564054936685706\n",
      "train loss:0.013952683696060526\n",
      "train loss:0.004446751372894211\n",
      "train loss:0.024636300890345863\n",
      "train loss:0.005469979484922335\n",
      "train loss:0.007371691994841006\n",
      "train loss:0.012430626685875563\n",
      "train loss:0.028108293195295442\n",
      "train loss:0.00336897311762624\n",
      "train loss:0.05131798677484525\n",
      "train loss:0.020518000781108738\n",
      "train loss:0.0023973895721710395\n",
      "train loss:0.0074438729325659045\n",
      "train loss:0.010631042005225837\n",
      "train loss:0.07137214389571335\n",
      "train loss:0.016615375152644638\n",
      "train loss:0.0031272312022166226\n",
      "train loss:0.00401220690679396\n",
      "train loss:0.01024850733150397\n",
      "train loss:0.00855957085199893\n",
      "train loss:0.004024468757324167\n",
      "train loss:0.03055033686323156\n",
      "train loss:0.035178149786660444\n",
      "train loss:0.052905779510852756\n",
      "train loss:0.005770021726798124\n",
      "train loss:0.0037614925904624714\n",
      "train loss:0.005513714916742498\n",
      "train loss:0.00549436973377172\n",
      "train loss:0.008795323332532894\n",
      "train loss:0.014416744430624056\n",
      "train loss:0.004282522669545733\n",
      "train loss:0.04171543874543151\n",
      "train loss:0.03877851219346285\n",
      "train loss:0.0038292042809399767\n",
      "train loss:0.010450358319036495\n",
      "train loss:0.005112251565786355\n",
      "train loss:0.020883425410923057\n",
      "train loss:0.008236899595204347\n",
      "train loss:0.0031759829723555584\n",
      "train loss:0.01563024568283268\n",
      "train loss:0.013000849731357842\n",
      "train loss:0.02927972774387857\n",
      "train loss:0.009368220644091856\n",
      "train loss:0.038822200759108944\n",
      "train loss:0.003487803030163088\n",
      "train loss:0.006744683223260228\n",
      "train loss:0.026952954560391724\n",
      "train loss:0.008903795542382093\n",
      "train loss:0.0015351292118593136\n",
      "train loss:0.004509045360131554\n",
      "train loss:0.00789516910380954\n",
      "train loss:0.008173307167831904\n",
      "train loss:0.028033323402201292\n",
      "train loss:0.002363415217767814\n",
      "train loss:0.005725210827063476\n",
      "train loss:0.019618741071633857\n",
      "train loss:0.06050416817118439\n",
      "train loss:0.006523184727223455\n",
      "train loss:0.00431475395949443\n",
      "train loss:0.01959193406626891\n",
      "train loss:0.002436299734186349\n",
      "train loss:0.004000819206529319\n",
      "train loss:0.01670043507794935\n",
      "train loss:0.008234291731683448\n",
      "train loss:0.03430379722712712\n",
      "train loss:0.027730367718144064\n",
      "train loss:0.005729285012168545\n",
      "train loss:0.01194666999404443\n",
      "train loss:0.07615915784572022\n",
      "train loss:0.00904802738415008\n",
      "train loss:0.008292906664613086\n",
      "train loss:0.004533061492798442\n",
      "train loss:0.012312584916887158\n",
      "train loss:0.06478325575480504\n",
      "train loss:0.010643549494039627\n",
      "train loss:0.05282555751852459\n",
      "train loss:0.044310161260531576\n",
      "train loss:0.02477178792318827\n",
      "train loss:0.0045153712193431\n",
      "train loss:0.0523482246801691\n",
      "train loss:0.04988396443346753\n",
      "train loss:0.02294963622908219\n",
      "train loss:0.02030050718058491\n",
      "train loss:0.03235319151487507\n",
      "train loss:0.01244122289021633\n",
      "train loss:0.0024207512856074392\n",
      "train loss:0.005494117782432801\n",
      "train loss:0.02560020731582373\n",
      "train loss:0.008647415417255232\n",
      "=== epoch:9, train acc:0.992, test acc:0.98 ===\n",
      "train loss:0.007821837670773366\n",
      "train loss:0.009654935669147017\n",
      "train loss:0.03656989638039093\n",
      "train loss:0.014525615444793914\n",
      "train loss:0.0029281628257241264\n",
      "train loss:0.0072095996424865975\n",
      "train loss:0.006381077294720242\n",
      "train loss:0.005573451407715748\n",
      "train loss:0.006044327744776812\n",
      "train loss:0.0057252804862217895\n",
      "train loss:0.002044851827622886\n",
      "train loss:0.003842591781186239\n",
      "train loss:0.0013880444702060785\n",
      "train loss:0.023954728888705992\n",
      "train loss:0.007083969639684203\n",
      "train loss:0.04652909128112433\n",
      "train loss:0.004265929439650093\n",
      "train loss:0.0062655190348098865\n",
      "train loss:0.012439778795089704\n",
      "train loss:0.01318300622196971\n",
      "train loss:0.013913032761284274\n",
      "train loss:0.007933837858201483\n",
      "train loss:0.00840041599309413\n",
      "train loss:0.007916709092624364\n",
      "train loss:0.008507619506213869\n",
      "train loss:0.006916329368248683\n",
      "train loss:0.005046421248614185\n",
      "train loss:0.0038943253514232847\n",
      "train loss:0.008482254113849126\n",
      "train loss:0.011380308290199077\n",
      "train loss:0.013015195897018616\n",
      "train loss:0.010296275270069466\n",
      "train loss:0.011784910969787364\n",
      "train loss:0.013608506391892865\n",
      "train loss:0.009800594987938328\n",
      "train loss:0.0025639310040612403\n",
      "train loss:0.002492866530986986\n",
      "train loss:0.010414956235372901\n",
      "train loss:0.0015385549901305693\n",
      "train loss:0.016681061672323753\n",
      "train loss:0.004063947736676188\n",
      "train loss:0.0035036846301064618\n",
      "train loss:0.0042902214046188596\n",
      "train loss:0.011484279177632045\n",
      "train loss:0.007630083622581347\n",
      "train loss:0.009541238945838786\n",
      "train loss:0.0007882892911032228\n",
      "train loss:0.022965903660306188\n",
      "train loss:0.008069639051961699\n",
      "train loss:0.0031130341315116737\n",
      "train loss:0.0012834316260142756\n",
      "train loss:0.0042171580664846315\n",
      "train loss:0.017203025771606033\n",
      "train loss:0.013334905244867207\n",
      "train loss:0.016198547552620027\n",
      "train loss:0.017559731840316176\n",
      "train loss:0.004085567324024003\n",
      "train loss:0.0033625106938866274\n",
      "train loss:0.006753751904133659\n",
      "train loss:0.050763764043251516\n",
      "train loss:0.008526285039287982\n",
      "train loss:0.03313515637464382\n",
      "train loss:0.004468252172439554\n",
      "train loss:0.0019140874357800501\n",
      "train loss:0.00956309554584374\n",
      "train loss:0.010433755225094994\n",
      "train loss:0.007351970427239913\n",
      "train loss:0.020536934572673013\n",
      "train loss:0.009224276779980074\n",
      "train loss:0.018498415178844718\n",
      "train loss:0.015821304117967873\n",
      "train loss:0.08278641387848565\n",
      "train loss:0.002864833016265399\n",
      "train loss:0.027746773825529307\n",
      "train loss:0.02333003234377968\n",
      "train loss:0.02232256778347303\n",
      "train loss:0.0010270601154488334\n",
      "train loss:0.0030693008121191957\n",
      "train loss:0.006532294318902355\n",
      "train loss:0.02548613119725961\n",
      "train loss:0.03211219270861094\n",
      "train loss:0.029659764258950436\n",
      "train loss:0.010885687798524708\n",
      "train loss:0.003471347549693836\n",
      "train loss:0.001804489642568955\n",
      "train loss:0.016034015979597534\n",
      "train loss:0.021019645159261153\n",
      "train loss:0.004420590472808936\n",
      "train loss:0.023469176710253045\n",
      "train loss:0.004484582348218741\n",
      "train loss:0.07131910232815425\n",
      "train loss:0.008324380027579476\n",
      "train loss:0.007918642456134226\n",
      "train loss:0.004015561049627619\n",
      "train loss:0.0064686982717812895\n",
      "train loss:0.007404679452416838\n",
      "train loss:0.004485484388521083\n",
      "train loss:0.16910512437987893\n",
      "train loss:0.011667531340399521\n",
      "train loss:0.0043070035971477525\n",
      "train loss:0.00505182237444856\n",
      "train loss:0.011685471425231884\n",
      "train loss:0.0013345713289961306\n",
      "train loss:0.006192549709678648\n",
      "train loss:0.003211610356555463\n",
      "train loss:0.015256163853069408\n",
      "train loss:0.003918868884404257\n",
      "train loss:0.027354189186967456\n",
      "train loss:0.003105818624424425\n",
      "train loss:0.0037584768206225545\n",
      "train loss:0.006891461975296259\n",
      "train loss:0.013305085121738846\n",
      "train loss:0.004055530713788657\n",
      "train loss:0.003227574317161484\n",
      "train loss:0.004609896472973717\n",
      "train loss:0.01249632134043728\n",
      "train loss:0.005012470826154775\n",
      "train loss:0.001905957827453673\n",
      "train loss:0.02013228354145478\n",
      "train loss:0.0033541523933557304\n",
      "train loss:0.013763924686524778\n",
      "train loss:0.015855912101906774\n",
      "train loss:0.004685160584226807\n",
      "train loss:0.0036495527017860762\n",
      "train loss:0.005509725097723518\n",
      "train loss:0.014186232795094424\n",
      "train loss:0.015097077979704478\n",
      "train loss:0.004182910092647409\n",
      "train loss:0.00996371152669732\n",
      "train loss:0.006509161596992111\n",
      "train loss:0.02096487819343798\n",
      "train loss:0.011985878217284666\n",
      "train loss:0.12938613813683286\n",
      "train loss:0.010948752786457974\n",
      "train loss:0.005508248920830303\n",
      "train loss:0.016636800157091985\n",
      "train loss:0.012139485439512132\n",
      "train loss:0.008296103509476977\n",
      "train loss:0.004651777771055577\n",
      "train loss:0.007507664657446646\n",
      "train loss:0.009685540513895823\n",
      "train loss:0.01429192413001548\n",
      "train loss:0.025109886190795884\n",
      "train loss:0.006905221079654196\n",
      "train loss:0.005942214187175079\n",
      "train loss:0.006374115237887251\n",
      "train loss:0.010491171796622224\n",
      "train loss:0.008947127838274716\n",
      "train loss:0.008557524745304846\n",
      "train loss:0.011863235895022951\n",
      "train loss:0.013020669770620129\n",
      "train loss:0.0038253282863009806\n",
      "train loss:0.0011452400296354632\n",
      "train loss:0.00863536154003456\n",
      "train loss:0.005460909225883503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002922063393891269\n",
      "train loss:0.001406653882651375\n",
      "train loss:0.004454491533809149\n",
      "train loss:0.013841730314804427\n",
      "train loss:0.004505055830178108\n",
      "train loss:0.007925511825389846\n",
      "train loss:0.0074842317016964475\n",
      "train loss:0.006282685787232136\n",
      "train loss:0.01975560716829367\n",
      "train loss:0.011469142039720617\n",
      "train loss:0.01619445865810103\n",
      "train loss:0.004097267690180295\n",
      "train loss:0.0038790758207902253\n",
      "train loss:0.04045402885133174\n",
      "train loss:0.004036770957419903\n",
      "train loss:0.01279270566541036\n",
      "train loss:0.009039663113551035\n",
      "train loss:0.04765468798078532\n",
      "train loss:0.004016710396550736\n",
      "train loss:0.0019455230778382517\n",
      "train loss:0.0012865805925892965\n",
      "train loss:0.004505294944161595\n",
      "train loss:0.01291928617130925\n",
      "train loss:0.001676606967565635\n",
      "train loss:0.02078350705511796\n",
      "train loss:0.002031471367409136\n",
      "train loss:0.004397091029803162\n",
      "train loss:0.012307538701459675\n",
      "train loss:0.00834784041239483\n",
      "train loss:0.012778730879313529\n",
      "train loss:0.006615379478022511\n",
      "train loss:0.015004896316044155\n",
      "train loss:0.011349586666621631\n",
      "train loss:0.00442361190381263\n",
      "train loss:0.013515102249416766\n",
      "train loss:0.0015150473414678096\n",
      "train loss:0.005630105712673285\n",
      "train loss:0.0018705494471407014\n",
      "train loss:0.03329206843803546\n",
      "train loss:0.01568040206800936\n",
      "train loss:0.01858683475711737\n",
      "train loss:0.0054137359612686535\n",
      "train loss:0.0022413844420376234\n",
      "train loss:0.012760439021026259\n",
      "train loss:0.027106147334303724\n",
      "train loss:0.034642054147255893\n",
      "train loss:0.007410622139112867\n",
      "train loss:0.026325530967365257\n",
      "train loss:0.030460244475848556\n",
      "train loss:0.010637916840946022\n",
      "train loss:0.003823944122403954\n",
      "train loss:0.005220850868625302\n",
      "train loss:0.005788239563425012\n",
      "train loss:0.0238577098154223\n",
      "train loss:0.017586361158406026\n",
      "train loss:0.0635670711865333\n",
      "train loss:0.01575871728908869\n",
      "train loss:0.005269109743201456\n",
      "train loss:0.004534191252318394\n",
      "train loss:0.004550234997569441\n",
      "train loss:0.00423656215699145\n",
      "train loss:0.0030466352062910617\n",
      "train loss:0.009296801077747557\n",
      "train loss:0.012081038451903604\n",
      "train loss:0.004945121573441558\n",
      "train loss:0.0016372243500734848\n",
      "train loss:0.025304116056898612\n",
      "train loss:0.004442850191218972\n",
      "train loss:0.004938937724330062\n",
      "train loss:0.008373349289371692\n",
      "train loss:0.006338335716820897\n",
      "train loss:0.0026789850493302127\n",
      "train loss:0.008686990497348519\n",
      "train loss:0.013931813030687842\n",
      "train loss:0.010159079317770587\n",
      "train loss:0.06226533810623467\n",
      "train loss:0.023008424157657054\n",
      "train loss:0.006736887742149943\n",
      "train loss:0.028227651616419772\n",
      "train loss:0.011065274111770005\n",
      "train loss:0.004909531301295637\n",
      "train loss:0.0007454849164480791\n",
      "train loss:0.0030186641767905157\n",
      "train loss:0.004931871976911178\n",
      "train loss:0.004175852911499124\n",
      "train loss:0.007311480337947287\n",
      "train loss:0.0015942742091497692\n",
      "train loss:0.0041458366948998624\n",
      "train loss:0.006884218286632484\n",
      "train loss:0.00540002637413062\n",
      "train loss:0.005862595922785071\n",
      "train loss:0.019975918409432622\n",
      "train loss:0.021936572628399556\n",
      "train loss:0.003493882601908363\n",
      "train loss:0.013656804692780182\n",
      "train loss:0.013930728434737534\n",
      "train loss:0.008129280404291443\n",
      "train loss:0.008918355468067043\n",
      "train loss:0.01714507260373367\n",
      "train loss:0.005031119119924677\n",
      "train loss:0.02493085082178434\n",
      "train loss:0.027433341226690274\n",
      "train loss:0.008312690292555897\n",
      "train loss:0.004217058462215881\n",
      "train loss:0.014821222351588165\n",
      "train loss:0.024596208501700297\n",
      "train loss:0.010734870587002766\n",
      "train loss:0.011735438195627551\n",
      "train loss:0.027840392523680858\n",
      "train loss:0.01586916848389671\n",
      "train loss:0.0022416597447091143\n",
      "train loss:0.004407230781370888\n",
      "train loss:0.007455174333984226\n",
      "train loss:0.010328444707581682\n",
      "train loss:0.0026994382522933535\n",
      "train loss:0.0113421831641736\n",
      "train loss:0.0019428783209662706\n",
      "train loss:0.03424526019527771\n",
      "train loss:0.01032162081852268\n",
      "train loss:0.0017069468127708753\n",
      "train loss:0.010861930465056647\n",
      "train loss:0.020256103383684113\n",
      "train loss:0.008503407622785312\n",
      "train loss:0.0016611340244833933\n",
      "train loss:0.0008201445657496529\n",
      "train loss:0.0024875998298248543\n",
      "train loss:0.004310731202634166\n",
      "train loss:0.04128731377619825\n",
      "train loss:0.06321563443826256\n",
      "train loss:0.010032919476817044\n",
      "train loss:0.008491217460597757\n",
      "train loss:0.032703717338570165\n",
      "train loss:0.0019258687075055859\n",
      "train loss:0.01535493583870863\n",
      "train loss:0.008868720316900282\n",
      "train loss:0.06707754241345606\n",
      "train loss:0.004607342531301332\n",
      "train loss:0.07933251683139797\n",
      "train loss:0.009233308057911716\n",
      "train loss:0.01255982715086991\n",
      "train loss:0.0018638051352782143\n",
      "train loss:0.011313099769589325\n",
      "train loss:0.0179520865197615\n",
      "train loss:0.005369452241532157\n",
      "train loss:0.005008413068185883\n",
      "train loss:0.0017866263640653188\n",
      "train loss:0.017534216297997153\n",
      "train loss:0.016391642252238187\n",
      "train loss:0.018341358484779337\n",
      "train loss:0.005924220987326902\n",
      "train loss:0.013075708170197122\n",
      "train loss:0.004241402663518325\n",
      "train loss:0.008186434969026933\n",
      "train loss:0.0033133373525944644\n",
      "train loss:0.007823619982282084\n",
      "train loss:0.014920781554585151\n",
      "train loss:0.033588212095623675\n",
      "train loss:0.004615436912594019\n",
      "train loss:0.0040290957607892995\n",
      "train loss:0.030917475870239436\n",
      "train loss:0.029398201812322996\n",
      "train loss:0.007614127774897617\n",
      "train loss:0.001720264089452857\n",
      "train loss:0.0035581492050447234\n",
      "train loss:0.007248256077279239\n",
      "train loss:0.012164961042661359\n",
      "train loss:0.057198863037319254\n",
      "train loss:0.001997614562513963\n",
      "train loss:0.006688716641783254\n",
      "train loss:0.005077756084331992\n",
      "train loss:0.03621895411523708\n",
      "train loss:0.04017381410978119\n",
      "train loss:0.005188020790603907\n",
      "train loss:0.006018620969540245\n",
      "train loss:0.01573144991103884\n",
      "train loss:0.007701972722849935\n",
      "train loss:0.012388334309974214\n",
      "train loss:0.06298242482294573\n",
      "train loss:0.0032970898357729678\n",
      "train loss:0.061092616194601615\n",
      "train loss:0.015468329646525156\n",
      "train loss:0.00399968843444998\n",
      "train loss:0.004901981824807744\n",
      "train loss:0.00992166568170611\n",
      "train loss:0.016508822406575543\n",
      "train loss:0.013115165138993263\n",
      "train loss:0.006958071637428456\n",
      "train loss:0.014119738887762735\n",
      "train loss:0.004334910352522336\n",
      "train loss:0.0029717472262525326\n",
      "train loss:0.0033730269134494384\n",
      "train loss:0.04744337633223258\n",
      "train loss:0.06271601999476212\n",
      "train loss:0.034490002787418865\n",
      "train loss:0.019028706536320984\n",
      "train loss:0.005736563845876077\n",
      "train loss:0.006899140567407266\n",
      "train loss:0.004285034213727088\n",
      "train loss:0.030688338468232646\n",
      "train loss:0.0017992726566431045\n",
      "train loss:0.029196390962893854\n",
      "train loss:0.004893953262873534\n",
      "train loss:0.0020984623613227098\n",
      "train loss:0.04458717514567378\n",
      "train loss:0.003193258893516888\n",
      "train loss:0.003111123134732778\n",
      "train loss:0.012535303449959075\n",
      "train loss:0.012469254106341704\n",
      "train loss:0.004447650349412194\n",
      "train loss:0.005625609213736413\n",
      "train loss:0.0009513569436479721\n",
      "train loss:0.00593543296623002\n",
      "train loss:0.009835574026205577\n",
      "train loss:0.00677056713159171\n",
      "train loss:0.011330716371582141\n",
      "train loss:0.021285516096662196\n",
      "train loss:0.006793560517545922\n",
      "train loss:0.01017657108069582\n",
      "train loss:0.007440408886723629\n",
      "train loss:0.05520474878379592\n",
      "train loss:0.01152767311102891\n",
      "train loss:0.005991324113295634\n",
      "train loss:0.010707280063828959\n",
      "train loss:0.0020207867045430334\n",
      "train loss:0.0014752374960999405\n",
      "train loss:0.0013364272759069382\n",
      "train loss:0.018551585152438516\n",
      "train loss:0.00787338187309966\n",
      "train loss:0.003169700256730008\n",
      "train loss:0.029186173617537055\n",
      "train loss:0.02002631517423517\n",
      "train loss:0.013060602719712435\n",
      "train loss:0.017168743228895347\n",
      "train loss:0.011059464204541049\n",
      "train loss:0.014463635667789356\n",
      "train loss:0.01044984267811591\n",
      "train loss:0.012185409429368072\n",
      "train loss:0.005273684995342888\n",
      "train loss:0.0015632919219391195\n",
      "train loss:0.006412463066753454\n",
      "train loss:0.011180513860337667\n",
      "train loss:0.005639410592044746\n",
      "train loss:0.0030628737497526105\n",
      "train loss:0.023412040254254474\n",
      "train loss:0.0011325647197451246\n",
      "train loss:0.07216802894988819\n",
      "train loss:0.03157967007917363\n",
      "train loss:0.016795371046302205\n",
      "train loss:0.00829935221939872\n",
      "train loss:0.06430995732254083\n",
      "train loss:0.002700632296013657\n",
      "train loss:0.0048747376457731395\n",
      "train loss:0.0053906828045209194\n",
      "train loss:0.004442604333146583\n",
      "train loss:0.009884456074645331\n",
      "train loss:0.0830832245482907\n",
      "train loss:0.029394267681378414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.013022634601705125\n",
      "train loss:0.0011207580574961803\n",
      "train loss:0.005305469337069246\n",
      "train loss:0.007358165730435255\n",
      "train loss:0.038718387385858206\n",
      "train loss:0.0005424368655549437\n",
      "train loss:0.007975748262646937\n",
      "train loss:0.019738596234956753\n",
      "train loss:0.003039320230605018\n",
      "train loss:0.013280714387895702\n",
      "train loss:0.012435997055825211\n",
      "train loss:0.021746753280762192\n",
      "train loss:0.001017377991325137\n",
      "train loss:0.0026752589412025528\n",
      "train loss:0.006410944825133938\n",
      "train loss:0.0029632421118367426\n",
      "train loss:0.00904429834734813\n",
      "train loss:0.03796936574376355\n",
      "train loss:0.006886991440416201\n",
      "train loss:0.018038081150777072\n",
      "train loss:0.005315438065276703\n",
      "train loss:0.01483710042353611\n",
      "train loss:0.006197913068247882\n",
      "train loss:0.014158448180844321\n",
      "train loss:0.011226479380690029\n",
      "train loss:0.003279248572018465\n",
      "train loss:0.025580100291005447\n",
      "train loss:0.024068144035129854\n",
      "train loss:0.039379504728609266\n",
      "train loss:0.0033217708005525066\n",
      "train loss:0.001481288442254051\n",
      "train loss:0.0033903640303972176\n",
      "train loss:0.0055801837009349185\n",
      "train loss:0.0311028582452445\n",
      "train loss:0.011002607948862922\n",
      "train loss:0.0068332746439883066\n",
      "train loss:0.0067705614791376345\n",
      "train loss:0.008288399576508962\n",
      "train loss:0.0031793306925306467\n",
      "train loss:0.00034122923278539797\n",
      "train loss:0.008507068589245777\n",
      "train loss:0.011984162537696484\n",
      "train loss:0.004854677936701013\n",
      "train loss:0.13710429609560365\n",
      "train loss:0.017261231402876755\n",
      "train loss:0.003894288855085753\n",
      "train loss:0.013370387081136779\n",
      "train loss:0.012451499046119951\n",
      "train loss:0.022969654067185635\n",
      "train loss:0.050268820842965196\n",
      "train loss:0.05072000853500655\n",
      "train loss:0.0031153463906991017\n",
      "train loss:0.007989148056246157\n",
      "train loss:0.0015717425763221676\n",
      "train loss:0.004565899515934144\n",
      "train loss:0.0015415898399955773\n",
      "train loss:0.00550514358861138\n",
      "train loss:0.011040450251603759\n",
      "train loss:0.0034897610016688995\n",
      "train loss:0.014445527696704956\n",
      "train loss:0.001757208850338548\n",
      "train loss:0.007577430390523115\n",
      "train loss:0.002406830313020396\n",
      "train loss:0.001995207000163165\n",
      "train loss:0.008983084727918794\n",
      "train loss:0.011313016832311014\n",
      "train loss:0.0059351644794743905\n",
      "train loss:0.021100012982781823\n",
      "train loss:0.008763648155005237\n",
      "train loss:0.007808064781970865\n",
      "train loss:0.004739023580971431\n",
      "train loss:0.03770653879600452\n",
      "train loss:0.013266036227582495\n",
      "train loss:0.022610134747939672\n",
      "train loss:0.010338826757847266\n",
      "train loss:0.00422714561848695\n",
      "train loss:0.007166215423848526\n",
      "train loss:0.004397075939848461\n",
      "train loss:0.01732642673533264\n",
      "train loss:0.008055538216348855\n",
      "train loss:0.04322424596069824\n",
      "train loss:0.006140268934768498\n",
      "train loss:0.0030057355905445406\n",
      "train loss:0.0053298847779947485\n",
      "train loss:0.02911513687243049\n",
      "train loss:0.01759423832233617\n",
      "train loss:0.00964969734454333\n",
      "train loss:0.0082597580919753\n",
      "train loss:0.008895984844983638\n",
      "train loss:0.005712675912783604\n",
      "train loss:0.00452352855162633\n",
      "train loss:0.029750310003166473\n",
      "train loss:0.0012239280290478696\n",
      "train loss:0.009792468966401714\n",
      "train loss:0.008380459778174193\n",
      "train loss:0.004633397672787959\n",
      "train loss:0.006940432552386137\n",
      "train loss:0.002774429772551436\n",
      "train loss:0.07294360481436156\n",
      "train loss:0.008904527819798837\n",
      "train loss:0.05242182981608611\n",
      "train loss:0.0058744497750319894\n",
      "train loss:0.013114500532122693\n",
      "train loss:0.03227880130442226\n",
      "train loss:0.011378455217384476\n",
      "train loss:0.01601197115701342\n",
      "train loss:0.00875621262880781\n",
      "train loss:0.009098742657509689\n",
      "train loss:0.01613470756140649\n",
      "train loss:0.017092325408130892\n",
      "train loss:0.0013189386744958931\n",
      "train loss:0.027584270019967282\n",
      "train loss:0.0018250831043251283\n",
      "train loss:0.022435388621126876\n",
      "train loss:0.00349133261856484\n",
      "train loss:0.006945454524474934\n",
      "train loss:0.03838186485580839\n",
      "train loss:0.026610399178780438\n",
      "train loss:0.0025267877990866523\n",
      "train loss:0.0082635418200627\n",
      "train loss:0.009773608758496526\n",
      "train loss:0.009711202577617109\n",
      "train loss:0.005326048926223614\n",
      "train loss:0.011889496359532134\n",
      "train loss:0.0038513314228489043\n",
      "train loss:0.005548349872464497\n",
      "train loss:0.021302567774535895\n",
      "train loss:0.0065329018489861425\n",
      "train loss:0.0033095549813321706\n",
      "train loss:0.01909343503589347\n",
      "train loss:0.002490816046402787\n",
      "train loss:0.012855035086633881\n",
      "train loss:0.004745307066976834\n",
      "train loss:0.006160765075007279\n",
      "train loss:0.00460898742604861\n",
      "train loss:0.0034842866846377545\n",
      "train loss:0.0007773070837778141\n",
      "train loss:0.012132015258722748\n",
      "train loss:0.05110559744152395\n",
      "train loss:0.005551252719835831\n",
      "train loss:0.005724868561754229\n",
      "train loss:0.010546693826650393\n",
      "train loss:0.004966331271125332\n",
      "train loss:0.012242123257379198\n",
      "train loss:0.0038667037340404994\n",
      "train loss:0.016063875695464157\n",
      "train loss:0.023086811746823355\n",
      "train loss:0.0026839225264252854\n",
      "train loss:0.00801732935072309\n",
      "train loss:0.0023866984342420274\n",
      "train loss:0.008947281626735849\n",
      "train loss:0.021403842700106583\n",
      "train loss:0.016226169946012156\n",
      "train loss:0.031493239468772895\n",
      "train loss:0.00837054256102546\n",
      "train loss:0.011135905943887924\n",
      "train loss:0.0029305030180596463\n",
      "train loss:0.0032848182534539177\n",
      "train loss:0.012310752516657784\n",
      "train loss:0.024440084221011425\n",
      "train loss:0.029887084273929672\n",
      "train loss:0.01050122062687013\n",
      "train loss:0.008363002729948988\n",
      "train loss:0.010373533838203402\n",
      "train loss:0.004725595173194233\n",
      "train loss:0.02161080274272531\n",
      "train loss:0.006943746049915581\n",
      "train loss:0.014284273707649143\n",
      "train loss:0.01180542883056283\n",
      "train loss:0.0025005009967517555\n",
      "train loss:0.023827291348451952\n",
      "train loss:0.004940650617698637\n",
      "train loss:0.004748621118328301\n",
      "train loss:0.018874144494011\n",
      "train loss:0.013848151370059934\n",
      "train loss:0.007445339723299803\n",
      "train loss:0.003674150234576137\n",
      "train loss:0.0023299192917882756\n",
      "train loss:0.05506243820772455\n",
      "train loss:0.0054619615616518565\n",
      "train loss:0.0529859240461005\n",
      "train loss:0.005437690950075223\n",
      "train loss:0.00046902586929840716\n",
      "train loss:0.021707851136449876\n",
      "train loss:0.004413829865351607\n",
      "train loss:0.0025515139595874113\n",
      "train loss:0.02088075565162562\n",
      "train loss:0.004482473623292438\n",
      "=== epoch:10, train acc:0.988, test acc:0.981 ===\n",
      "train loss:0.013952847124439227\n",
      "train loss:0.01202386876906085\n",
      "train loss:0.026012447823074235\n",
      "train loss:0.04644337489041358\n",
      "train loss:0.008394422741331795\n",
      "train loss:0.003954367146898985\n",
      "train loss:0.004505798411675478\n",
      "train loss:0.024044143186365715\n",
      "train loss:0.015244829442791012\n",
      "train loss:0.004034907368917705\n",
      "train loss:0.004929209993644814\n",
      "train loss:0.002137853150778776\n",
      "train loss:0.003609025698736876\n",
      "train loss:0.010653621167914195\n",
      "train loss:0.006343821125925731\n",
      "train loss:0.011897864178078896\n",
      "train loss:0.018962849540547905\n",
      "train loss:0.019237549495947647\n",
      "train loss:0.018714250541040117\n",
      "train loss:0.019098989115854243\n",
      "train loss:0.013948311210085534\n",
      "train loss:0.036579933295324545\n",
      "train loss:0.0017043677446909608\n",
      "train loss:0.0029394700578951106\n",
      "train loss:0.01539268199468874\n",
      "train loss:0.0056282696054795\n",
      "train loss:0.00445103241208725\n",
      "train loss:0.014114460534305928\n",
      "train loss:0.002505559116799059\n",
      "train loss:0.0036330954446935192\n",
      "train loss:0.010157062304650659\n",
      "train loss:0.018276135261526348\n",
      "train loss:0.004789530858171176\n",
      "train loss:0.010764582370587876\n",
      "train loss:0.011273668212709703\n",
      "train loss:0.012600688535217197\n",
      "train loss:0.005536770948280434\n",
      "train loss:0.0025993041825685113\n",
      "train loss:0.006075789043607631\n",
      "train loss:0.04487761972282413\n",
      "train loss:0.0009629749889551761\n",
      "train loss:0.007787742810712392\n",
      "train loss:0.02985149042149767\n",
      "train loss:0.0026565176792356874\n",
      "train loss:0.0036001660826677695\n",
      "train loss:0.009602471343972211\n",
      "train loss:0.004428362331728796\n",
      "train loss:0.0024322160567252214\n",
      "train loss:0.03865788555091741\n",
      "train loss:0.02599795178594897\n",
      "train loss:0.0024310279356458096\n",
      "train loss:0.0004988144584171938\n",
      "train loss:0.06050725091388216\n",
      "train loss:0.0004887626098759356\n",
      "train loss:0.0036737981421005846\n",
      "train loss:0.004506401066299585\n",
      "train loss:0.0005346453739661576\n",
      "train loss:0.0028068245534392357\n",
      "train loss:0.002569921565387795\n",
      "train loss:0.004852169455501274\n",
      "train loss:0.003938393454654444\n",
      "train loss:0.03831346246795467\n",
      "train loss:0.00982609858564697\n",
      "train loss:0.004203985967376537\n",
      "train loss:0.0036155735887482316\n",
      "train loss:0.011493614061310685\n",
      "train loss:0.012599095427933605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.012849190067146694\n",
      "train loss:0.002499300713311224\n",
      "train loss:0.018609715563713058\n",
      "train loss:0.024661370145567657\n",
      "train loss:0.009304509456086416\n",
      "train loss:0.0031978595170121522\n",
      "train loss:0.004306688066763045\n",
      "train loss:0.03152754271340335\n",
      "train loss:0.014951715959999159\n",
      "train loss:0.005273939525514517\n",
      "train loss:0.0024249165757890836\n",
      "train loss:0.011148007369649214\n",
      "train loss:0.001493898957343658\n",
      "train loss:0.03486098085343388\n",
      "train loss:0.006902956145581073\n",
      "train loss:0.01090262638598439\n",
      "train loss:0.003251070544506792\n",
      "train loss:0.009811758200023323\n",
      "train loss:0.01169108941806899\n",
      "train loss:0.003151176597150271\n",
      "train loss:0.012784380880496493\n",
      "train loss:0.014343528623874753\n",
      "train loss:0.009268352258851788\n",
      "train loss:0.03803543421528552\n",
      "train loss:0.0006430378199649485\n",
      "train loss:0.008007617441463498\n",
      "train loss:0.030427434051807055\n",
      "train loss:0.008252218971065489\n",
      "train loss:0.0005346750141761448\n",
      "train loss:0.005631948656483512\n",
      "train loss:0.003747788076510342\n",
      "train loss:0.018113459195353655\n",
      "train loss:0.02049015447953787\n",
      "train loss:0.012386889764129112\n",
      "train loss:0.0007148170691539634\n",
      "train loss:0.011883266775435995\n",
      "train loss:0.0018307219259805932\n",
      "train loss:0.007533591895919556\n",
      "train loss:0.04299990280972907\n",
      "train loss:0.03528174522169916\n",
      "train loss:0.003068461225897571\n",
      "train loss:0.016885428370845522\n",
      "train loss:0.007842304377047403\n",
      "train loss:0.003185200390443605\n",
      "train loss:0.00587379189355015\n",
      "train loss:0.0016943047151220672\n",
      "train loss:0.006082872719088418\n",
      "train loss:0.02371166479223382\n",
      "train loss:0.0018096120541204752\n",
      "train loss:0.005399692962031431\n",
      "train loss:0.004198534804711098\n",
      "train loss:0.003933196861440592\n",
      "train loss:0.05188285134487093\n",
      "train loss:0.00857659680346433\n",
      "train loss:0.0013631668732465845\n",
      "train loss:0.01783613671906693\n",
      "train loss:0.0033465724742407273\n",
      "train loss:0.000570764795984503\n",
      "train loss:0.0034085427417601395\n",
      "train loss:0.011252440120314244\n",
      "train loss:0.004121415865912196\n",
      "train loss:0.000973259508006343\n",
      "train loss:0.021638601423384907\n",
      "train loss:0.021648079913177378\n",
      "train loss:0.028429007564458257\n",
      "train loss:0.006451081594763062\n",
      "train loss:0.0090339449644801\n",
      "train loss:0.000605943573249848\n",
      "train loss:0.009706990360074667\n",
      "train loss:0.0007688599380546638\n",
      "train loss:0.035413040573294474\n",
      "train loss:0.0012342752723495016\n",
      "train loss:0.01430820167415526\n",
      "train loss:0.003530046672653628\n",
      "train loss:0.010866752353880198\n",
      "train loss:0.0049293799618793325\n",
      "train loss:0.05198807279692187\n",
      "train loss:0.0019569648230500776\n",
      "train loss:0.0075271638014801434\n",
      "train loss:0.02176135331232075\n",
      "train loss:0.010129859521391666\n",
      "train loss:0.0035213421843618476\n",
      "train loss:0.0020357233656409855\n",
      "train loss:0.02407372454929502\n",
      "train loss:0.009614692280757639\n",
      "train loss:0.011923957005506787\n",
      "train loss:0.009068876104116278\n",
      "train loss:0.01086167768262148\n",
      "train loss:0.01206239564655769\n",
      "train loss:0.007438731670852635\n",
      "train loss:0.004878920518619034\n",
      "train loss:0.010099984525528093\n",
      "train loss:0.005934919967152353\n",
      "train loss:0.00806844309234846\n",
      "train loss:0.009526633469322707\n",
      "train loss:0.0037408277888600393\n",
      "train loss:0.003994943389676525\n",
      "train loss:0.003305613052372319\n",
      "train loss:0.017126409699014463\n",
      "train loss:0.010272854075321207\n",
      "train loss:0.022406750416982372\n",
      "train loss:0.0044163058501728155\n",
      "train loss:0.0009013838584240075\n",
      "train loss:0.008686175726507957\n",
      "train loss:0.0008208432245742498\n",
      "train loss:0.008545538369853922\n",
      "train loss:0.00462410396170073\n",
      "train loss:0.004806796805028232\n",
      "train loss:0.0033554523117054697\n",
      "train loss:0.024565500160836598\n",
      "train loss:0.023022999222402977\n",
      "train loss:0.007815169714714775\n",
      "train loss:0.006624877493952016\n",
      "train loss:0.001450673022140904\n",
      "train loss:0.0025645770778867827\n",
      "train loss:0.009509883330625756\n",
      "train loss:0.00873253927147968\n",
      "train loss:0.0006795126478880882\n",
      "train loss:0.004434680230026177\n",
      "train loss:0.004298011450240325\n",
      "train loss:0.005535551336242251\n",
      "train loss:0.0027670472178409128\n",
      "train loss:0.05466895314214227\n",
      "train loss:0.0030299130744889623\n",
      "train loss:0.005573700531471081\n",
      "train loss:0.008182531462794877\n",
      "train loss:0.005392140209371798\n",
      "train loss:0.0039345456921771925\n",
      "train loss:0.0074013122723134974\n",
      "train loss:0.015109466560931532\n",
      "train loss:0.00478381848118253\n",
      "train loss:0.0033539880745229976\n",
      "train loss:0.014768656494329666\n",
      "train loss:0.008990880226459792\n",
      "train loss:0.008079159119482301\n",
      "train loss:0.008454704870852911\n",
      "train loss:0.004999369835961465\n",
      "train loss:0.0035087822393560842\n",
      "train loss:0.009059849861350307\n",
      "train loss:0.0015412652814234483\n",
      "train loss:0.0008067372912450313\n",
      "train loss:0.0038627075455018272\n",
      "train loss:0.005317479306395058\n",
      "train loss:0.00537982248117425\n",
      "train loss:0.00465569272279648\n",
      "train loss:0.01770657211706327\n",
      "train loss:0.003967658313609599\n",
      "train loss:0.005193767363756835\n",
      "train loss:0.0023969070070216326\n",
      "train loss:0.011466675295503888\n",
      "train loss:0.004506306399854858\n",
      "train loss:0.005222651876813308\n",
      "train loss:0.020106482358684955\n",
      "train loss:0.0052849920850149435\n",
      "train loss:0.006931234320559659\n",
      "train loss:0.002154706185495582\n",
      "train loss:0.0036520093241124213\n",
      "train loss:0.001996669211772637\n",
      "train loss:0.004352911978365436\n",
      "train loss:0.0022844470948619796\n",
      "train loss:0.003044386403673847\n",
      "train loss:0.009701455878978716\n",
      "train loss:0.002653906621113551\n",
      "train loss:0.0017873362054868659\n",
      "train loss:0.03812057657194186\n",
      "train loss:0.001076393466073029\n",
      "train loss:0.004482046438826914\n",
      "train loss:0.008722401042028387\n",
      "train loss:0.02958675451699369\n",
      "train loss:0.004271347726246473\n",
      "train loss:0.02936220705848655\n",
      "train loss:0.01825207842035789\n",
      "train loss:0.0053146207969011015\n",
      "train loss:0.005542197249618891\n",
      "train loss:0.05018539782508504\n",
      "train loss:0.017718182524860265\n",
      "train loss:0.0036208017441071876\n",
      "train loss:0.0012901073515939388\n",
      "train loss:0.005960037680397386\n",
      "train loss:0.00034247233191748045\n",
      "train loss:0.010944437280576287\n",
      "train loss:0.0015136366854737252\n",
      "train loss:0.033255519416441455\n",
      "train loss:0.00685740655835301\n",
      "train loss:0.03886394824207758\n",
      "train loss:0.0010461862063936987\n",
      "train loss:0.000761703249737826\n",
      "train loss:0.008536134237073724\n",
      "train loss:0.0034867198823941388\n",
      "train loss:0.0030396893839994455\n",
      "train loss:0.012515728590523826\n",
      "train loss:0.012377341557872068\n",
      "train loss:0.016065492234043473\n",
      "train loss:0.000674336805542541\n",
      "train loss:0.011854116883219941\n",
      "train loss:0.006032082227395066\n",
      "train loss:0.004861321704110817\n",
      "train loss:0.004458791660660987\n",
      "train loss:0.008398432390920292\n",
      "train loss:0.0018904566669101733\n",
      "train loss:0.005193814806680468\n",
      "train loss:0.001893890106214658\n",
      "train loss:0.014387791923285797\n",
      "train loss:0.01104756155866478\n",
      "train loss:0.006275655926555967\n",
      "train loss:0.0053871883078304775\n",
      "train loss:0.008283171425973828\n",
      "train loss:0.009292112049649892\n",
      "train loss:0.003908207843706121\n",
      "train loss:0.003332482804965695\n",
      "train loss:0.008435863423951133\n",
      "train loss:0.01565507388828377\n",
      "train loss:0.0019303261329876409\n",
      "train loss:0.002253026929500878\n",
      "train loss:0.01321904673694726\n",
      "train loss:0.005066598781189642\n",
      "train loss:0.017740650137490755\n",
      "train loss:0.018823909556614015\n",
      "train loss:0.0029420027040857333\n",
      "train loss:0.009003034451393142\n",
      "train loss:0.010192610499542176\n",
      "train loss:0.003211184482002129\n",
      "train loss:0.0041452112780215105\n",
      "train loss:0.001796737559772027\n",
      "train loss:0.004106833839794842\n",
      "train loss:0.02462999784829055\n",
      "train loss:0.006255101253228431\n",
      "train loss:0.002216901395235198\n",
      "train loss:0.005084187227204235\n",
      "train loss:0.0037560566446377137\n",
      "train loss:0.0009259088982006121\n",
      "train loss:0.04204470575875757\n",
      "train loss:0.03866491209344851\n",
      "train loss:0.012899449872278545\n",
      "train loss:0.006443976356518429\n",
      "train loss:0.014704215374797365\n",
      "train loss:0.004312728004281056\n",
      "train loss:0.005999228773843916\n",
      "train loss:0.008454038211316397\n",
      "train loss:0.009114415106530207\n",
      "train loss:0.012358764261003557\n",
      "train loss:0.03683453684992974\n",
      "train loss:0.006346962013494269\n",
      "train loss:0.008450203109528107\n",
      "train loss:0.0008562425949152328\n",
      "train loss:0.006208423737184754\n",
      "train loss:0.0024582669643897306\n",
      "train loss:0.005219829005392095\n",
      "train loss:0.003975545467345244\n",
      "train loss:0.0014644601930507242\n",
      "train loss:0.007929529578874321\n",
      "train loss:0.010756571245370801\n",
      "train loss:0.0007987827170671362\n",
      "train loss:0.019676834653676856\n",
      "train loss:0.009679661304609295\n",
      "train loss:0.0013677771097273881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001744996881042707\n",
      "train loss:0.01218693069264144\n",
      "train loss:0.016890977158553717\n",
      "train loss:0.0017941234577648181\n",
      "train loss:0.0014323721052899416\n",
      "train loss:0.004086007585051002\n",
      "train loss:0.0023264005355233745\n",
      "train loss:0.004964062940996313\n",
      "train loss:0.005352525022062946\n",
      "train loss:0.004218882827000397\n",
      "train loss:0.011770083186907363\n",
      "train loss:0.0033559536422687565\n",
      "train loss:0.0038443315788267373\n",
      "train loss:0.00466019472336314\n",
      "train loss:0.0046014928075697814\n",
      "train loss:0.0013833797742480675\n",
      "train loss:0.0270603644798041\n",
      "train loss:0.0017508828912199813\n",
      "train loss:0.005552384878536742\n",
      "train loss:0.021483144759463668\n",
      "train loss:0.0022497489506966067\n",
      "train loss:0.0008458040035044482\n",
      "train loss:0.004389988395207552\n",
      "train loss:0.0015681691394694405\n",
      "train loss:0.0035129110763898247\n",
      "train loss:0.017750810150118895\n",
      "train loss:0.0010300721844325859\n",
      "train loss:0.003526261522376125\n",
      "train loss:0.014674201163746426\n",
      "train loss:0.0010009538368976757\n",
      "train loss:0.0027780734192363677\n",
      "train loss:0.007409883546222407\n",
      "train loss:0.0010616282743051678\n",
      "train loss:0.0036186986801212463\n",
      "train loss:0.0012721407088307443\n",
      "train loss:0.002456246598225231\n",
      "train loss:0.009953429460513887\n",
      "train loss:0.015191770927807706\n",
      "train loss:0.002157922684106419\n",
      "train loss:0.005099932189133524\n",
      "train loss:0.018760655604964756\n",
      "train loss:0.03661971194290699\n",
      "train loss:0.00810329856326288\n",
      "train loss:0.0033560640487955654\n",
      "train loss:0.003597623606172609\n",
      "train loss:0.002154253215792453\n",
      "train loss:0.008502820110824028\n",
      "train loss:0.05086546308382335\n",
      "train loss:0.002007789293055614\n",
      "train loss:0.008253269078497187\n",
      "train loss:0.027654959629822954\n",
      "train loss:0.009325469411934986\n",
      "train loss:0.013394478098394154\n",
      "train loss:0.0011645553170227206\n",
      "train loss:0.006256232319795187\n",
      "train loss:0.0038350285355639095\n",
      "train loss:0.0022956248811171497\n",
      "train loss:0.018152370157914866\n",
      "train loss:0.003248513913035397\n",
      "train loss:0.002324626116221291\n",
      "train loss:0.00899738045601222\n",
      "train loss:0.011555440623151563\n",
      "train loss:0.0010147938153922142\n",
      "train loss:0.0008075107116648709\n",
      "train loss:0.005881287510508862\n",
      "train loss:0.0018638342277416844\n",
      "train loss:0.00443264653342991\n",
      "train loss:0.0031288638475179863\n",
      "train loss:0.0051970784879805795\n",
      "train loss:0.0487408771223208\n",
      "train loss:0.002127535724633669\n",
      "train loss:0.0011093368939465906\n",
      "train loss:0.0020513007343011293\n",
      "train loss:0.032910417978821535\n",
      "train loss:0.022822519187972762\n",
      "train loss:0.0018772971535919282\n",
      "train loss:0.03916182155067049\n",
      "train loss:0.021671854597005255\n",
      "train loss:0.002494728722532363\n",
      "train loss:0.0010191626541961143\n",
      "train loss:0.025380294824449017\n",
      "train loss:0.0012012894915170108\n",
      "train loss:0.010613310651084219\n",
      "train loss:0.010643504831961397\n",
      "train loss:0.001981835468605602\n",
      "train loss:0.009314159512470983\n",
      "train loss:0.003178585328861114\n",
      "train loss:0.027638535535372613\n",
      "train loss:0.010447112646790678\n",
      "train loss:0.0010695279575933102\n",
      "train loss:0.025634965184685946\n",
      "train loss:0.002482538304866725\n",
      "train loss:0.0026931384431283854\n",
      "train loss:0.007836145804360126\n",
      "train loss:0.005659447710680764\n",
      "train loss:0.011278679700333917\n",
      "train loss:0.003211908793266264\n",
      "train loss:0.02290807834238835\n",
      "train loss:0.019463852039148646\n",
      "train loss:0.053389420833174536\n",
      "train loss:0.03030132158998079\n",
      "train loss:0.0008137367414512436\n",
      "train loss:0.007835752343059915\n",
      "train loss:0.0015951791223545028\n",
      "train loss:0.010879785683004527\n",
      "train loss:0.0013233497707460164\n",
      "train loss:0.007874915546570412\n",
      "train loss:0.007447213071229585\n",
      "train loss:0.03309017377508747\n",
      "train loss:0.020877602237504934\n",
      "train loss:0.009018882767942684\n",
      "train loss:0.004338390218406341\n",
      "train loss:0.0034005072608772136\n",
      "train loss:0.01350332296242763\n",
      "train loss:0.0026344509847366204\n",
      "train loss:0.027842242577618633\n",
      "train loss:0.019409060033083066\n",
      "train loss:0.010826838656777466\n",
      "train loss:0.0036446724239992596\n",
      "train loss:0.0021224470611251748\n",
      "train loss:0.001056479125641901\n",
      "train loss:0.005850714172296072\n",
      "train loss:0.0030653740418706433\n",
      "train loss:0.008187134601396756\n",
      "train loss:0.007408755002107765\n",
      "train loss:0.00754431056354781\n",
      "train loss:0.0019527704244991586\n",
      "train loss:0.009703593266270252\n",
      "train loss:0.001668376384459885\n",
      "train loss:0.01069829619519135\n",
      "train loss:0.009000288680494786\n",
      "train loss:0.003590947726388976\n",
      "train loss:0.0015878275785825985\n",
      "train loss:0.01803823942762371\n",
      "train loss:0.003358306635289142\n",
      "train loss:0.009193072090890852\n",
      "train loss:0.02509213610069609\n",
      "train loss:0.002443420493530658\n",
      "train loss:0.0009683810194288256\n",
      "train loss:0.0038420712967893113\n",
      "train loss:0.0013833578361738502\n",
      "train loss:0.006297964531491277\n",
      "train loss:0.014482379943862714\n",
      "train loss:0.007583605137055272\n",
      "train loss:0.00191037646808817\n",
      "train loss:0.025734128965002094\n",
      "train loss:0.0019987743508260987\n",
      "train loss:0.001859344221918574\n",
      "train loss:0.003727697545721619\n",
      "train loss:0.014770402735425634\n",
      "train loss:0.0011262805580926282\n",
      "train loss:0.0033871607116047527\n",
      "train loss:0.0012646712971376814\n",
      "train loss:0.009568449285153057\n",
      "train loss:0.002255537620460112\n",
      "train loss:0.010327089287634365\n",
      "train loss:0.013747512473674037\n",
      "train loss:0.002378402827103556\n",
      "train loss:0.0015497551753736452\n",
      "train loss:0.0174695178937889\n",
      "train loss:0.0024900595855834942\n",
      "train loss:0.01970023986012811\n",
      "train loss:0.0024227137446449693\n",
      "train loss:0.008692463215862287\n",
      "train loss:0.004559069809960464\n",
      "train loss:0.002719894331930349\n",
      "train loss:0.017930096558832806\n",
      "train loss:0.006994107811071052\n",
      "train loss:0.004830107325211533\n",
      "train loss:0.0063771994841187955\n",
      "train loss:0.015118987423398149\n",
      "train loss:0.005194717348558178\n",
      "train loss:0.008318378472585675\n",
      "train loss:0.10837056854253914\n",
      "train loss:0.0010154545537221932\n",
      "train loss:0.004212658739910713\n",
      "train loss:0.018692819201917902\n",
      "train loss:0.0017035970656380415\n",
      "train loss:0.011106382377010974\n",
      "train loss:0.006521486468682972\n",
      "train loss:0.031519993082448655\n",
      "train loss:0.012986413848536263\n",
      "train loss:0.00897232640336818\n",
      "train loss:0.011345112268141713\n",
      "train loss:0.0072689651893375175\n",
      "train loss:0.0050202628619485\n",
      "train loss:0.006465320999522989\n",
      "train loss:0.0012135628784151306\n",
      "train loss:0.04125271931431928\n",
      "train loss:0.004017685715067829\n",
      "train loss:0.04361241770665734\n",
      "train loss:0.011664170916831185\n",
      "train loss:0.002743456618253606\n",
      "train loss:0.007595271866420723\n",
      "train loss:0.001150594943879734\n",
      "train loss:0.004929082630727963\n",
      "train loss:0.006093150082221145\n",
      "train loss:0.033449823716843546\n",
      "train loss:0.008863290466356121\n",
      "train loss:0.005720788129614084\n",
      "train loss:0.01721762682712658\n",
      "train loss:0.0027113461749291323\n",
      "train loss:0.004657876925017547\n",
      "train loss:0.0075659395929258185\n",
      "train loss:0.004085254289951718\n",
      "train loss:0.004452859812882751\n",
      "train loss:0.0023700655056349772\n",
      "train loss:0.015183322835046585\n",
      "train loss:0.007002002274539807\n",
      "train loss:0.026342873498268794\n",
      "train loss:0.004983175233683427\n",
      "train loss:0.012330834975701194\n",
      "train loss:0.011654123256258038\n",
      "train loss:0.011740587242403781\n",
      "train loss:0.016442450877395404\n",
      "train loss:0.013306289174640752\n",
      "train loss:0.0011202071800682214\n",
      "train loss:0.010021592921226882\n",
      "train loss:0.010835675880657281\n",
      "train loss:0.0018532653054474705\n",
      "train loss:0.0006531598805906108\n",
      "train loss:0.011903747813123693\n",
      "train loss:0.008314077793776516\n",
      "train loss:0.09542757289815745\n",
      "train loss:0.0015743274285709733\n",
      "train loss:0.012522168510616005\n",
      "train loss:0.010975532720438228\n",
      "train loss:0.01079800517976398\n",
      "train loss:0.003793984071480709\n",
      "train loss:0.011522338469807101\n",
      "train loss:0.015972296336772482\n",
      "train loss:0.007949529942253883\n",
      "train loss:0.0012381866251198377\n",
      "train loss:0.012295470376184097\n",
      "train loss:0.020564945668317722\n",
      "train loss:0.010099747158004163\n",
      "train loss:0.024609206717696074\n",
      "train loss:0.01013725772572046\n",
      "train loss:0.004844316313229213\n",
      "train loss:0.003502708475768638\n",
      "train loss:0.005860849782063863\n",
      "train loss:0.002460472799247403\n",
      "train loss:0.006874936516574683\n",
      "train loss:0.019326933211277014\n",
      "train loss:0.05503534500863603\n",
      "train loss:0.007211850569605112\n",
      "train loss:0.0011640917048970029\n",
      "train loss:0.002322743636543506\n",
      "train loss:0.0008339691347595215\n",
      "train loss:0.009708789055970618\n",
      "train loss:0.0032790687317152357\n",
      "train loss:0.005462820337010577\n",
      "train loss:0.01002399322975963\n",
      "train loss:0.002172401373433177\n",
      "train loss:0.04029300845382048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006173577037219062\n",
      "train loss:0.0024466983447315187\n",
      "train loss:0.02670516054709509\n",
      "train loss:0.025186964367425197\n",
      "train loss:0.003127202312551683\n",
      "train loss:0.01258042507637269\n",
      "train loss:0.012945322854959439\n",
      "train loss:0.0003666876265578401\n",
      "train loss:0.03007576983779639\n",
      "train loss:0.0007023442292339837\n",
      "train loss:0.009317162830092108\n",
      "train loss:0.02799674616900559\n",
      "train loss:0.008107733914262867\n",
      "train loss:0.007267589057614556\n",
      "train loss:0.02733039369536112\n",
      "train loss:0.00889466910886955\n",
      "train loss:0.00896905109959321\n",
      "train loss:0.04025349820883202\n",
      "train loss:0.022070998702545183\n",
      "train loss:0.009362030043632402\n",
      "train loss:0.006620858968264539\n",
      "train loss:0.0022784606615491396\n",
      "=== epoch:11, train acc:0.991, test acc:0.983 ===\n",
      "train loss:0.00776948024090144\n",
      "train loss:0.004670067857044437\n",
      "train loss:0.014023227502656943\n",
      "train loss:0.017457985588719388\n",
      "train loss:0.009476532063132368\n",
      "train loss:0.009283243847433863\n",
      "train loss:0.004094368663114983\n",
      "train loss:0.008594947375412861\n",
      "train loss:0.004845439494178484\n",
      "train loss:0.0028278506791868975\n",
      "train loss:0.012963324161159877\n",
      "train loss:0.0015707892876473306\n",
      "train loss:0.01644165513192335\n",
      "train loss:0.002954118333647038\n",
      "train loss:0.0006072760486789718\n",
      "train loss:0.0015263495101260965\n",
      "train loss:0.004112485064165923\n",
      "train loss:0.003246702489441589\n",
      "train loss:0.0017130777559086355\n",
      "train loss:0.016774817261764108\n",
      "train loss:0.0030513518088244995\n",
      "train loss:0.07119276911297004\n",
      "train loss:0.0017994654007397262\n",
      "train loss:0.008277636659176042\n",
      "train loss:0.0015222943614086365\n",
      "train loss:0.014261819887897908\n",
      "train loss:0.03167304583852329\n",
      "train loss:0.013775593526647607\n",
      "train loss:0.010360705759611219\n",
      "train loss:0.0012388517060742878\n",
      "train loss:0.011869005087882675\n",
      "train loss:0.003663572670085134\n",
      "train loss:0.0023716605360411414\n",
      "train loss:0.0009722366189077222\n",
      "train loss:0.010019114678953146\n",
      "train loss:0.017807153543721997\n",
      "train loss:0.001369992691235255\n",
      "train loss:0.0032159048552075947\n",
      "train loss:0.06234177536411607\n",
      "train loss:0.008322498746248644\n",
      "train loss:0.011213423561116233\n",
      "train loss:0.002331539471893072\n",
      "train loss:0.001519582191469105\n",
      "train loss:0.002393208502943045\n",
      "train loss:0.0017433067716959643\n",
      "train loss:0.006449418615606538\n",
      "train loss:0.0038844597185267236\n",
      "train loss:0.028378297081069436\n",
      "train loss:0.004867190471506493\n",
      "train loss:0.09656953869648546\n",
      "train loss:0.015421596337950521\n",
      "train loss:0.012290271046649584\n",
      "train loss:0.002992374679099164\n",
      "train loss:0.0036839743946563367\n",
      "train loss:0.0033397603915308353\n",
      "train loss:0.00693249607371247\n",
      "train loss:0.011796775544054257\n",
      "train loss:0.01966946872060622\n",
      "train loss:0.011305878584105788\n",
      "train loss:0.013845241580703414\n",
      "train loss:0.003966913454963384\n",
      "train loss:0.009927390802954355\n",
      "train loss:0.0013388169317502814\n",
      "train loss:0.003840603967510671\n",
      "train loss:0.0075000420963738\n",
      "train loss:0.008351678342767413\n",
      "train loss:0.005044672741533671\n",
      "train loss:0.0014104973845363536\n",
      "train loss:0.00365611840673692\n",
      "train loss:0.004848450837870058\n",
      "train loss:0.0005248101871907496\n",
      "train loss:0.006833089458324612\n",
      "train loss:0.004085179690157223\n",
      "train loss:0.0050308606498108265\n",
      "train loss:0.005385352590481888\n",
      "train loss:0.009652572309706158\n",
      "train loss:0.01883986282413073\n",
      "train loss:0.0027124643202493643\n",
      "train loss:0.0252107070962435\n",
      "train loss:0.003602805796782956\n",
      "train loss:0.006556380170606401\n",
      "train loss:0.020902472876346417\n",
      "train loss:0.008157452663048435\n",
      "train loss:0.00396046174489866\n",
      "train loss:0.0020027795379752044\n",
      "train loss:0.0012618711162027288\n",
      "train loss:0.03061839917849275\n",
      "train loss:0.05242707294916578\n",
      "train loss:0.0015980244445611403\n",
      "train loss:0.017475343321856688\n",
      "train loss:0.013650723212388211\n",
      "train loss:0.005940256448085299\n",
      "train loss:0.008477929596360814\n",
      "train loss:0.07081019142188147\n",
      "train loss:0.012718104200050756\n",
      "train loss:0.0038594120487651885\n",
      "train loss:0.010362440322084904\n",
      "train loss:0.017249333243378212\n",
      "train loss:0.0016620223443801075\n",
      "train loss:0.001016283465469011\n",
      "train loss:0.00431764407869565\n",
      "train loss:0.004719516014137027\n",
      "train loss:0.0440222346736176\n",
      "train loss:0.0023901434254889106\n",
      "train loss:0.01674358710041114\n",
      "train loss:0.005693416575270754\n",
      "train loss:0.011614025545945244\n",
      "train loss:0.011556388543533452\n",
      "train loss:0.02015561979190128\n",
      "train loss:0.010418184923237145\n",
      "train loss:0.008149211793051506\n",
      "train loss:0.0019398047372750403\n",
      "train loss:0.00469796327216971\n",
      "train loss:0.0011090451440300608\n",
      "train loss:0.00410640386960923\n",
      "train loss:0.008638433143447706\n",
      "train loss:0.004529289377706288\n",
      "train loss:0.0020853370254689317\n",
      "train loss:0.004088548314005332\n",
      "train loss:0.008696790003489824\n",
      "train loss:0.013593884248612664\n",
      "train loss:0.002552334009886169\n",
      "train loss:0.00812428262289897\n",
      "train loss:0.00620700400873414\n",
      "train loss:0.004604102584651469\n",
      "train loss:0.004352311670317805\n",
      "train loss:0.005483326495617613\n",
      "train loss:0.006032171640288979\n",
      "train loss:0.02782974018296788\n",
      "train loss:0.014183990205326904\n",
      "train loss:0.00206401135446808\n",
      "train loss:0.010155623458769525\n",
      "train loss:0.013729761601773605\n",
      "train loss:0.005149300380262705\n",
      "train loss:0.003817298246173438\n",
      "train loss:0.009638980695408663\n",
      "train loss:0.004877492854979851\n",
      "train loss:0.05831742119628863\n",
      "train loss:0.01483962906960287\n",
      "train loss:0.004336907123445447\n",
      "train loss:0.00831118048959562\n",
      "train loss:0.012905123733604789\n",
      "train loss:0.0011707411205015136\n",
      "train loss:0.007333170251535939\n",
      "train loss:0.004218476772107564\n",
      "train loss:0.004333070508756731\n",
      "train loss:0.0016124353463333454\n",
      "train loss:0.018607136682445354\n",
      "train loss:0.00907586445521389\n",
      "train loss:0.006200237693153953\n",
      "train loss:0.010737730424105873\n",
      "train loss:0.00736521356176277\n",
      "train loss:0.010396835420133858\n",
      "train loss:0.014545390137743737\n",
      "train loss:0.0009028335860370545\n",
      "train loss:0.0018414188271906468\n",
      "train loss:0.0019035375958591219\n",
      "train loss:0.003417777260768308\n",
      "train loss:0.05325204953648604\n",
      "train loss:0.034796242296428324\n",
      "train loss:0.04102957626716193\n",
      "train loss:0.003275674927595786\n",
      "train loss:0.0024381265094924665\n",
      "train loss:0.001955120476397138\n",
      "train loss:0.010851649524941574\n",
      "train loss:0.06213560560287038\n",
      "train loss:0.005087884840566041\n",
      "train loss:0.004854893030854864\n",
      "train loss:0.01601640892194083\n",
      "train loss:0.053157487459205094\n",
      "train loss:0.010754314296820363\n",
      "train loss:0.001232916181175473\n",
      "train loss:0.003834607100263609\n",
      "train loss:0.005838736383961707\n",
      "train loss:0.007405807656905113\n",
      "train loss:0.002689421862986407\n",
      "train loss:0.004097408013869659\n",
      "train loss:0.019302696049170728\n",
      "train loss:0.008478281309679118\n",
      "train loss:0.00907153887382372\n",
      "train loss:0.014262524313126348\n",
      "train loss:0.0056052212865880776\n",
      "train loss:0.0057390907584659355\n",
      "train loss:0.0031447317588554923\n",
      "train loss:0.010111756920967063\n",
      "train loss:0.03575545210533359\n",
      "train loss:0.004126857610369015\n",
      "train loss:0.0054116586248611894\n",
      "train loss:0.01025430843358529\n",
      "train loss:0.010398312354639238\n",
      "train loss:0.023353045965936573\n",
      "train loss:0.003291456597953328\n",
      "train loss:0.006144243662170261\n",
      "train loss:0.02060260422637636\n",
      "train loss:0.005921599726788699\n",
      "train loss:0.02115757745599661\n",
      "train loss:0.010803192581624215\n",
      "train loss:0.01364008842289693\n",
      "train loss:0.003453389268124879\n",
      "train loss:0.0023665733211030424\n",
      "train loss:0.0037093968291554893\n",
      "train loss:0.002367036316390812\n",
      "train loss:0.0017925666125657947\n",
      "train loss:0.005813150766663721\n",
      "train loss:0.0007808994501255404\n",
      "train loss:0.025428858643731483\n",
      "train loss:0.001618187602292249\n",
      "train loss:0.0013370416615939354\n",
      "train loss:0.010855256411952306\n",
      "train loss:0.0017849403720694224\n",
      "train loss:0.00567652151074869\n",
      "train loss:0.0032945316893146755\n",
      "train loss:0.0026927648162620964\n",
      "train loss:0.004820903379873494\n",
      "train loss:0.011558325298098242\n",
      "train loss:0.021244831659889312\n",
      "train loss:0.01023063083707347\n",
      "train loss:0.011457068369537405\n",
      "train loss:0.00816565981360097\n",
      "train loss:0.002049138289568825\n",
      "train loss:0.014580345260444771\n",
      "train loss:0.0036769904973095392\n",
      "train loss:0.0017179032430770793\n",
      "train loss:0.005593735683493278\n",
      "train loss:0.004756867442120418\n",
      "train loss:0.001435147899529115\n",
      "train loss:0.007976995795522341\n",
      "train loss:0.0051262096409464605\n",
      "train loss:0.001864040329631619\n",
      "train loss:0.0014866839890672436\n",
      "train loss:0.010879636034697026\n",
      "train loss:0.04673036360027228\n",
      "train loss:0.002837505802355725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001772608526821584\n",
      "train loss:0.006955462828259857\n",
      "train loss:0.0010867668435112182\n",
      "train loss:0.00551281629690074\n",
      "train loss:0.004381915528837837\n",
      "train loss:0.008506498160835825\n",
      "train loss:0.0021515659212039354\n",
      "train loss:0.011342953425049176\n",
      "train loss:0.0056527703454389965\n",
      "train loss:0.0028774328839927784\n",
      "train loss:0.0034666343888797536\n",
      "train loss:0.0048830845608470955\n",
      "train loss:0.004609989568129664\n",
      "train loss:0.004806940221168984\n",
      "train loss:0.003980117417083111\n",
      "train loss:0.004989506010338504\n",
      "train loss:0.0017975178657267804\n",
      "train loss:0.001414745557023897\n",
      "train loss:0.011505570324305906\n",
      "train loss:0.015239052510217167\n",
      "train loss:0.0004911275108676412\n",
      "train loss:0.0020245870424944476\n",
      "train loss:0.012744239204867131\n",
      "train loss:0.006726440639659449\n",
      "train loss:0.0016478454911011584\n",
      "train loss:0.0016716247275360846\n",
      "train loss:0.008306462302250761\n",
      "train loss:0.0017345906182505957\n",
      "train loss:0.0021687343463351934\n",
      "train loss:0.02537017080343795\n",
      "train loss:0.011918412520879954\n",
      "train loss:0.007606731644814802\n",
      "train loss:0.004762858345959626\n",
      "train loss:0.0005985121172247868\n",
      "train loss:0.004071485132326233\n",
      "train loss:0.0031071079065107437\n",
      "train loss:0.0061550670447987985\n",
      "train loss:0.006142179963357589\n",
      "train loss:0.013668838338222928\n",
      "train loss:0.0008330705978013453\n",
      "train loss:0.005753645972542316\n",
      "train loss:0.0008337300088567862\n",
      "train loss:0.009289985453167308\n",
      "train loss:0.003272591239919726\n",
      "train loss:0.0035018447860201683\n",
      "train loss:0.0008238172063875952\n",
      "train loss:0.0005082573411847967\n",
      "train loss:0.0011610235839992402\n",
      "train loss:0.0006237091438178599\n",
      "train loss:0.0028697582548509975\n",
      "train loss:0.004505679798239215\n",
      "train loss:0.006529869554735195\n",
      "train loss:0.0032883683565268825\n",
      "train loss:0.009794652701373753\n",
      "train loss:0.027796870065660645\n",
      "train loss:0.012704572740103774\n",
      "train loss:0.008000877136050863\n",
      "train loss:0.001735448484462182\n",
      "train loss:0.048326448586523234\n",
      "train loss:0.004528101820991639\n",
      "train loss:0.008239820471792801\n",
      "train loss:0.004336207269852288\n",
      "train loss:0.001819763057454112\n",
      "train loss:0.011360043538974861\n",
      "train loss:0.03185521123521929\n",
      "train loss:0.0015533390650669923\n",
      "train loss:0.0031785382928255913\n",
      "train loss:0.011038131904129047\n",
      "train loss:0.012996707508869752\n",
      "train loss:0.0020428272451727806\n",
      "train loss:0.004012115803994096\n",
      "train loss:0.019226919793124554\n",
      "train loss:0.008971846021092017\n",
      "train loss:0.010492486406524662\n",
      "train loss:0.007089960599810045\n",
      "train loss:0.008903495322300371\n",
      "train loss:0.004271978697101688\n",
      "train loss:0.0024854086600780197\n",
      "train loss:0.0012573923971044459\n",
      "train loss:0.004271478322515524\n",
      "train loss:0.0039074207702745065\n",
      "train loss:0.0009625061747652117\n",
      "train loss:0.0003597760473477928\n",
      "train loss:0.0036421535233421938\n",
      "train loss:0.004213693061368808\n",
      "train loss:0.0006677017272645277\n",
      "train loss:0.0025585271770965133\n",
      "train loss:0.013938828887924219\n",
      "train loss:0.015625666893109947\n",
      "train loss:0.010789663837652032\n",
      "train loss:0.0007803445655673446\n",
      "train loss:0.028297035017950122\n",
      "train loss:0.0011341951512679783\n",
      "train loss:0.0053162678137731526\n",
      "train loss:0.0056466562825084835\n",
      "train loss:0.012825567589498831\n",
      "train loss:0.0030157360026618475\n",
      "train loss:0.036833849680939855\n",
      "train loss:0.0036598670052214476\n",
      "train loss:0.0018187146285905966\n",
      "train loss:0.012193512431643206\n",
      "train loss:0.029136525244519193\n",
      "train loss:0.001021279644388594\n",
      "train loss:0.004619239063442046\n",
      "train loss:0.01694102505282777\n",
      "train loss:0.0036776017271080317\n",
      "train loss:0.0011776330293863065\n",
      "train loss:0.013192498189324345\n",
      "train loss:0.002729797323378552\n",
      "train loss:0.0034077137106892762\n",
      "train loss:0.002561243180391048\n",
      "train loss:0.0020784819528025956\n",
      "train loss:0.002649779485109255\n",
      "train loss:0.0023781788795549873\n",
      "train loss:0.003734441224698461\n",
      "train loss:0.0057762222633301885\n",
      "train loss:0.002273337546725711\n",
      "train loss:0.004329396275061902\n",
      "train loss:0.003821163285001438\n",
      "train loss:0.00681280754741873\n",
      "train loss:0.005164319191490237\n",
      "train loss:0.00475733667517037\n",
      "train loss:0.005003787014702313\n",
      "train loss:0.004052806148056224\n",
      "train loss:0.002593074221773696\n",
      "train loss:0.0021792402268024313\n",
      "train loss:0.009029750689488863\n",
      "train loss:0.004229049529144865\n",
      "train loss:0.002311867607191149\n",
      "train loss:0.0013981648073270333\n",
      "train loss:0.011075849145098158\n",
      "train loss:0.009340742050857703\n",
      "train loss:0.0005788145359291991\n",
      "train loss:0.006286521567037794\n",
      "train loss:0.011351797669920565\n",
      "train loss:0.005539920463902844\n",
      "train loss:0.03188169277074866\n",
      "train loss:0.0004437734252602532\n",
      "train loss:0.006464240142159019\n",
      "train loss:0.008290148172146204\n",
      "train loss:0.0004678083783618366\n",
      "train loss:0.0033893545249926247\n",
      "train loss:0.005108250910310265\n",
      "train loss:0.0036595356986413056\n",
      "train loss:0.018042324519943767\n",
      "train loss:0.003525720841115637\n",
      "train loss:0.007241006218459568\n",
      "train loss:0.010171511309457275\n",
      "train loss:0.0013355720307620831\n",
      "train loss:0.0044048224627935275\n",
      "train loss:0.0012850568163405049\n",
      "train loss:0.001988618130717387\n",
      "train loss:0.0013404647816854123\n",
      "train loss:0.016187006836724856\n",
      "train loss:0.002898928323171643\n",
      "train loss:0.006368947720285377\n",
      "train loss:0.01685635719777647\n",
      "train loss:0.0013452324322202277\n",
      "train loss:0.005775567170255901\n",
      "train loss:0.006270365137795304\n",
      "train loss:0.003959739692194219\n",
      "train loss:0.023069756946013906\n",
      "train loss:0.01588012849689848\n",
      "train loss:0.00581203854134318\n",
      "train loss:0.003719410246376341\n",
      "train loss:0.0006083054212664167\n",
      "train loss:0.05855413899526081\n",
      "train loss:0.0011886374449141918\n",
      "train loss:0.004118062180944119\n",
      "train loss:0.0011598904518798094\n",
      "train loss:0.0012668043881870214\n",
      "train loss:0.005047865784536881\n",
      "train loss:0.0009747076548370465\n",
      "train loss:0.00762311588474523\n",
      "train loss:0.007956764694880856\n",
      "train loss:0.003490620075698669\n",
      "train loss:0.002020460108399008\n",
      "train loss:0.028427623953026195\n",
      "train loss:0.0015006817545129471\n",
      "train loss:0.006719564775208305\n",
      "train loss:0.028270469770654047\n",
      "train loss:0.000945901395748456\n",
      "train loss:0.010872977174694072\n",
      "train loss:0.006393907691500957\n",
      "train loss:0.0021196736052678062\n",
      "train loss:0.0034310559775476224\n",
      "train loss:0.007314043533601358\n",
      "train loss:0.007078988779502744\n",
      "train loss:0.007489212776793378\n",
      "train loss:0.0023141481717911788\n",
      "train loss:0.005800542382630993\n",
      "train loss:0.001648752332334483\n",
      "train loss:0.0031228432950487655\n",
      "train loss:0.0006414313349167508\n",
      "train loss:0.00010341691017554711\n",
      "train loss:0.003181436489366557\n",
      "train loss:0.0029993541089153057\n",
      "train loss:0.0006786361959255466\n",
      "train loss:0.0015657476345520519\n",
      "train loss:0.000832001321829558\n",
      "train loss:0.006842802069301679\n",
      "train loss:0.003141415468183833\n",
      "train loss:0.0035768059264154033\n",
      "train loss:0.009446213761544524\n",
      "train loss:0.005447401946494371\n",
      "train loss:0.012823386322735083\n",
      "train loss:0.002645573984998614\n",
      "train loss:0.001372608109720732\n",
      "train loss:0.008264058968918814\n",
      "train loss:0.0039260636929295606\n",
      "train loss:0.0024202108749588986\n",
      "train loss:0.0010968488030573406\n",
      "train loss:0.009988191638073034\n",
      "train loss:0.0022521949493324463\n",
      "train loss:0.00821566861114138\n",
      "train loss:0.004226625204442292\n",
      "train loss:0.016072958990922825\n",
      "train loss:0.007054914312722439\n",
      "train loss:0.003956933205510446\n",
      "train loss:0.0005955635460116147\n",
      "train loss:0.025451122737847616\n",
      "train loss:0.007681889501461151\n",
      "train loss:0.002574715495603092\n",
      "train loss:0.009082358215779988\n",
      "train loss:0.0031598643607321873\n",
      "train loss:0.0003170944722618038\n",
      "train loss:0.00397284643706325\n",
      "train loss:0.0010341492100204874\n",
      "train loss:0.010708783933708211\n",
      "train loss:0.004674895091009273\n",
      "train loss:0.00023305723899730182\n",
      "train loss:0.017505681276343162\n",
      "train loss:0.0013873981181023636\n",
      "train loss:0.0035731948468283943\n",
      "train loss:0.0027125032709076897\n",
      "train loss:0.001709129770119557\n",
      "train loss:0.0037258019565639634\n",
      "train loss:0.008818346275987163\n",
      "train loss:0.001962228745806379\n",
      "train loss:0.0036348570786224237\n",
      "train loss:0.004054044988100544\n",
      "train loss:0.0038040377894272776\n",
      "train loss:0.0027753696337002283\n",
      "train loss:0.00011757405728819056\n",
      "train loss:0.005403725110182341\n",
      "train loss:0.0008021675993990388\n",
      "train loss:0.0012435285390712835\n",
      "train loss:0.0014216187628282577\n",
      "train loss:0.005820754742292334\n",
      "train loss:0.006471725645432618\n",
      "train loss:0.002162572240527494\n",
      "train loss:0.0019540799544056006\n",
      "train loss:0.0037080492950804906\n",
      "train loss:0.010415947687956593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010465833958798894\n",
      "train loss:0.0018570144483876774\n",
      "train loss:0.002383157362786404\n",
      "train loss:0.001968452072053101\n",
      "train loss:0.014306770837133385\n",
      "train loss:0.055073599043198584\n",
      "train loss:0.0015597156229558515\n",
      "train loss:0.010385422882371653\n",
      "train loss:0.0013135998398425823\n",
      "train loss:0.010021871777644464\n",
      "train loss:0.0035600644103722036\n",
      "train loss:0.0018961676419710987\n",
      "train loss:0.0007704789292578465\n",
      "train loss:0.01808297437364637\n",
      "train loss:0.03192668051547848\n",
      "train loss:0.0018299685742603307\n",
      "train loss:0.011376428357802906\n",
      "train loss:0.0026001057254869107\n",
      "train loss:0.004008313480757036\n",
      "train loss:0.0010019859901781803\n",
      "train loss:0.0010747332736393163\n",
      "train loss:0.0005290014445846574\n",
      "train loss:0.004603451037662318\n",
      "train loss:0.013598461198490253\n",
      "train loss:0.0022091288739255655\n",
      "train loss:0.0019248869154825637\n",
      "train loss:0.002467719309501559\n",
      "train loss:0.002396255604745747\n",
      "train loss:0.010598525478966144\n",
      "train loss:0.0020413930594884466\n",
      "train loss:0.0020033407991876307\n",
      "train loss:0.0062142722964651145\n",
      "train loss:0.002032356522560394\n",
      "train loss:0.001592350522765925\n",
      "train loss:0.007440829982250211\n",
      "train loss:0.0013029269760848833\n",
      "train loss:0.00646094922357171\n",
      "train loss:0.014983734165882454\n",
      "train loss:0.013184418155352184\n",
      "train loss:0.005075890545898369\n",
      "train loss:0.013674241074593934\n",
      "train loss:0.005026295008776378\n",
      "train loss:0.0018228309571932772\n",
      "train loss:0.0017292129676180238\n",
      "train loss:0.008103357313071139\n",
      "train loss:0.024596964521763232\n",
      "train loss:0.0006256016839764827\n",
      "train loss:0.003332204266892156\n",
      "train loss:0.008176892969949447\n",
      "train loss:0.04670309374753533\n",
      "train loss:0.007368214216493148\n",
      "train loss:0.04876057047586038\n",
      "train loss:0.0024797130786735483\n",
      "train loss:0.010363536208114255\n",
      "train loss:0.0019419059584634482\n",
      "train loss:0.0013398925450134104\n",
      "train loss:0.004213355336766665\n",
      "train loss:0.01794093778970672\n",
      "train loss:0.0004489121467563994\n",
      "train loss:0.0006796695377319174\n",
      "train loss:0.0033200349224284764\n",
      "train loss:0.00787104903466394\n",
      "train loss:0.004228507281550717\n",
      "train loss:0.003423563170846812\n",
      "train loss:0.008784258132002424\n",
      "train loss:0.00732896441708516\n",
      "train loss:0.0022138773785791337\n",
      "train loss:0.002465159826452577\n",
      "train loss:0.03017312808639391\n",
      "train loss:0.01110992491691818\n",
      "train loss:0.030062449557565124\n",
      "train loss:0.002303270887589621\n",
      "train loss:0.023818475438725797\n",
      "train loss:0.014079642613472514\n",
      "train loss:0.004677717905767032\n",
      "train loss:0.003685533218387319\n",
      "train loss:0.0019487274395996845\n",
      "train loss:0.011835387413893417\n",
      "train loss:0.037275373674772426\n",
      "train loss:0.009049033940486144\n",
      "train loss:0.005413510278756628\n",
      "train loss:0.0026902508198960074\n",
      "train loss:0.0021600881712142256\n",
      "train loss:0.014753492606268306\n",
      "train loss:0.0018126574408944957\n",
      "train loss:0.0007280776618727149\n",
      "train loss:0.006948725799620776\n",
      "train loss:0.007726717614477081\n",
      "train loss:0.0047870416813058925\n",
      "train loss:0.0015632792572225999\n",
      "train loss:0.0008919152429639493\n",
      "train loss:0.012357050175162459\n",
      "train loss:0.0023416544222209824\n",
      "train loss:0.002738532969878687\n",
      "train loss:0.010853217140101108\n",
      "train loss:0.0020659095235208112\n",
      "train loss:0.0037198917047696345\n",
      "train loss:0.00778689018560306\n",
      "train loss:0.0010379334368224831\n",
      "train loss:0.003165186455274229\n",
      "train loss:0.0022214742688268342\n",
      "train loss:0.010371505058029537\n",
      "train loss:0.0009743378047699303\n",
      "train loss:0.00010542452054799437\n",
      "train loss:0.0006184279978033345\n",
      "train loss:0.0025428873960891022\n",
      "train loss:0.011498347704056926\n",
      "train loss:0.0013306697579224694\n",
      "train loss:0.001356965460905289\n",
      "train loss:0.0035796618262515924\n",
      "train loss:0.014322456949945068\n",
      "train loss:0.0009920209579838332\n",
      "train loss:0.0022675648698443724\n",
      "=== epoch:12, train acc:0.996, test acc:0.987 ===\n",
      "train loss:0.005416319973508757\n",
      "train loss:0.01911110177355446\n",
      "train loss:0.0034317891441297266\n",
      "train loss:0.004947919608370778\n",
      "train loss:0.044754518972188746\n",
      "train loss:0.003263914653178629\n",
      "train loss:0.0074342666208532734\n",
      "train loss:0.0046643381759982885\n",
      "train loss:0.0015552602844503853\n",
      "train loss:0.006846687169372971\n",
      "train loss:0.0021649835550056015\n",
      "train loss:0.004495153951402362\n",
      "train loss:0.00501757658443623\n",
      "train loss:0.00165690912130037\n",
      "train loss:0.002926354123531925\n",
      "train loss:0.005913513119114381\n",
      "train loss:9.932648314016276e-05\n",
      "train loss:0.0008857967476036514\n",
      "train loss:0.041541069913118456\n",
      "train loss:0.0005837695231436437\n",
      "train loss:0.0005971378915005134\n",
      "train loss:0.003149079317099273\n",
      "train loss:0.0038743529700593633\n",
      "train loss:0.010663540816535026\n",
      "train loss:0.006194798097610855\n",
      "train loss:0.004139024376162579\n",
      "train loss:0.0011827361704408181\n",
      "train loss:0.004623366787676613\n",
      "train loss:0.0017615183201862194\n",
      "train loss:0.010201885384701615\n",
      "train loss:0.0031845381133976127\n",
      "train loss:0.010919346250695725\n",
      "train loss:0.0038264777253899903\n",
      "train loss:0.007302743703049833\n",
      "train loss:0.0015800725964422667\n",
      "train loss:0.0018905050451925877\n",
      "train loss:0.023031342354190944\n",
      "train loss:0.002864904027100631\n",
      "train loss:0.0006286731006574713\n",
      "train loss:0.027025886651401817\n",
      "train loss:0.00013004247922693968\n",
      "train loss:0.012716589515975943\n",
      "train loss:0.008807281375969811\n",
      "train loss:0.006601160285325824\n",
      "train loss:0.012659099702361416\n",
      "train loss:0.006890621503414693\n",
      "train loss:0.0038175043773591485\n",
      "train loss:0.004508516159335059\n",
      "train loss:0.0006674576292839414\n",
      "train loss:0.003386858723499172\n",
      "train loss:0.008092956874468094\n",
      "train loss:0.012415013721338053\n",
      "train loss:0.019814195626186495\n",
      "train loss:0.003072952091721899\n",
      "train loss:0.004457201543577597\n",
      "train loss:0.0006290166746873763\n",
      "train loss:0.0016651070934472145\n",
      "train loss:0.007931124792012516\n",
      "train loss:0.00039753814489060615\n",
      "train loss:0.011338284055453611\n",
      "train loss:0.00212494961007428\n",
      "train loss:0.0015030339292754693\n",
      "train loss:0.0013607876928882143\n",
      "train loss:0.0010646886011820846\n",
      "train loss:0.0018849220496869818\n",
      "train loss:0.0014490928646399433\n",
      "train loss:0.007296320396186124\n",
      "train loss:0.013083315115050516\n",
      "train loss:0.008267872694346468\n",
      "train loss:0.0018946257454220399\n",
      "train loss:0.008782407232300789\n",
      "train loss:0.0018981404063958473\n",
      "train loss:0.00019588139319886636\n",
      "train loss:0.0022999114192550287\n",
      "train loss:0.007518969110722385\n",
      "train loss:0.00240903858797128\n",
      "train loss:0.013517236367447949\n",
      "train loss:0.0016382246849209051\n",
      "train loss:0.004072197887501064\n",
      "train loss:0.0005340772575643292\n",
      "train loss:0.015717788862502646\n",
      "train loss:0.009000656015953023\n",
      "train loss:0.001586591282826451\n",
      "train loss:0.03871450570293165\n",
      "train loss:0.0034810558566060468\n",
      "train loss:0.00014666619388501988\n",
      "train loss:0.0015086541052416955\n",
      "train loss:0.0009776537345158388\n",
      "train loss:0.001423316880934285\n",
      "train loss:0.0017110739620332703\n",
      "train loss:0.003210357018962497\n",
      "train loss:0.0014194111371012195\n",
      "train loss:0.0030137864980214735\n",
      "train loss:0.0036786007651110086\n",
      "train loss:0.005765266747451797\n",
      "train loss:0.005129990887057861\n",
      "train loss:0.004014309470606682\n",
      "train loss:0.0010597747688694764\n",
      "train loss:0.016687846848809643\n",
      "train loss:0.005904240551457125\n",
      "train loss:0.041788745439484104\n",
      "train loss:0.025191023484486777\n",
      "train loss:0.002461920064720086\n",
      "train loss:0.010393202814391399\n",
      "train loss:0.0026021043480696994\n",
      "train loss:0.0023551841716207464\n",
      "train loss:0.011557979277462842\n",
      "train loss:0.011347662888893335\n",
      "train loss:0.0013093555603092169\n",
      "train loss:0.002615093402834709\n",
      "train loss:0.010873703760053097\n",
      "train loss:0.001314406843677419\n",
      "train loss:0.019164599856047196\n",
      "train loss:0.0008039827732520068\n",
      "train loss:0.0022633122334770966\n",
      "train loss:0.00473332277294286\n",
      "train loss:0.015002269611535059\n",
      "train loss:0.0004098810752494288\n",
      "train loss:0.0038382297438150207\n",
      "train loss:0.009100452908011612\n",
      "train loss:0.0020436997505592445\n",
      "train loss:0.0022269057892747926\n",
      "train loss:0.003471565501157672\n",
      "train loss:0.006693247894752373\n",
      "train loss:0.0020975797585352065\n",
      "train loss:0.0013750255867606169\n",
      "train loss:0.008432204514231167\n",
      "train loss:0.0008074853370650209\n",
      "train loss:0.005415724020442829\n",
      "train loss:0.004066607401329235\n",
      "train loss:0.013626479384793968\n",
      "train loss:0.0026207411089593786\n",
      "train loss:0.0011557994585986472\n",
      "train loss:0.00258674147566899\n",
      "train loss:0.0017068050319152667\n",
      "train loss:0.0054041086046406304\n",
      "train loss:0.004513266625556624\n",
      "train loss:0.001573510844739629\n",
      "train loss:0.003195326834824729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011936176050617818\n",
      "train loss:0.0033534616249100094\n",
      "train loss:0.0031300548788819075\n",
      "train loss:0.0008249036509229432\n",
      "train loss:0.008913840922169522\n",
      "train loss:0.0009679365986224662\n",
      "train loss:0.0024960529706865658\n",
      "train loss:0.004033429449037402\n",
      "train loss:0.0027854666692918983\n",
      "train loss:0.002061785494594161\n",
      "train loss:0.0015490210634735138\n",
      "train loss:0.003436249483736212\n",
      "train loss:0.00048444658857250267\n",
      "train loss:0.005075969185347533\n",
      "train loss:0.0006263495535119792\n",
      "train loss:0.0018997422525433797\n",
      "train loss:0.0001993216236482307\n",
      "train loss:0.04192308386175243\n",
      "train loss:0.0015265799160290216\n",
      "train loss:0.006348446131290072\n",
      "train loss:0.007388939263812982\n",
      "train loss:0.00041156014656848066\n",
      "train loss:0.0047389449668771315\n",
      "train loss:0.006544108373934614\n",
      "train loss:0.0006563199794212172\n",
      "train loss:0.0034567781568564976\n",
      "train loss:0.00532581777396105\n",
      "train loss:0.005730367343165657\n",
      "train loss:0.009499256378262235\n",
      "train loss:0.022381883905897747\n",
      "train loss:0.0010945069786420089\n",
      "train loss:0.002157221816138634\n",
      "train loss:0.0031290929550133427\n",
      "train loss:0.00585999327865222\n",
      "train loss:0.008177315056316251\n",
      "train loss:0.010125211916888324\n",
      "train loss:0.0028367289710819477\n",
      "train loss:0.00720893005784208\n",
      "train loss:0.007467336436629158\n",
      "train loss:0.003508355084889529\n",
      "train loss:0.001924477868597055\n",
      "train loss:0.0010002521345784882\n",
      "train loss:0.0008750580523730299\n",
      "train loss:0.005146349919515086\n",
      "train loss:0.006913175026120798\n",
      "train loss:0.0010678809356837106\n",
      "train loss:0.004136288934113881\n",
      "train loss:0.002517244239458241\n",
      "train loss:0.0023942288790576565\n",
      "train loss:0.00045541815279149996\n",
      "train loss:0.003098018149573998\n",
      "train loss:0.006172459127709105\n",
      "train loss:0.002265209723917632\n",
      "train loss:0.00736807679413677\n",
      "train loss:0.00022437241850504269\n",
      "train loss:0.003789236522979393\n",
      "train loss:0.004759693129177065\n",
      "train loss:0.002075810877813432\n",
      "train loss:0.0062189870040303295\n",
      "train loss:0.0022028236555316043\n",
      "train loss:0.0017580955389998665\n",
      "train loss:0.0031180467736417494\n",
      "train loss:0.0039895401498274636\n",
      "train loss:0.0036953835162803154\n",
      "train loss:0.008403027395774672\n",
      "train loss:0.006323143160828825\n",
      "train loss:0.005491877064437348\n",
      "train loss:0.002792798862098074\n",
      "train loss:0.005783344514450679\n",
      "train loss:0.0028857474277423313\n",
      "train loss:0.001541915460300708\n",
      "train loss:0.013087475848679331\n",
      "train loss:0.006188338274257494\n",
      "train loss:0.0024212885180287884\n",
      "train loss:0.026445215823045407\n",
      "train loss:0.023078816128170424\n",
      "train loss:0.00014668130453692746\n",
      "train loss:0.002480309451945197\n",
      "train loss:0.006139070160020767\n",
      "train loss:0.005189922542891351\n",
      "train loss:0.004011779788688789\n",
      "train loss:0.00673795713221986\n",
      "train loss:6.69944214527343e-05\n",
      "train loss:0.0005050645581911691\n",
      "train loss:0.00048024903803848184\n",
      "train loss:0.0023176985218820194\n",
      "train loss:0.0028642406033491676\n",
      "train loss:0.07826008343101418\n",
      "train loss:0.0045765370390504516\n",
      "train loss:0.0014350938199631594\n",
      "train loss:0.006130370796374646\n",
      "train loss:0.0003196795691766339\n",
      "train loss:0.002214142084842109\n",
      "train loss:0.01280247517685876\n",
      "train loss:0.05693372965560761\n",
      "train loss:0.002421066907789075\n",
      "train loss:0.002777804211304059\n",
      "train loss:0.010330483461807132\n",
      "train loss:0.0011129218329011654\n",
      "train loss:0.004339933812204637\n",
      "train loss:0.0036659708423286397\n",
      "train loss:0.0014475951879725768\n",
      "train loss:0.007932661092387104\n",
      "train loss:0.0025648993939486344\n",
      "train loss:0.012362441679907436\n",
      "train loss:0.0044618261923977595\n",
      "train loss:0.00963320218703648\n",
      "train loss:0.0033675012894044424\n",
      "train loss:0.02065341445483073\n",
      "train loss:0.007139984470443723\n",
      "train loss:0.001103265005159487\n",
      "train loss:0.06960952933824711\n",
      "train loss:0.0014073498587939403\n",
      "train loss:0.02140090879174602\n",
      "train loss:0.00037243157528666715\n",
      "train loss:0.011426828732007543\n",
      "train loss:0.00495901304951187\n",
      "train loss:0.004841542929920503\n",
      "train loss:0.013512419082153625\n",
      "train loss:0.03406521493216385\n",
      "train loss:0.003623102910700526\n",
      "train loss:0.0075109546390509105\n",
      "train loss:0.01791241723551022\n",
      "train loss:0.000853000123328533\n",
      "train loss:0.008712758739168502\n",
      "train loss:0.0032637738406506495\n",
      "train loss:0.020414324735490368\n",
      "train loss:0.004417413856632136\n",
      "train loss:0.007442733074004577\n",
      "train loss:0.0029930505511646865\n",
      "train loss:0.005727166911678961\n",
      "train loss:0.005916921565093908\n",
      "train loss:0.00010069125940970262\n",
      "train loss:0.012642461215969767\n",
      "train loss:0.002231936953616455\n",
      "train loss:0.008141177393780426\n",
      "train loss:0.030646203075518717\n",
      "train loss:0.005846988478164799\n",
      "train loss:0.0008659946341294587\n",
      "train loss:0.01358719588334954\n",
      "train loss:0.005881158627502821\n",
      "train loss:0.001567056342546151\n",
      "train loss:0.0031841837457552923\n",
      "train loss:0.0025968371553727713\n",
      "train loss:0.0020856626119016342\n",
      "train loss:0.004293455300842867\n",
      "train loss:0.02327199627301452\n",
      "train loss:0.004827739488758264\n",
      "train loss:0.006396033413416758\n",
      "train loss:0.0013069552256012344\n",
      "train loss:0.0017635723192328861\n",
      "train loss:0.0012047671463134677\n",
      "train loss:0.0050922998415704876\n",
      "train loss:0.004114179248792778\n",
      "train loss:0.018505051284778175\n",
      "train loss:0.0008351327820960658\n",
      "train loss:0.003155468926172764\n",
      "train loss:0.002339201429751975\n",
      "train loss:0.000807696178036319\n",
      "train loss:0.0010630842906110278\n",
      "train loss:0.007817006904344335\n",
      "train loss:0.0025324623202008754\n",
      "train loss:0.007716612962001806\n",
      "train loss:0.0023817408909025074\n",
      "train loss:0.00503393625466831\n",
      "train loss:0.008913635336836697\n",
      "train loss:0.006726390077636746\n",
      "train loss:0.0011643775867747346\n",
      "train loss:0.018772786780062996\n",
      "train loss:0.0003241463540251565\n",
      "train loss:0.0332287812759684\n",
      "train loss:0.0003701817106852847\n",
      "train loss:0.0004954325691853659\n",
      "train loss:0.0005923452662982915\n",
      "train loss:0.0023417024017907424\n",
      "train loss:0.0012915102412950257\n",
      "train loss:0.008539904657129678\n",
      "train loss:0.0021776476548106666\n",
      "train loss:0.0670825686418916\n",
      "train loss:0.005660300643567237\n",
      "train loss:0.0020787487865081434\n",
      "train loss:0.0007998032372768095\n",
      "train loss:0.0016018304283067673\n",
      "train loss:0.0029905181937722462\n",
      "train loss:0.009733151096889431\n",
      "train loss:0.010406780562977695\n",
      "train loss:0.0033482410217086705\n",
      "train loss:0.00629691773204736\n",
      "train loss:0.006770999171152452\n",
      "train loss:0.0014466336735736184\n",
      "train loss:0.010274307347354907\n",
      "train loss:0.002722877152992929\n",
      "train loss:0.0027106673775756\n",
      "train loss:0.0004922807572359936\n",
      "train loss:0.09268223808889817\n",
      "train loss:0.0025340500103017746\n",
      "train loss:0.023300536522893475\n",
      "train loss:0.034251251607411264\n",
      "train loss:0.0022596830572485997\n",
      "train loss:0.007141909735864483\n",
      "train loss:0.004360180202085325\n",
      "train loss:0.003420426576789804\n",
      "train loss:0.0007524490150291192\n",
      "train loss:0.008621183417940059\n",
      "train loss:0.0030029905665420052\n",
      "train loss:0.004837562202172046\n",
      "train loss:0.005174616693476042\n",
      "train loss:0.0009513217220157243\n",
      "train loss:0.0017707209980292785\n",
      "train loss:0.013989880650138642\n",
      "train loss:0.001312917521154823\n",
      "train loss:0.0018749581688983785\n",
      "train loss:0.001989118793561957\n",
      "train loss:0.0043374536461719335\n",
      "train loss:0.0034957765696629678\n",
      "train loss:0.004431313654589106\n",
      "train loss:0.005367657129963782\n",
      "train loss:0.0022227898068116767\n",
      "train loss:0.0029117882052273796\n",
      "train loss:0.001351055149518467\n",
      "train loss:0.0037949127922745894\n",
      "train loss:0.0018185318751645482\n",
      "train loss:0.0018054981468884684\n",
      "train loss:0.0032394944672619924\n",
      "train loss:0.00290309451247379\n",
      "train loss:0.0034452828829033303\n",
      "train loss:0.0023080719195077877\n",
      "train loss:0.006604628845475009\n",
      "train loss:0.0006207006019656964\n",
      "train loss:0.003947882080934286\n",
      "train loss:0.0007786321407961087\n",
      "train loss:0.002056147294958971\n",
      "train loss:0.0009760352450939621\n",
      "train loss:0.0005821746443348073\n",
      "train loss:0.0014428893379337807\n",
      "train loss:0.004753879720443034\n",
      "train loss:0.0037165881309172725\n",
      "train loss:0.002939633181056599\n",
      "train loss:0.005490436242419124\n",
      "train loss:0.016799845912033512\n",
      "train loss:0.009951605691353867\n",
      "train loss:0.00043288915729355816\n",
      "train loss:0.0032612726759980674\n",
      "train loss:0.012886841379054376\n",
      "train loss:0.011604250510891397\n",
      "train loss:0.002439119568744173\n",
      "train loss:0.010242219437745257\n",
      "train loss:0.006567316646507938\n",
      "train loss:0.0018474158499208499\n",
      "train loss:0.0123247161289902\n",
      "train loss:0.007268869617303101\n",
      "train loss:0.00267753972742891\n",
      "train loss:0.0017417209048701564\n",
      "train loss:0.0075822687810904845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0018301975574387369\n",
      "train loss:0.023289705565855186\n",
      "train loss:0.0031834455107111613\n",
      "train loss:0.027771341056868307\n",
      "train loss:0.000163857457689915\n",
      "train loss:0.0017832273189308484\n",
      "train loss:0.00037885470600692786\n",
      "train loss:0.001271313487582388\n",
      "train loss:0.005592792182618929\n",
      "train loss:0.002261275194513044\n",
      "train loss:0.0016097878355119425\n",
      "train loss:0.004219886831544983\n",
      "train loss:0.003739427372881999\n",
      "train loss:0.007978541975068866\n",
      "train loss:0.0028292083173436094\n",
      "train loss:0.0024295815009961566\n",
      "train loss:0.0035881112993424802\n",
      "train loss:0.003057173887791838\n",
      "train loss:0.0025886523669332293\n",
      "train loss:0.020153100589465237\n",
      "train loss:0.0037581065363682126\n",
      "train loss:0.006267012694495145\n",
      "train loss:0.0019195836713645734\n",
      "train loss:0.003144165774742995\n",
      "train loss:0.004649157281275074\n",
      "train loss:0.007988446293780298\n",
      "train loss:0.0042623281910227125\n",
      "train loss:0.005707642862985749\n",
      "train loss:0.0004694031088266959\n",
      "train loss:0.000520510434567914\n",
      "train loss:0.0031914605100703004\n",
      "train loss:0.0009623731709204656\n",
      "train loss:0.0003794612544364126\n",
      "train loss:0.001673719225060253\n",
      "train loss:0.0004537702144796723\n",
      "train loss:0.04094444285930785\n",
      "train loss:0.0046744583999436635\n",
      "train loss:0.0013231486912337281\n",
      "train loss:0.004591562949163779\n",
      "train loss:0.00230023701764596\n",
      "train loss:0.0005896443206747479\n",
      "train loss:0.0017535210947390676\n",
      "train loss:0.06671239562412497\n",
      "train loss:0.009850009085930108\n",
      "train loss:0.01280090802991972\n",
      "train loss:0.005451009900179719\n",
      "train loss:0.002167744779484759\n",
      "train loss:0.0034343891238945707\n",
      "train loss:0.003856421414936225\n",
      "train loss:0.005323395484740974\n",
      "train loss:0.003049858303139096\n",
      "train loss:0.0015528642205533821\n",
      "train loss:0.0026731663062239926\n",
      "train loss:0.00488550724016862\n",
      "train loss:0.004373263291579831\n",
      "train loss:0.007417305122312181\n",
      "train loss:0.006720817629368361\n",
      "train loss:0.0007004774883027616\n",
      "train loss:0.0017359327329382127\n",
      "train loss:0.00849105375371134\n",
      "train loss:0.0033606236776456805\n",
      "train loss:0.0016471882315418757\n",
      "train loss:0.0018016898403787171\n",
      "train loss:0.0029366724715626288\n",
      "train loss:0.005139583327767673\n",
      "train loss:0.005812693577557098\n",
      "train loss:0.006977202792758962\n",
      "train loss:0.0031576564714088733\n",
      "train loss:0.014719668685775553\n",
      "train loss:0.0034435143412853792\n",
      "train loss:0.0078036641783617855\n",
      "train loss:0.007082911684433566\n",
      "train loss:0.0009934368422597837\n",
      "train loss:0.005820343655908613\n",
      "train loss:0.004337062461813369\n",
      "train loss:0.004189017649463908\n",
      "train loss:0.0023464527044392376\n",
      "train loss:0.0016668554486785586\n",
      "train loss:0.010575117775696133\n",
      "train loss:0.0018005089827903289\n",
      "train loss:0.005507417488016008\n",
      "train loss:0.008908802787499526\n",
      "train loss:0.009285769585737824\n",
      "train loss:0.011372045362564785\n",
      "train loss:0.002663457092627704\n",
      "train loss:0.008962634920178228\n",
      "train loss:0.005224517928829577\n",
      "train loss:0.004595087971677616\n",
      "train loss:0.012666256603894532\n",
      "train loss:0.030021351633497746\n",
      "train loss:0.009869245211373697\n",
      "train loss:0.001228188417382912\n",
      "train loss:0.010813324914748434\n",
      "train loss:0.003211646912306541\n",
      "train loss:0.040778563665224296\n",
      "train loss:0.01863329371521245\n",
      "train loss:0.0008952951448911072\n",
      "train loss:0.0012559808932765873\n",
      "train loss:0.0058138224747974225\n",
      "train loss:0.004871588059991486\n",
      "train loss:0.0024585784586492305\n",
      "train loss:0.020998720625073877\n",
      "train loss:0.0045713917851543774\n",
      "train loss:0.0015353155371949387\n",
      "train loss:0.0009486069788669578\n",
      "train loss:0.002922911104154845\n",
      "train loss:0.0007344664872218008\n",
      "train loss:0.012177345991956568\n",
      "train loss:0.0016854643701884945\n",
      "train loss:0.0007855697923565375\n",
      "train loss:0.002448944753777435\n",
      "train loss:0.017410676926350156\n",
      "train loss:0.017527015725001715\n",
      "train loss:0.004076165727213298\n",
      "train loss:0.0047862048721682175\n",
      "train loss:0.0012289557647094072\n",
      "train loss:0.0012275574063640075\n",
      "train loss:0.0038812897596655544\n",
      "train loss:0.00422968352843081\n",
      "train loss:0.0027004232032124824\n",
      "train loss:0.011461543960469943\n",
      "train loss:0.0037625941855905314\n",
      "train loss:0.0023623153045831493\n",
      "train loss:0.005086861944104706\n",
      "train loss:0.0018363544682409405\n",
      "train loss:0.0002208081792823467\n",
      "train loss:0.009912682652482218\n",
      "train loss:0.0031457242482703656\n",
      "train loss:0.0006226560942471528\n",
      "train loss:0.004357543673312631\n",
      "train loss:0.0021167314586823787\n",
      "train loss:0.0036401344659268663\n",
      "train loss:0.0012357700441272\n",
      "train loss:0.004611297031326785\n",
      "train loss:0.0007104687272662753\n",
      "train loss:0.005091484917491515\n",
      "train loss:0.0018034791094236134\n",
      "train loss:0.0014618642779420166\n",
      "train loss:0.01457314582876081\n",
      "train loss:0.0008418660296262057\n",
      "train loss:0.007142892314598086\n",
      "train loss:0.024082887694567033\n",
      "train loss:0.005332568892872495\n",
      "train loss:0.00041023909423939977\n",
      "train loss:0.0053186571418946\n",
      "train loss:0.08199195240015539\n",
      "train loss:0.0003459009416047703\n",
      "train loss:0.0007610816044667293\n",
      "train loss:0.002055372885195442\n",
      "train loss:0.0025844061601747\n",
      "train loss:0.0034763451972945813\n",
      "train loss:0.003968172797961555\n",
      "train loss:0.0016150060327057023\n",
      "train loss:0.0072247380121968074\n",
      "train loss:0.002071969503790476\n",
      "train loss:0.0026818502808566027\n",
      "train loss:0.0005204522113241484\n",
      "train loss:0.00909264898881232\n",
      "train loss:0.0060329331691891\n",
      "train loss:0.01794382191105132\n",
      "train loss:0.0010174525287046333\n",
      "train loss:0.0006918413614411568\n",
      "train loss:0.0025271158121140634\n",
      "train loss:0.005522239079595605\n",
      "train loss:0.0031504285156120334\n",
      "train loss:0.0025083751222547534\n",
      "train loss:0.001053553972766921\n",
      "train loss:0.013760976908605933\n",
      "train loss:0.003496450675148372\n",
      "train loss:0.0011257818464536174\n",
      "train loss:0.005362226300437063\n",
      "train loss:0.0038611666057328515\n",
      "train loss:0.01887545684624969\n",
      "train loss:0.0050839626914329795\n",
      "train loss:0.002429554070002235\n",
      "train loss:0.004747766551778868\n",
      "train loss:0.0011879349073506283\n",
      "train loss:0.0017080602391593602\n",
      "train loss:0.0072326661150997895\n",
      "train loss:0.0037668335791998775\n",
      "train loss:0.008058138787235969\n",
      "train loss:0.0036296535583971645\n",
      "train loss:0.004947683499350499\n",
      "train loss:0.0025554007348050135\n",
      "train loss:0.00562099832044888\n",
      "train loss:0.024192214457614315\n",
      "train loss:0.0007745003050982083\n",
      "train loss:0.009535408577422473\n",
      "train loss:0.019299141202338988\n",
      "train loss:0.003840983353242067\n",
      "train loss:0.0041233681255790295\n",
      "train loss:0.001234099053125145\n",
      "train loss:0.008362804827071631\n",
      "train loss:0.0002923117863253184\n",
      "train loss:0.00437281516601153\n",
      "train loss:0.033567789906441964\n",
      "train loss:0.008421098563059577\n",
      "train loss:0.00041277692111444503\n",
      "train loss:0.0004523721965807484\n",
      "train loss:0.0008422071001656918\n",
      "train loss:0.00225833889634285\n",
      "train loss:0.003941750068504929\n",
      "train loss:0.006014825583945779\n",
      "train loss:0.0026571388433893842\n",
      "train loss:0.006687897735136675\n",
      "train loss:0.002683959569568735\n",
      "train loss:0.0033083822927298208\n",
      "=== epoch:13, train acc:0.994, test acc:0.99 ===\n",
      "train loss:0.005206397217612272\n",
      "train loss:0.0031669282774878416\n",
      "train loss:0.06346019471111579\n",
      "train loss:0.002047211591956536\n",
      "train loss:0.0011690274924771788\n",
      "train loss:0.00031068196626167434\n",
      "train loss:0.0003718171036712176\n",
      "train loss:0.0009803211928771332\n",
      "train loss:0.0004183321297692498\n",
      "train loss:0.003558369876804261\n",
      "train loss:0.013161847440194482\n",
      "train loss:0.0031557790947829346\n",
      "train loss:0.016691708849134144\n",
      "train loss:0.0008392166020528939\n",
      "train loss:0.012049433009324246\n",
      "train loss:0.0003900158426596094\n",
      "train loss:0.0015420110802475146\n",
      "train loss:0.0035561167466802183\n",
      "train loss:0.0011827503834240221\n",
      "train loss:0.0018980528436149744\n",
      "train loss:0.0038880880752480544\n",
      "train loss:0.02576491153093615\n",
      "train loss:0.01083182317616097\n",
      "train loss:0.005144088895097162\n",
      "train loss:0.0031577268906049405\n",
      "train loss:0.0011518198888344538\n",
      "train loss:0.003141526306672942\n",
      "train loss:0.006378164493029455\n",
      "train loss:0.015830315150441438\n",
      "train loss:0.002267516999172699\n",
      "train loss:0.007055880383610944\n",
      "train loss:0.01643157133454658\n",
      "train loss:0.004472179651071237\n",
      "train loss:0.0054198950950762655\n",
      "train loss:0.006918642160112176\n",
      "train loss:0.0019017769250106189\n",
      "train loss:0.015046805535681405\n",
      "train loss:0.0026208938030777957\n",
      "train loss:0.0012384356705335373\n",
      "train loss:0.004636787988164262\n",
      "train loss:0.009197264226727463\n",
      "train loss:0.010764618388313356\n",
      "train loss:0.0005590743717954643\n",
      "train loss:0.010760861565266486\n",
      "train loss:0.0034957259742258743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0008693635554694379\n",
      "train loss:0.005046741073488216\n",
      "train loss:0.0025780693916227426\n",
      "train loss:0.009402578596964804\n",
      "train loss:0.00076971226769981\n",
      "train loss:0.005225173007706671\n",
      "train loss:0.0014516976384188322\n",
      "train loss:0.005097099082139475\n",
      "train loss:0.00039125235918166827\n",
      "train loss:0.00041882212132308624\n",
      "train loss:0.006823644894705701\n",
      "train loss:0.0014500683446629782\n",
      "train loss:0.0017225285288895351\n",
      "train loss:0.0013225994128778426\n",
      "train loss:0.0033568453958705263\n",
      "train loss:0.014275740431954877\n",
      "train loss:0.001974174776852314\n",
      "train loss:0.003188711682166968\n",
      "train loss:0.015102437041432083\n",
      "train loss:0.0006678381139106462\n",
      "train loss:0.0007260085230496959\n",
      "train loss:0.015031839456406806\n",
      "train loss:0.0027488080167224634\n",
      "train loss:0.003509432310250056\n",
      "train loss:0.0021388253782501426\n",
      "train loss:0.014536441038991392\n",
      "train loss:0.0017292161495803266\n",
      "train loss:0.002622603830432926\n",
      "train loss:0.0017828074790053603\n",
      "train loss:0.0033179274955268765\n",
      "train loss:0.0033866890103858194\n",
      "train loss:0.00871236744443374\n",
      "train loss:0.005723162712076413\n",
      "train loss:0.03497888589397822\n",
      "train loss:0.006675832031098767\n",
      "train loss:0.006521826900759193\n",
      "train loss:0.0022238290125347394\n",
      "train loss:0.0021783495348523065\n",
      "train loss:0.002537883152005948\n",
      "train loss:0.0037678191412286637\n",
      "train loss:0.005506851561044771\n",
      "train loss:0.0003791572041474988\n",
      "train loss:0.0015474532171747954\n",
      "train loss:0.0010802981104065757\n",
      "train loss:0.00814151388559266\n",
      "train loss:0.02231423704873619\n",
      "train loss:0.004664577592888557\n",
      "train loss:0.0029082700907272136\n",
      "train loss:0.001252935589933784\n",
      "train loss:0.024017414667010725\n",
      "train loss:0.048754104537684195\n",
      "train loss:0.006947766706895814\n",
      "train loss:0.004620934497098439\n",
      "train loss:0.0015538829265807574\n",
      "train loss:0.0008197319382156293\n",
      "train loss:0.0004730600469987869\n",
      "train loss:0.0007769000157649172\n",
      "train loss:0.004984109281372576\n",
      "train loss:0.004880222005678376\n",
      "train loss:0.008824431033311668\n",
      "train loss:0.0005321849553946048\n",
      "train loss:0.007594344976602311\n",
      "train loss:0.0012613592382688162\n",
      "train loss:0.0025561741054980188\n",
      "train loss:0.0006038602160358816\n",
      "train loss:0.009643130216062926\n",
      "train loss:0.003882750998032256\n",
      "train loss:0.00031254433591474355\n",
      "train loss:0.002342259890692239\n",
      "train loss:0.006804440247863238\n",
      "train loss:0.009512169415156563\n",
      "train loss:0.02150783521419819\n",
      "train loss:0.004089787976649758\n",
      "train loss:0.0014324688895528417\n",
      "train loss:0.007986663620518057\n",
      "train loss:0.0016640657113771258\n",
      "train loss:0.0030495873567707847\n",
      "train loss:0.005435408923530473\n",
      "train loss:0.0033043430377316736\n",
      "train loss:0.0010323471227060672\n",
      "train loss:0.003986365794928635\n",
      "train loss:0.0009583837815803323\n",
      "train loss:0.00042778994312532256\n",
      "train loss:0.011777168947427457\n",
      "train loss:0.0006908733657059805\n",
      "train loss:0.003002412224318271\n",
      "train loss:0.010315879824573502\n",
      "train loss:0.0007067209304667997\n",
      "train loss:0.00034420652752911995\n",
      "train loss:0.00014707087690811918\n",
      "train loss:0.005693978417790404\n",
      "train loss:0.012524831513493373\n",
      "train loss:0.01225593513398557\n",
      "train loss:0.003951971235930544\n",
      "train loss:0.0009759584319836293\n",
      "train loss:0.0009298173070760986\n",
      "train loss:0.0016766387464536815\n",
      "train loss:0.0037111414755005762\n",
      "train loss:0.0011316110693818384\n",
      "train loss:0.009847801287353379\n",
      "train loss:0.0012835470187559474\n",
      "train loss:0.004705116761247682\n",
      "train loss:0.002893676540435432\n",
      "train loss:0.001575219678158552\n",
      "train loss:0.00785129913275777\n",
      "train loss:0.003815940289012758\n",
      "train loss:0.001273709947276519\n",
      "train loss:0.005483178600805555\n",
      "train loss:0.0014682133178361176\n",
      "train loss:0.0009128774700938189\n",
      "train loss:0.002161741521440744\n",
      "train loss:0.0012488668492997837\n",
      "train loss:0.002840306244723609\n",
      "train loss:0.015140552483930664\n",
      "train loss:0.005782003213868451\n",
      "train loss:0.0014963394344685694\n",
      "train loss:0.004950398683955677\n",
      "train loss:0.01875436353093324\n",
      "train loss:0.0015326355439823436\n",
      "train loss:0.0023286173438045953\n",
      "train loss:0.001965605508751637\n",
      "train loss:0.007640407256555741\n",
      "train loss:0.007334004766451487\n",
      "train loss:0.0031115868891677056\n",
      "train loss:0.01353118790429469\n",
      "train loss:0.0009783000443380795\n",
      "train loss:0.003241217826991208\n",
      "train loss:0.009429751590989471\n",
      "train loss:0.00144375526002846\n",
      "train loss:0.0013126711016236067\n",
      "train loss:0.0033842614150134277\n",
      "train loss:0.003694676237286611\n",
      "train loss:0.0005292958299482885\n",
      "train loss:0.0016049129223939865\n",
      "train loss:0.0032360879838770453\n",
      "train loss:0.0041483421773648955\n",
      "train loss:0.0013230024703589755\n",
      "train loss:0.003122109825834218\n",
      "train loss:0.00042360034542730996\n",
      "train loss:0.007330632551009816\n",
      "train loss:0.005088952133631099\n",
      "train loss:0.002542533909433284\n",
      "train loss:0.00198169386806041\n",
      "train loss:0.0019595455558642358\n",
      "train loss:0.006155485827169598\n",
      "train loss:0.0023392996601411713\n",
      "train loss:0.0049596708868827\n",
      "train loss:0.0016321528092236297\n",
      "train loss:0.0031644389768467024\n",
      "train loss:0.0025150700936157015\n",
      "train loss:0.00098758141067079\n",
      "train loss:0.0005460574287996633\n",
      "train loss:0.0008475633720778935\n",
      "train loss:0.0017532414524070183\n",
      "train loss:0.014171319055108657\n",
      "train loss:0.004342343777051813\n",
      "train loss:0.0041961227298770295\n",
      "train loss:0.00287580333710063\n",
      "train loss:0.0022523675440930127\n",
      "train loss:0.004839178343807319\n",
      "train loss:0.001021128243077282\n",
      "train loss:0.0035549268540688494\n",
      "train loss:0.0009318461885893898\n",
      "train loss:0.007456757714631213\n",
      "train loss:0.00039424668853043997\n",
      "train loss:0.002029721163170393\n",
      "train loss:0.00045395663469612957\n",
      "train loss:0.005511652236485473\n",
      "train loss:0.027276996848089437\n",
      "train loss:0.00519725605359585\n",
      "train loss:0.0037270513857847183\n",
      "train loss:0.0006150121348902659\n",
      "train loss:0.005133442850729613\n",
      "train loss:0.0018172273202128203\n",
      "train loss:0.0008587240592722594\n",
      "train loss:0.003898023186049718\n",
      "train loss:0.0007670635796750815\n",
      "train loss:0.004898276640469933\n",
      "train loss:0.00028699579991463156\n",
      "train loss:0.03832860124391559\n",
      "train loss:0.003094858066366529\n",
      "train loss:0.005694224780753415\n",
      "train loss:0.01187099967346953\n",
      "train loss:0.001749498492944588\n",
      "train loss:0.0006342417694843387\n",
      "train loss:0.000887877910046026\n",
      "train loss:0.0003052021374070859\n",
      "train loss:0.0037614484540564003\n",
      "train loss:0.00012822143239704385\n",
      "train loss:0.023759842027923524\n",
      "train loss:0.0007997080375101815\n",
      "train loss:0.012922515795071185\n",
      "train loss:0.0006743690608811314\n",
      "train loss:0.008181337584070785\n",
      "train loss:0.0028348316354188286\n",
      "train loss:0.0005508201354266641\n",
      "train loss:0.004249268532971214\n",
      "train loss:0.0032850972072260625\n",
      "train loss:0.0024934250133019716\n",
      "train loss:0.0023554737196306193\n",
      "train loss:0.0050113290663369005\n",
      "train loss:0.0041206010049378685\n",
      "train loss:0.008805063592364007\n",
      "train loss:0.008320403486911683\n",
      "train loss:0.004865308128938185\n",
      "train loss:0.00281195060575905\n",
      "train loss:0.006628250553496844\n",
      "train loss:0.0013003980094226397\n",
      "train loss:0.002703284574710419\n",
      "train loss:0.00106333640877002\n",
      "train loss:0.042912228208159965\n",
      "train loss:0.0016475015687048068\n",
      "train loss:0.006178810440085769\n",
      "train loss:0.00018282855829822368\n",
      "train loss:0.0034567503846110307\n",
      "train loss:0.000903381089821471\n",
      "train loss:0.002267966461127602\n",
      "train loss:0.0061958600984844655\n",
      "train loss:0.015234920112937167\n",
      "train loss:0.0035718891688167565\n",
      "train loss:0.0019066733117065653\n",
      "train loss:0.0029579409648600626\n",
      "train loss:0.0017088542042876431\n",
      "train loss:0.0038860263302092947\n",
      "train loss:0.005208321358694331\n",
      "train loss:0.000905865169198299\n",
      "train loss:0.0011756791608078855\n",
      "train loss:0.00422921173119804\n",
      "train loss:0.00048239805908319497\n",
      "train loss:0.006604193450319239\n",
      "train loss:0.00872645308229629\n",
      "train loss:0.0010134471116844508\n",
      "train loss:0.0017161964754282668\n",
      "train loss:0.0029504300123471662\n",
      "train loss:0.0025046632575141574\n",
      "train loss:0.003130664333981059\n",
      "train loss:0.0023221046693700418\n",
      "train loss:0.0011506245893049343\n",
      "train loss:0.00041618021463972504\n",
      "train loss:0.013487983573487256\n",
      "train loss:0.0017482619348409834\n",
      "train loss:0.0009650900614962042\n",
      "train loss:0.003632495920486875\n",
      "train loss:0.00036517559484675597\n",
      "train loss:0.0005180020758664088\n",
      "train loss:0.008527634821246336\n",
      "train loss:0.013252525028990946\n",
      "train loss:0.0007487553194186852\n",
      "train loss:0.0024629097693496848\n",
      "train loss:0.0014428226010489266\n",
      "train loss:0.00503859338284558\n",
      "train loss:0.003405108035981597\n",
      "train loss:0.0015631775367344108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004481090823893079\n",
      "train loss:0.03002160732447392\n",
      "train loss:0.0016693244699092947\n",
      "train loss:0.007364372011374597\n",
      "train loss:0.005209364329098592\n",
      "train loss:0.0027898153802398107\n",
      "train loss:0.003147239866039635\n",
      "train loss:0.002807932532300729\n",
      "train loss:0.0013737759591938938\n",
      "train loss:0.005806160494846596\n",
      "train loss:0.0028793584591553347\n",
      "train loss:0.00355827928704339\n",
      "train loss:0.001307294170331416\n",
      "train loss:0.001306436956270626\n",
      "train loss:0.00449923225903414\n",
      "train loss:0.00041255681543471765\n",
      "train loss:0.0007649783959740895\n",
      "train loss:0.0003090348497066217\n",
      "train loss:0.002577267958203339\n",
      "train loss:8.141836530057759e-05\n",
      "train loss:0.0026719081531211037\n",
      "train loss:0.005174975319802111\n",
      "train loss:0.0031371468275228176\n",
      "train loss:0.004859595977903977\n",
      "train loss:0.0016513288235008347\n",
      "train loss:0.0008505368543918017\n",
      "train loss:0.002466591631228898\n",
      "train loss:0.0008954000400306422\n",
      "train loss:0.00016171732721471466\n",
      "train loss:0.0007306648164299876\n",
      "train loss:0.002997852997619054\n",
      "train loss:0.0010284335752240499\n",
      "train loss:0.000602629109347412\n",
      "train loss:0.0019322659667957666\n",
      "train loss:0.015805633580930022\n",
      "train loss:0.0037801763449400077\n",
      "train loss:0.0018799474424727198\n",
      "train loss:0.0013254612044312415\n",
      "train loss:0.007439788971468738\n",
      "train loss:0.015287484888036194\n",
      "train loss:0.01860679938975246\n",
      "train loss:0.0049346330295120195\n",
      "train loss:0.004858525162209974\n",
      "train loss:0.0010998703185463347\n",
      "train loss:0.0028957650661296276\n",
      "train loss:0.011163621252600984\n",
      "train loss:0.02179075964850186\n",
      "train loss:0.000712241698980819\n",
      "train loss:0.02462461902634118\n",
      "train loss:0.0004127653587817702\n",
      "train loss:0.001773794354214065\n",
      "train loss:0.0031028093344233447\n",
      "train loss:0.0028433895519582256\n",
      "train loss:0.0058848794142737585\n",
      "train loss:0.0013737014589705252\n",
      "train loss:0.000653710214008053\n",
      "train loss:0.0013098154372427084\n",
      "train loss:0.007176433119253463\n",
      "train loss:0.0038706355169005687\n",
      "train loss:0.002093152682026081\n",
      "train loss:0.03980742748365845\n",
      "train loss:0.01791978910192485\n",
      "train loss:0.006832785978865018\n",
      "train loss:0.005311465217704424\n",
      "train loss:0.002847801200794558\n",
      "train loss:0.0005306292107332554\n",
      "train loss:0.0003992124141057301\n",
      "train loss:0.0016442933825432068\n",
      "train loss:0.00604996378905783\n",
      "train loss:0.003492972442292138\n",
      "train loss:0.005273118075093048\n",
      "train loss:0.001955209153447224\n",
      "train loss:0.001534947311256423\n",
      "train loss:0.0028044526287635857\n",
      "train loss:0.0019488880013541307\n",
      "train loss:0.004290929434976006\n",
      "train loss:0.000667537652339618\n",
      "train loss:0.001361885159838807\n",
      "train loss:0.0012801301355257406\n",
      "train loss:0.0006732339311877166\n",
      "train loss:0.00627433349301706\n",
      "train loss:0.0010294268620303403\n",
      "train loss:0.0028291267098997717\n",
      "train loss:0.00029831534956251414\n",
      "train loss:0.0015738313218922099\n",
      "train loss:0.007368589205886987\n",
      "train loss:0.0017140063542411264\n",
      "train loss:0.001320521197113151\n",
      "train loss:0.0007641905120993758\n",
      "train loss:0.027061690753249396\n",
      "train loss:0.0016618631174896952\n",
      "train loss:0.0006753031696367297\n",
      "train loss:0.002398419816880396\n",
      "train loss:0.0012681931102044475\n",
      "train loss:6.087686719268827e-05\n",
      "train loss:0.004031358558529256\n",
      "train loss:0.003744435531342516\n",
      "train loss:0.03272121121291759\n",
      "train loss:0.005305062512883884\n",
      "train loss:0.0011538205373515529\n",
      "train loss:0.0013254979211570644\n",
      "train loss:0.0020923819001629996\n",
      "train loss:0.0049791899762201405\n",
      "train loss:0.0028060848664921436\n",
      "train loss:0.0061438151879695865\n",
      "train loss:0.0008958119344098351\n",
      "train loss:0.0018933275676936401\n",
      "train loss:0.002837219972019063\n",
      "train loss:0.001522823056415248\n",
      "train loss:0.0008033122094973648\n",
      "train loss:0.003592420532883121\n",
      "train loss:0.0034027456175087477\n",
      "train loss:0.0005376926315075368\n",
      "train loss:0.001568388713631314\n",
      "train loss:0.0014871361322261526\n",
      "train loss:0.0018128682109299237\n",
      "train loss:0.010818444941660104\n",
      "train loss:0.0007135599375428691\n",
      "train loss:0.0034058552805447204\n",
      "train loss:0.0017007337680491998\n",
      "train loss:0.0018493308138265157\n",
      "train loss:0.07789347345387601\n",
      "train loss:0.002537868514861109\n",
      "train loss:0.0003990953864767801\n",
      "train loss:0.0015686729212858533\n",
      "train loss:0.0008911760530677695\n",
      "train loss:0.0029646680431842857\n",
      "train loss:0.0029095137979640385\n",
      "train loss:0.004462404102311747\n",
      "train loss:0.0018631187870529289\n",
      "train loss:0.005380804307350146\n",
      "train loss:0.008029117061657393\n",
      "train loss:0.0029634134969339213\n",
      "train loss:0.000493360999490291\n",
      "train loss:0.003477703463213807\n",
      "train loss:0.00596264210138001\n",
      "train loss:0.007450735255274255\n",
      "train loss:0.001005119307701933\n",
      "train loss:0.006719789252199163\n",
      "train loss:0.0079315950746286\n",
      "train loss:0.00035073530327309514\n",
      "train loss:0.002300800370407731\n",
      "train loss:0.002784389569764662\n",
      "train loss:0.0038971282183205016\n",
      "train loss:0.0037156609147077444\n",
      "train loss:0.0006843607819650556\n",
      "train loss:0.0028315757886458316\n",
      "train loss:0.0036027693082265884\n",
      "train loss:0.0022396592865118687\n",
      "train loss:0.0018641502734395637\n",
      "train loss:0.004930890433153325\n",
      "train loss:0.003047706464192077\n",
      "train loss:0.00851642983851965\n",
      "train loss:0.002238565857328399\n",
      "train loss:0.014496304404512375\n",
      "train loss:0.0012233249341014405\n",
      "train loss:0.0005529721662103289\n",
      "train loss:0.0003047634856798095\n",
      "train loss:0.006180085883679267\n",
      "train loss:0.009836491715541396\n",
      "train loss:0.0010109282338284697\n",
      "train loss:0.0027849916285613164\n",
      "train loss:0.0015301136128846428\n",
      "train loss:0.009172975771074472\n",
      "train loss:0.003597893968157281\n",
      "train loss:0.0030494132036420797\n",
      "train loss:9.889853275271434e-05\n",
      "train loss:0.00898174398749966\n",
      "train loss:0.0030719475251975797\n",
      "train loss:0.033602144855965514\n",
      "train loss:0.0007969062961693846\n",
      "train loss:0.009233660862498801\n",
      "train loss:0.004530697073512347\n",
      "train loss:0.0021343180480335334\n",
      "train loss:0.006608929316989465\n",
      "train loss:0.003733616019613875\n",
      "train loss:0.0329863864610989\n",
      "train loss:0.0009005115092953615\n",
      "train loss:0.006058550404285451\n",
      "train loss:0.0002717809638164416\n",
      "train loss:0.005069941734866853\n",
      "train loss:0.04872508436525882\n",
      "train loss:0.011762390222958954\n",
      "train loss:0.00998271631822681\n",
      "train loss:0.0032293806130399803\n",
      "train loss:0.003888421189480164\n",
      "train loss:0.005199549475264162\n",
      "train loss:0.0010080809297918559\n",
      "train loss:0.004246577937703067\n",
      "train loss:0.00232117539199831\n",
      "train loss:0.016694413265649154\n",
      "train loss:0.0007900933258812994\n",
      "train loss:0.00289030045439761\n",
      "train loss:0.002691669249657447\n",
      "train loss:0.007367267000171862\n",
      "train loss:0.014924571262169138\n",
      "train loss:0.008735521115969357\n",
      "train loss:0.015015756760353436\n",
      "train loss:0.0018875091637146567\n",
      "train loss:0.004764217465259148\n",
      "train loss:0.006629921279887616\n",
      "train loss:0.002831991460631011\n",
      "train loss:0.004049608275233082\n",
      "train loss:0.0004882900676279308\n",
      "train loss:0.00852275715652072\n",
      "train loss:0.00019150173378765307\n",
      "train loss:0.00019019299960588976\n",
      "train loss:0.0011603984362687973\n",
      "train loss:0.00033281941721300274\n",
      "train loss:0.00072519285617364\n",
      "train loss:0.004272945358386456\n",
      "train loss:0.008188274270614797\n",
      "train loss:0.001964884602330226\n",
      "train loss:0.0008937124048952642\n",
      "train loss:0.001119077078751745\n",
      "train loss:0.010049211780169822\n",
      "train loss:0.0012736965848030074\n",
      "train loss:0.0009242125327486994\n",
      "train loss:0.0011218570053115637\n",
      "train loss:0.0027503468562699016\n",
      "train loss:0.002526461249951817\n",
      "train loss:0.0014693937402568893\n",
      "train loss:0.0032323749088833858\n",
      "train loss:0.001021180820785321\n",
      "train loss:0.019139283041709768\n",
      "train loss:0.0017444526003043673\n",
      "train loss:0.00574314142401374\n",
      "train loss:0.0029974016440519943\n",
      "train loss:0.0004283492272296334\n",
      "train loss:0.0007226735747492122\n",
      "train loss:0.016163525022653606\n",
      "train loss:0.0009810242461314154\n",
      "train loss:0.012774612076380929\n",
      "train loss:0.003038748523986329\n",
      "train loss:0.0017150974568601516\n",
      "train loss:0.009709302992956748\n",
      "train loss:0.007728341074848326\n",
      "train loss:0.01016624662177251\n",
      "train loss:0.00843810399790855\n",
      "train loss:0.00012262491142817875\n",
      "train loss:0.000915128759837963\n",
      "train loss:0.0003253698153210317\n",
      "train loss:0.0028740902092056365\n",
      "train loss:0.010805282152377456\n",
      "train loss:0.0003686147318400692\n",
      "train loss:0.008273439807105473\n",
      "train loss:0.00754971131279419\n",
      "train loss:0.003561962071195661\n",
      "train loss:0.00046557369254026114\n",
      "train loss:0.0027371673219049493\n",
      "train loss:0.02070977132458103\n",
      "train loss:0.010733921990491049\n",
      "train loss:0.002171937990694306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.030228158541453224\n",
      "train loss:0.0027337510144733066\n",
      "train loss:0.0030018768301640804\n",
      "train loss:0.008139554683646298\n",
      "train loss:0.00298293686441215\n",
      "train loss:0.005001398792337444\n",
      "train loss:0.0016483185401866198\n",
      "train loss:0.0003140953441897796\n",
      "train loss:0.01903837468866842\n",
      "train loss:0.004137727250354759\n",
      "train loss:0.0014117149817273612\n",
      "train loss:0.0022370885361266395\n",
      "train loss:0.0028502635076560977\n",
      "train loss:0.025435745025749138\n",
      "train loss:0.002469282187137557\n",
      "train loss:0.00420220279440332\n",
      "train loss:0.0007560921424735006\n",
      "train loss:0.023449747902302573\n",
      "train loss:0.0035414286604516215\n",
      "train loss:0.003068200635716427\n",
      "train loss:0.0002583913645773289\n",
      "train loss:0.02193780037126074\n",
      "train loss:0.0030596660529282295\n",
      "train loss:0.00010507554640392854\n",
      "train loss:0.013687770529957873\n",
      "train loss:0.00951576051073053\n",
      "train loss:0.002202465606496534\n",
      "train loss:0.005334530669577241\n",
      "train loss:0.002735734947083651\n",
      "train loss:0.0021735316004878966\n",
      "train loss:0.003100163790200973\n",
      "train loss:0.005138956966441621\n",
      "train loss:0.0005397669162656138\n",
      "train loss:0.00039056479091618843\n",
      "train loss:0.004605449527372466\n",
      "train loss:0.0008294109904682645\n",
      "train loss:0.0031874798302322376\n",
      "train loss:0.002244633446958371\n",
      "train loss:0.017096564222399246\n",
      "train loss:0.0034320504705962385\n",
      "train loss:0.0009877061550003148\n",
      "train loss:0.0029790105298314945\n",
      "train loss:0.0007587427570395844\n",
      "train loss:0.000345264106599386\n",
      "train loss:0.004440347159463363\n",
      "train loss:0.009880300763076154\n",
      "train loss:0.0011024473003056103\n",
      "train loss:0.0035239897214962156\n",
      "train loss:0.0030977238341815794\n",
      "=== epoch:14, train acc:0.995, test acc:0.984 ===\n",
      "train loss:0.01402705860755214\n",
      "train loss:0.00222298421519137\n",
      "train loss:0.009152859049340815\n",
      "train loss:0.0005757068680666733\n",
      "train loss:0.011729473279572123\n",
      "train loss:0.00031417913260064725\n",
      "train loss:0.002295336701337087\n",
      "train loss:0.0021120943532460085\n",
      "train loss:0.00012395933376569277\n",
      "train loss:0.00043588783083096347\n",
      "train loss:0.0006091171622157631\n",
      "train loss:0.006604968910000637\n",
      "train loss:0.0013262203913975356\n",
      "train loss:0.0027728556184348917\n",
      "train loss:0.007757022527549162\n",
      "train loss:0.00064318530755615\n",
      "train loss:0.0029845353024430645\n",
      "train loss:0.001932244686698972\n",
      "train loss:0.009262909240977977\n",
      "train loss:0.0032641531966650693\n",
      "train loss:0.003171623310374771\n",
      "train loss:0.0008726155564037307\n",
      "train loss:0.0015371080593367626\n",
      "train loss:0.002397406615091496\n",
      "train loss:0.0042855635886020725\n",
      "train loss:0.0004111652278205624\n",
      "train loss:0.0025682047449223024\n",
      "train loss:0.03912052678157106\n",
      "train loss:0.0036253824560535785\n",
      "train loss:0.017601725051915332\n",
      "train loss:0.000710938975516046\n",
      "train loss:0.002112893696547752\n",
      "train loss:0.003596574548249062\n",
      "train loss:0.0055553555206996515\n",
      "train loss:0.006196898537736333\n",
      "train loss:0.001310283242508352\n",
      "train loss:0.0008693428861384841\n",
      "train loss:0.00949821802969151\n",
      "train loss:0.010181552899645587\n",
      "train loss:0.00611142504596067\n",
      "train loss:0.0017890844431590594\n",
      "train loss:0.0059137499554113215\n",
      "train loss:0.0014256490233774224\n",
      "train loss:0.0008618223811331646\n",
      "train loss:0.002516830048279446\n",
      "train loss:0.0034115954799110396\n",
      "train loss:0.0022004330039744418\n",
      "train loss:0.006495192698210928\n",
      "train loss:0.006956162128428849\n",
      "train loss:0.004036407706776246\n",
      "train loss:0.006091967160140146\n",
      "train loss:0.0018527221157535682\n",
      "train loss:0.0022502678519673407\n",
      "train loss:0.0003283483065359498\n",
      "train loss:0.002755462685978687\n",
      "train loss:0.0013305455367473892\n",
      "train loss:0.0014281309037547896\n",
      "train loss:0.002545162106757373\n",
      "train loss:0.0036728144215998093\n",
      "train loss:0.016167447804095632\n",
      "train loss:0.0021282655069876054\n",
      "train loss:0.0036917329974723535\n",
      "train loss:0.008855061561353652\n",
      "train loss:0.002874967925192574\n",
      "train loss:0.0016920495118309049\n",
      "train loss:0.0076437270871001165\n",
      "train loss:0.0008400286270506866\n",
      "train loss:0.004877114116454065\n",
      "train loss:0.0002866236322787688\n",
      "train loss:0.003792063885608366\n",
      "train loss:0.00370020010623482\n",
      "train loss:0.004206133392717992\n",
      "train loss:0.0008447941375770527\n",
      "train loss:0.004951449965566245\n",
      "train loss:0.0008893612039965239\n",
      "train loss:0.0017556955328288063\n",
      "train loss:0.020042461919058077\n",
      "train loss:0.029715758694110455\n",
      "train loss:0.00166937270067009\n",
      "train loss:0.003078653059578351\n",
      "train loss:0.0007381278412693796\n",
      "train loss:0.00013344763390543598\n",
      "train loss:0.004585143258402766\n",
      "train loss:0.002270303367629811\n",
      "train loss:0.003290770217183793\n",
      "train loss:0.006589221447017437\n",
      "train loss:0.0021433905861095114\n",
      "train loss:0.004222487386442546\n",
      "train loss:0.010964454549149169\n",
      "train loss:0.002086698411273453\n",
      "train loss:0.005028216633700632\n",
      "train loss:0.009039670773321887\n",
      "train loss:0.006163146180510042\n",
      "train loss:0.004234755882944805\n",
      "train loss:0.006716336721967123\n",
      "train loss:0.005922785257217587\n",
      "train loss:0.005553143554662583\n",
      "train loss:0.006920073329165086\n",
      "train loss:0.0014882447806246581\n",
      "train loss:0.0004311144164756195\n",
      "train loss:0.001883014374070653\n",
      "train loss:0.000613921744784576\n",
      "train loss:0.022258742833046477\n",
      "train loss:0.00035076712790790636\n",
      "train loss:0.0005681100286796395\n",
      "train loss:0.0049029133286514655\n",
      "train loss:0.006600940004307062\n",
      "train loss:0.0014072385339181888\n",
      "train loss:0.001187075942988963\n",
      "train loss:0.008328784549118125\n",
      "train loss:0.044394043378645005\n",
      "train loss:0.002146233692375317\n",
      "train loss:0.0008893588950983855\n",
      "train loss:0.0014824355962258376\n",
      "train loss:0.0008883216818230072\n",
      "train loss:0.0072656496512848775\n",
      "train loss:0.0014007924707498279\n",
      "train loss:0.002040851971718878\n",
      "train loss:0.00300163216302507\n",
      "train loss:0.000590905656533635\n",
      "train loss:0.0013147264067958433\n",
      "train loss:0.004626320851600711\n",
      "train loss:0.0024406139492628882\n",
      "train loss:0.004079415889668791\n",
      "train loss:0.0020559816158344\n",
      "train loss:0.03610972585593097\n",
      "train loss:0.0011811670198777781\n",
      "train loss:0.007528675901779945\n",
      "train loss:0.0018923248890197644\n",
      "train loss:0.0013079452646017399\n",
      "train loss:0.002633139017495597\n",
      "train loss:0.004919557471244104\n",
      "train loss:0.0002499378715660196\n",
      "train loss:0.013435584075421328\n",
      "train loss:0.0011639043095885118\n",
      "train loss:0.008894171197777377\n",
      "train loss:0.004699849082764081\n",
      "train loss:0.003840992008254189\n",
      "train loss:0.0008442630000783824\n",
      "train loss:0.0007510702460487842\n",
      "train loss:0.0013911169318495615\n",
      "train loss:0.0003997532279136844\n",
      "train loss:0.0009233399153532642\n",
      "train loss:0.00952726978046889\n",
      "train loss:0.025764909441683814\n",
      "train loss:0.010794583299617602\n",
      "train loss:0.004394920591160986\n",
      "train loss:0.0031580563111649855\n",
      "train loss:0.003639964803219341\n",
      "train loss:0.002785266982101316\n",
      "train loss:0.0020131942730472223\n",
      "train loss:0.0015869766564567222\n",
      "train loss:0.006490808107751379\n",
      "train loss:0.0015395597402945696\n",
      "train loss:0.002880784851440615\n",
      "train loss:0.013795515045663977\n",
      "train loss:0.00030068828970768337\n",
      "train loss:0.004783951964164094\n",
      "train loss:0.0007102349851752489\n",
      "train loss:0.003374833966534838\n",
      "train loss:0.041141833713373585\n",
      "train loss:0.00027640889900560505\n",
      "train loss:0.05456580550518051\n",
      "train loss:0.004064827015215298\n",
      "train loss:0.0029616484128923907\n",
      "train loss:0.023914648655646173\n",
      "train loss:0.00017490639098888798\n",
      "train loss:0.0029111248639071014\n",
      "train loss:0.0008349550115429986\n",
      "train loss:0.006438466444349189\n",
      "train loss:0.0027121668509374596\n",
      "train loss:0.009561519004121222\n",
      "train loss:0.0056138184166472874\n",
      "train loss:0.0022920350759096557\n",
      "train loss:0.006329341626325099\n",
      "train loss:0.001268823663891041\n",
      "train loss:0.005164601957210961\n",
      "train loss:0.009519265673988378\n",
      "train loss:0.0058619853522276786\n",
      "train loss:0.004043594372757689\n",
      "train loss:0.0037030570478886345\n",
      "train loss:0.0016531089443503246\n",
      "train loss:0.011280516782346832\n",
      "train loss:0.00207059499561897\n",
      "train loss:0.03218081462559958\n",
      "train loss:0.01796160506501131\n",
      "train loss:0.001041346885781275\n",
      "train loss:0.00012461832978050147\n",
      "train loss:0.008726073061541247\n",
      "train loss:0.0013253822834016966\n",
      "train loss:0.0031201845140658695\n",
      "train loss:0.011308651781076366\n",
      "train loss:0.013037784818065414\n",
      "train loss:0.00563164038202561\n",
      "train loss:0.004723321519023146\n",
      "train loss:0.004409054347741403\n",
      "train loss:0.030098029991471965\n",
      "train loss:0.005767667754450481\n",
      "train loss:0.016933115840936958\n",
      "train loss:0.0008550922772046457\n",
      "train loss:0.006100125028773424\n",
      "train loss:0.0031693774421198057\n",
      "train loss:0.007257182081046267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01658306619848773\n",
      "train loss:0.0014679385000210435\n",
      "train loss:0.022408784544125652\n",
      "train loss:0.0027976119265252803\n",
      "train loss:0.013550941825058414\n",
      "train loss:0.001804090367697094\n",
      "train loss:0.010784093349519429\n",
      "train loss:0.011346841802452785\n",
      "train loss:0.001663781437021048\n",
      "train loss:0.0030460105661656105\n",
      "train loss:0.0027027161838113654\n",
      "train loss:0.014067903213112291\n",
      "train loss:0.0006725529813355573\n",
      "train loss:0.008838680114979725\n",
      "train loss:0.01377341157804844\n",
      "train loss:0.023160698176091885\n",
      "train loss:0.0019440510404131056\n",
      "train loss:0.0025270762009181745\n",
      "train loss:0.002495500830668249\n",
      "train loss:0.00287697582525236\n",
      "train loss:0.0018169477220718094\n",
      "train loss:0.004645446904926866\n",
      "train loss:0.0014840812083459312\n",
      "train loss:0.014020031278727219\n",
      "train loss:0.01220198844398038\n",
      "train loss:0.00813588081859013\n",
      "train loss:0.0011286578054203378\n",
      "train loss:0.014500170184036093\n",
      "train loss:0.0012572641989497993\n",
      "train loss:0.0013006223058850826\n",
      "train loss:0.000406787777008104\n",
      "train loss:0.003104810849110548\n",
      "train loss:0.0007241613983872536\n",
      "train loss:0.0006314747221771191\n",
      "train loss:0.004972571509190478\n",
      "train loss:0.04938870988793745\n",
      "train loss:0.00298403799484695\n",
      "train loss:0.0010391175643167064\n",
      "train loss:0.0023994586468692753\n",
      "train loss:0.007056978837018038\n",
      "train loss:0.005739305195459875\n",
      "train loss:0.008968727294196892\n",
      "train loss:0.023135152600155574\n",
      "train loss:0.05368325012280708\n",
      "train loss:0.007712558694547364\n",
      "train loss:0.007767679020298937\n",
      "train loss:0.0035255684739710657\n",
      "train loss:0.004136194931040776\n",
      "train loss:0.0005288023047853981\n",
      "train loss:0.008097810860031425\n",
      "train loss:0.005152169744536604\n",
      "train loss:0.0019978810861488432\n",
      "train loss:0.0008032046595643261\n",
      "train loss:0.0021537179525627638\n",
      "train loss:0.0023113753252127487\n",
      "train loss:0.010695537218178142\n",
      "train loss:0.007702643331403108\n",
      "train loss:0.0015508306819987025\n",
      "train loss:0.004823056471821168\n",
      "train loss:0.006974343206908317\n",
      "train loss:6.529794463016385e-05\n",
      "train loss:0.0037265986360651205\n",
      "train loss:0.0075036845265197116\n",
      "train loss:0.002677084483835992\n",
      "train loss:0.009638447601032506\n",
      "train loss:0.005144262624813883\n",
      "train loss:0.002418383780357866\n",
      "train loss:0.01388612693638082\n",
      "train loss:0.0014066723534439005\n",
      "train loss:0.0012235634629949813\n",
      "train loss:0.001429109104205869\n",
      "train loss:0.0026913765742954997\n",
      "train loss:0.007679291957777839\n",
      "train loss:0.001350971761734051\n",
      "train loss:0.01224336753084815\n",
      "train loss:0.005608888908019859\n",
      "train loss:0.0005994377310614286\n",
      "train loss:0.003201571986111934\n",
      "train loss:0.006838317044560643\n",
      "train loss:0.0020300868451695628\n",
      "train loss:0.007512542505685863\n",
      "train loss:0.008626302054944366\n",
      "train loss:0.004429675655464264\n",
      "train loss:0.00014850352256475907\n",
      "train loss:0.0018831325406252358\n",
      "train loss:0.0009635184941535488\n",
      "train loss:0.0013972531244081418\n",
      "train loss:0.0012189363241816326\n",
      "train loss:0.0021153775519391366\n",
      "train loss:0.004002151172750149\n",
      "train loss:0.0017945877159937038\n",
      "train loss:0.0032106719125242888\n",
      "train loss:0.00311295472663037\n",
      "train loss:0.004611170322287547\n",
      "train loss:0.00034278795296189337\n",
      "train loss:0.01316859892351297\n",
      "train loss:0.0005774526633870533\n",
      "train loss:0.012613330533077869\n",
      "train loss:0.0006571273973218808\n",
      "train loss:0.003818541351069586\n",
      "train loss:0.0007660629046701615\n",
      "train loss:0.0017126807922763986\n",
      "train loss:0.0006843228915240443\n",
      "train loss:0.00427244377872629\n",
      "train loss:0.005375846000572031\n",
      "train loss:0.004293928695901517\n",
      "train loss:0.007868765636438329\n",
      "train loss:0.008151553416388931\n",
      "train loss:0.0028790369439746348\n",
      "train loss:0.0032002342521454522\n",
      "train loss:0.045927364064229294\n",
      "train loss:0.0005708407228263406\n",
      "train loss:0.000982566299548393\n",
      "train loss:0.0026979783271639845\n",
      "train loss:0.0006713808711927749\n",
      "train loss:0.005943590640803148\n",
      "train loss:0.004623090342421221\n",
      "train loss:0.010283310815826077\n",
      "train loss:0.014096481853357374\n",
      "train loss:0.00020221814893149883\n",
      "train loss:0.0005951240391252426\n",
      "train loss:0.008094129436218634\n",
      "train loss:0.0023932891796395904\n",
      "train loss:0.0016982067625643635\n",
      "train loss:0.009434495222308593\n",
      "train loss:0.00426939995481074\n",
      "train loss:0.03193362137493155\n",
      "train loss:0.0031424493279872128\n",
      "train loss:0.0054616736701957914\n",
      "train loss:0.0008286639370926351\n",
      "train loss:0.0015571542770515215\n",
      "train loss:0.005267212685354724\n",
      "train loss:0.007859143820955294\n",
      "train loss:0.004114986710401234\n",
      "train loss:0.01205832570491323\n",
      "train loss:0.0005952204743931742\n",
      "train loss:0.011352458427997364\n",
      "train loss:0.002526453495478029\n",
      "train loss:0.0048224852435137565\n",
      "train loss:0.02118109784618743\n",
      "train loss:0.001109229575789176\n",
      "train loss:0.0052697451503767485\n",
      "train loss:0.0250262945919061\n",
      "train loss:0.0018482714855439085\n",
      "train loss:0.005353012791966876\n",
      "train loss:0.0043683984958665\n",
      "train loss:0.0047734836891284195\n",
      "train loss:0.0019510584370599346\n",
      "train loss:0.017382425646476435\n",
      "train loss:0.00048117093585436254\n",
      "train loss:0.004004608594027378\n",
      "train loss:0.08156470666498994\n",
      "train loss:0.039404735096675615\n",
      "train loss:0.00031137407343233877\n",
      "train loss:0.026951332415879242\n",
      "train loss:0.0025163011862030403\n",
      "train loss:0.0018471532387960622\n",
      "train loss:0.0004080448594971531\n",
      "train loss:0.0003774073597923707\n",
      "train loss:0.007074065038478477\n",
      "train loss:0.005927430432483612\n",
      "train loss:0.0025425708131307867\n",
      "train loss:0.005805247242713568\n",
      "train loss:0.003514864245077221\n",
      "train loss:0.0016216944326467846\n",
      "train loss:0.026618440618342714\n",
      "train loss:0.004197419119582419\n",
      "train loss:0.0007157995824297652\n",
      "train loss:0.0014691688963720795\n",
      "train loss:0.0017246195549479632\n",
      "train loss:0.0043843939282605686\n",
      "train loss:0.0024838069513138483\n",
      "train loss:0.0017624759907458618\n",
      "train loss:0.0071793224805725055\n",
      "train loss:0.005381918834268718\n",
      "train loss:0.004434346501050027\n",
      "train loss:0.012258050672331938\n",
      "train loss:0.00100727228814032\n",
      "train loss:0.012152313891041166\n",
      "train loss:0.004973405884147564\n",
      "train loss:0.05055249161621046\n",
      "train loss:0.0013697090434984446\n",
      "train loss:0.0020402704237485834\n",
      "train loss:0.007611319476695239\n",
      "train loss:0.013439782820702954\n",
      "train loss:0.00034950235044815814\n",
      "train loss:0.000871016300290768\n",
      "train loss:0.0015317375934508345\n",
      "train loss:0.0023987771061183007\n",
      "train loss:0.004862382979234917\n",
      "train loss:0.004931104272845111\n",
      "train loss:0.0013876283163636277\n",
      "train loss:0.002176805953135356\n",
      "train loss:0.0010611022971032285\n",
      "train loss:0.0011434916545423799\n",
      "train loss:0.004022008057477277\n",
      "train loss:0.0036734031176358702\n",
      "train loss:0.0009038962602921836\n",
      "train loss:0.0024108310371649335\n",
      "train loss:0.000322962476505276\n",
      "train loss:0.010262121107845738\n",
      "train loss:0.0008836573761119987\n",
      "train loss:0.003635912615025683\n",
      "train loss:0.0017318872842662905\n",
      "train loss:0.002736316222283299\n",
      "train loss:0.010847892088670801\n",
      "train loss:0.0011953663200421688\n",
      "train loss:0.006910932125994355\n",
      "train loss:0.002012992849673326\n",
      "train loss:0.0011693081804692968\n",
      "train loss:0.021198651308926\n",
      "train loss:0.011738845315673638\n",
      "train loss:0.011974010071055266\n",
      "train loss:0.005585139532375776\n",
      "train loss:0.0002740091278548482\n",
      "train loss:0.00037114203154429363\n",
      "train loss:0.00830294880999909\n",
      "train loss:0.00461364554546135\n",
      "train loss:0.000516128041194734\n",
      "train loss:0.0022896885343002445\n",
      "train loss:0.008719472657387815\n",
      "train loss:0.007768978137954857\n",
      "train loss:0.004903130840220458\n",
      "train loss:0.0008384030585462325\n",
      "train loss:0.004831963776829682\n",
      "train loss:0.0017248132767965336\n",
      "train loss:0.013408295842679961\n",
      "train loss:0.004653277671783846\n",
      "train loss:0.07492062320201125\n",
      "train loss:0.004647697117389608\n",
      "train loss:0.0028579368801606715\n",
      "train loss:0.0014695549612958874\n",
      "train loss:0.0011467536224962931\n",
      "train loss:0.0009436441970847764\n",
      "train loss:0.0027081879035981997\n",
      "train loss:0.008418411549198875\n",
      "train loss:0.0009269447911701904\n",
      "train loss:0.002301701496019345\n",
      "train loss:0.013149227683655179\n",
      "train loss:0.0006821675284169391\n",
      "train loss:0.0020503722715843166\n",
      "train loss:0.0006377197744261955\n",
      "train loss:0.003076589418602767\n",
      "train loss:0.008002267296838228\n",
      "train loss:0.0022490827478636797\n",
      "train loss:0.00239876848450303\n",
      "train loss:0.0028637464782464727\n",
      "train loss:0.0013544240265281717\n",
      "train loss:0.0025652833877104976\n",
      "train loss:0.004041506621109552\n",
      "train loss:0.00048262085394123186\n",
      "train loss:0.0007834578234040282\n",
      "train loss:0.003398394573790226\n",
      "train loss:0.0023855457099582326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010387615819929825\n",
      "train loss:0.001787441694470665\n",
      "train loss:0.0050960289125397355\n",
      "train loss:0.006561160887294715\n",
      "train loss:0.0009048901419721861\n",
      "train loss:0.002341674903949666\n",
      "train loss:0.00042634409436244835\n",
      "train loss:0.002663679821173334\n",
      "train loss:0.0005657971919579859\n",
      "train loss:0.002748344400653024\n",
      "train loss:0.00406547039608826\n",
      "train loss:0.013097760527699325\n",
      "train loss:0.0016871150356253199\n",
      "train loss:0.003593178750306306\n",
      "train loss:0.006869037880248126\n",
      "train loss:0.008277081130385212\n",
      "train loss:0.0060454101967613175\n",
      "train loss:0.042758192033531824\n",
      "train loss:0.0020891810278025665\n",
      "train loss:0.0011682651911777188\n",
      "train loss:0.0004940657093633964\n",
      "train loss:0.004587295407853138\n",
      "train loss:0.0017178930274827878\n",
      "train loss:0.0037969308847181638\n",
      "train loss:0.006814509579557871\n",
      "train loss:0.0001860359720881184\n",
      "train loss:0.0003373450054342684\n",
      "train loss:0.014473323946508809\n",
      "train loss:0.010913914883368549\n",
      "train loss:0.007720269298503848\n",
      "train loss:0.0007008533418887924\n",
      "train loss:0.00301772865919856\n",
      "train loss:0.007948018583239604\n",
      "train loss:0.00625183420593687\n",
      "train loss:0.0004815127748013495\n",
      "train loss:0.0002867124296548295\n",
      "train loss:0.0012566526762179781\n",
      "train loss:0.006215273896245505\n",
      "train loss:0.017959931423269192\n",
      "train loss:0.009078194152534415\n",
      "train loss:0.00470499422893085\n",
      "train loss:0.008354876702151178\n",
      "train loss:0.003729497878331852\n",
      "train loss:0.0005584400591868052\n",
      "train loss:0.0010635730270374811\n",
      "train loss:0.018955719018226635\n",
      "train loss:0.012425758804356663\n",
      "train loss:0.002291394681767286\n",
      "train loss:0.0031683368961221837\n",
      "train loss:0.008844413909229465\n",
      "train loss:0.0008390334413051403\n",
      "train loss:0.0045513082494492785\n",
      "train loss:0.0022423551148053845\n",
      "train loss:0.005759966890013579\n",
      "train loss:0.0013595352865265892\n",
      "train loss:0.011760247763739351\n",
      "train loss:0.00042215138248095105\n",
      "train loss:0.007584852738296636\n",
      "train loss:0.007234079878127645\n",
      "train loss:0.006426058388128042\n",
      "train loss:0.0014279939906299785\n",
      "train loss:0.002334204424435442\n",
      "train loss:0.007961343485910724\n",
      "train loss:0.0037876412297919776\n",
      "train loss:0.004950543176049336\n",
      "train loss:0.0063273760866817816\n",
      "train loss:0.0032745302937340183\n",
      "train loss:0.011106561134486834\n",
      "train loss:0.0012006758020867815\n",
      "train loss:0.024664157033090824\n",
      "train loss:0.0012764180685605078\n",
      "train loss:0.0006377017384730133\n",
      "train loss:0.001986486932469188\n",
      "train loss:0.0013923873052617203\n",
      "train loss:0.005563696543211143\n",
      "train loss:0.01168141937917757\n",
      "train loss:0.011031492698183805\n",
      "train loss:0.002134995252600512\n",
      "train loss:0.002020483892147618\n",
      "train loss:0.0009546492090751441\n",
      "train loss:0.0013216077379995864\n",
      "train loss:0.0035252013976412705\n",
      "train loss:0.011599353772204673\n",
      "train loss:0.0005017961656501611\n",
      "train loss:0.009336207365320709\n",
      "train loss:0.0122389639647628\n",
      "train loss:0.0009939716299975968\n",
      "train loss:0.0014020171198533369\n",
      "train loss:0.002681793969853832\n",
      "train loss:0.00869307075281537\n",
      "train loss:0.0007195909147844964\n",
      "train loss:0.0013639674943594392\n",
      "train loss:0.00644630186259245\n",
      "train loss:0.008185426288701106\n",
      "train loss:0.0008984176875200496\n",
      "train loss:0.0022653533846651295\n",
      "train loss:0.002235089098385992\n",
      "train loss:0.0038826854236796056\n",
      "train loss:0.0008062778039583505\n",
      "train loss:0.0036813685665023138\n",
      "train loss:0.0030016944826080287\n",
      "train loss:0.018751573477490933\n",
      "train loss:0.004888047750091522\n",
      "train loss:0.0023419133188919638\n",
      "train loss:0.0007907129947938265\n",
      "train loss:0.0005717600889218069\n",
      "train loss:0.001994502706199132\n",
      "train loss:0.0043423644168631105\n",
      "train loss:0.008712983708492725\n",
      "train loss:0.006114346433629247\n",
      "train loss:0.0007788401483064416\n",
      "train loss:0.0027627041780842383\n",
      "train loss:0.010142075282825918\n",
      "train loss:0.0008125053973459533\n",
      "train loss:0.003074050814821209\n",
      "train loss:0.0050964926643423236\n",
      "train loss:0.004067566273305016\n",
      "train loss:0.0027189503342232558\n",
      "train loss:0.0013809530955980198\n",
      "train loss:0.0018563819119290404\n",
      "train loss:0.0004517407446467069\n",
      "train loss:0.0015269154888842198\n",
      "train loss:0.0029465506443782756\n",
      "train loss:0.0006043750459638651\n",
      "train loss:0.002792690744116419\n",
      "train loss:0.0017387866462315199\n",
      "train loss:0.026538336512022108\n",
      "train loss:0.005108481406162004\n",
      "train loss:0.0008645414143168084\n",
      "train loss:0.0012604751221851854\n",
      "train loss:0.002429569456542498\n",
      "train loss:0.005875572031427637\n",
      "train loss:0.0017179160414200548\n",
      "train loss:0.0007023704878769674\n",
      "train loss:0.003703995395835025\n",
      "train loss:0.0017321243242867101\n",
      "train loss:0.007331536887349658\n",
      "train loss:0.0021945098591514937\n",
      "train loss:0.0008705765381974716\n",
      "train loss:0.0016408501502137595\n",
      "train loss:0.0025081294032365154\n",
      "train loss:0.0004028732757107409\n",
      "train loss:0.004099382768588245\n",
      "=== epoch:15, train acc:0.996, test acc:0.992 ===\n",
      "train loss:0.0016781732424577917\n",
      "train loss:0.0028659110340734633\n",
      "train loss:0.0035596289794615427\n",
      "train loss:0.003376503653160752\n",
      "train loss:0.0029345486862675835\n",
      "train loss:0.0037857507094673755\n",
      "train loss:0.03537477047763761\n",
      "train loss:0.0026392008601871042\n",
      "train loss:0.0003427985836290683\n",
      "train loss:0.002257392628531541\n",
      "train loss:0.002356894422511591\n",
      "train loss:0.0015037774858641445\n",
      "train loss:0.0008734086339831211\n",
      "train loss:0.00047300886436383763\n",
      "train loss:0.00084766048391546\n",
      "train loss:0.002954934514188856\n",
      "train loss:0.0010785805232289406\n",
      "train loss:0.0011610886824007433\n",
      "train loss:0.01051472640387283\n",
      "train loss:0.001419187682838615\n",
      "train loss:0.002436131938317598\n",
      "train loss:0.002911831385684428\n",
      "train loss:0.01440819798006609\n",
      "train loss:0.04513561381729701\n",
      "train loss:0.0010995549771738676\n",
      "train loss:0.0042140500900346165\n",
      "train loss:0.003977170506057684\n",
      "train loss:0.0008280707430586749\n",
      "train loss:0.0024682527408213454\n",
      "train loss:0.0009046680096649944\n",
      "train loss:0.012904940372598954\n",
      "train loss:0.0001072463262539984\n",
      "train loss:0.001238299434652027\n",
      "train loss:0.0035362473796539937\n",
      "train loss:0.008917737099739208\n",
      "train loss:3.9307704501715295e-05\n",
      "train loss:0.004789518799223216\n",
      "train loss:0.003271926495064412\n",
      "train loss:0.0010617782504811243\n",
      "train loss:0.00025523667995439476\n",
      "train loss:0.000607777417507518\n",
      "train loss:0.00238411374954369\n",
      "train loss:0.0024202035139448304\n",
      "train loss:0.006099847618456971\n",
      "train loss:0.0013823158181100047\n",
      "train loss:0.002080449466422259\n",
      "train loss:0.0015023902687137994\n",
      "train loss:0.0017300755377512892\n",
      "train loss:0.0051881053351289855\n",
      "train loss:0.014604872547991483\n",
      "train loss:0.001760264250740312\n",
      "train loss:0.0017983762557158894\n",
      "train loss:0.0029791409261447853\n",
      "train loss:0.00868910330265381\n",
      "train loss:0.0016034037139222338\n",
      "train loss:0.001875609477144618\n",
      "train loss:0.0032556181676085504\n",
      "train loss:0.0013756757080515955\n",
      "train loss:0.0004615052273423807\n",
      "train loss:0.0004807882241708227\n",
      "train loss:0.0042363845726836255\n",
      "train loss:0.0023732049668959672\n",
      "train loss:0.013299387286693679\n",
      "train loss:0.0019710257509287796\n",
      "train loss:0.006388841287018604\n",
      "train loss:0.0007542363274584105\n",
      "train loss:0.001287251449591029\n",
      "train loss:0.0009434395426987454\n",
      "train loss:0.00120461401547078\n",
      "train loss:0.0008396248253888308\n",
      "train loss:0.0008208603344667327\n",
      "train loss:0.004270637972908834\n",
      "train loss:0.004385196849298264\n",
      "train loss:0.0037783000684603026\n",
      "train loss:0.0012395592288241303\n",
      "train loss:0.0009041917634436147\n",
      "train loss:0.001227379129647052\n",
      "train loss:0.0022341428199971237\n",
      "train loss:0.0022759863604784854\n",
      "train loss:0.00046241420787467783\n",
      "train loss:0.0003319650531934237\n",
      "train loss:0.0042093650267293545\n",
      "train loss:0.0010048825566273234\n",
      "train loss:0.001346928959083558\n",
      "train loss:0.004398109989736837\n",
      "train loss:0.001753654375026453\n",
      "train loss:0.00017737893208621288\n",
      "train loss:0.0039815992606139885\n",
      "train loss:0.0021203505124507234\n",
      "train loss:0.00021790586609623863\n",
      "train loss:9.600900618167382e-05\n",
      "train loss:0.004540511213411962\n",
      "train loss:0.004104745020189232\n",
      "train loss:0.0005450346071349294\n",
      "train loss:0.0033024668584919763\n",
      "train loss:0.0006757388664964134\n",
      "train loss:0.0030025542587029446\n",
      "train loss:0.006009108712774216\n",
      "train loss:0.0006373563307589823\n",
      "train loss:0.00017728449134423962\n",
      "train loss:0.0037835086384212517\n",
      "train loss:0.001074816790048489\n",
      "train loss:0.000277159750775262\n",
      "train loss:0.001221047159335731\n",
      "train loss:0.001388511148389328\n",
      "train loss:0.0032926653528808024\n",
      "train loss:0.00015601669755944752\n",
      "train loss:0.00048439199549427743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009614957682860368\n",
      "train loss:0.008893292915122987\n",
      "train loss:0.0011945040356843495\n",
      "train loss:0.0045299634135056\n",
      "train loss:0.004382134730643164\n",
      "train loss:0.0004339968033245205\n",
      "train loss:0.0009232619128521339\n",
      "train loss:0.0004561301575373488\n",
      "train loss:0.001960941971037676\n",
      "train loss:0.00013308709040216941\n",
      "train loss:0.0047694086144852346\n",
      "train loss:0.004677002317722664\n",
      "train loss:0.026457142162401567\n",
      "train loss:0.00033102104876709987\n",
      "train loss:0.0018201352307998199\n",
      "train loss:0.00043122724219844355\n",
      "train loss:0.0009247970389268884\n",
      "train loss:0.002100690421077849\n",
      "train loss:0.00024984997470938207\n",
      "train loss:0.0005163633556494091\n",
      "train loss:0.0004890036690953002\n",
      "train loss:0.010783887842087362\n",
      "train loss:0.00019378906025213839\n",
      "train loss:0.004300488007827362\n",
      "train loss:0.0005993704668878193\n",
      "train loss:0.0009088179639678949\n",
      "train loss:0.0040806121828178875\n",
      "train loss:0.0016672935064803967\n",
      "train loss:0.001003523361472169\n",
      "train loss:0.01312097967949913\n",
      "train loss:0.0013389005325315942\n",
      "train loss:0.000622821853384028\n",
      "train loss:0.00029250012701126143\n",
      "train loss:0.0002938362118097887\n",
      "train loss:0.00018877543601944122\n",
      "train loss:0.001177194707291105\n",
      "train loss:0.0018440733622729585\n",
      "train loss:0.0015070103605155053\n",
      "train loss:0.008342788963363513\n",
      "train loss:0.0015390377676450329\n",
      "train loss:0.003061969202309029\n",
      "train loss:0.0017715579917245887\n",
      "train loss:0.0013072066070035438\n",
      "train loss:0.0013189696928592506\n",
      "train loss:0.00030109599535984416\n",
      "train loss:0.0024524448497002\n",
      "train loss:0.0017797593751235092\n",
      "train loss:0.00033569249507425287\n",
      "train loss:0.0001808844908882873\n",
      "train loss:0.0006579084673228572\n",
      "train loss:0.000920189489932508\n",
      "train loss:0.007008290168994092\n",
      "train loss:0.00688569458092238\n",
      "train loss:0.006818512979728617\n",
      "train loss:0.0004722115347915048\n",
      "train loss:0.0007318721139784297\n",
      "train loss:0.004531707817084459\n",
      "train loss:0.0003005655161612026\n",
      "train loss:0.0003568656257447626\n",
      "train loss:0.002730559077898435\n",
      "train loss:0.0007645665737992033\n",
      "train loss:0.0005385326159599406\n",
      "train loss:0.0011126891707259406\n",
      "train loss:0.010549793695073592\n",
      "train loss:0.0032934996431891444\n",
      "train loss:0.0019511984452594438\n",
      "train loss:0.0005485893328929178\n",
      "train loss:0.0004123752254663385\n",
      "train loss:0.003076440276540168\n",
      "train loss:0.0008327536371433715\n",
      "train loss:0.005691390375100568\n",
      "train loss:0.003944297569423027\n",
      "train loss:0.004319840474926167\n",
      "train loss:0.00022556410787647363\n",
      "train loss:0.011116545626632203\n",
      "train loss:0.015447161718815527\n",
      "train loss:0.017527711332619426\n",
      "train loss:0.010656093011148858\n",
      "train loss:0.0036217840549328984\n",
      "train loss:0.006228553687636028\n",
      "train loss:0.00017001932580820408\n",
      "train loss:0.0043979068235901145\n",
      "train loss:0.0009631578580731113\n",
      "train loss:0.0023860848083299734\n",
      "train loss:0.007916232507019972\n",
      "train loss:0.0002159226774013406\n",
      "train loss:0.020304133672019695\n",
      "train loss:0.0003965071443352811\n",
      "train loss:0.004796519328294849\n",
      "train loss:0.0002719493384784728\n",
      "train loss:0.00998522198906281\n",
      "train loss:0.0003284745032528405\n",
      "train loss:0.007618019151703732\n",
      "train loss:0.008026769643604425\n",
      "train loss:0.0033886589488022712\n",
      "train loss:0.003378737222764452\n",
      "train loss:0.0018405803383874748\n",
      "train loss:0.003067803752830828\n",
      "train loss:0.003205156283002121\n",
      "train loss:0.0015585798985271696\n",
      "train loss:0.0006559481691622631\n",
      "train loss:0.014347021454497242\n",
      "train loss:3.853408750885966e-05\n",
      "train loss:0.0035336716945154507\n",
      "train loss:0.0008756880207208526\n",
      "train loss:0.0007515568588998907\n",
      "train loss:0.01178266834399327\n",
      "train loss:0.0009118302603781952\n",
      "train loss:0.0007506100627009294\n",
      "train loss:0.00015611228296907604\n",
      "train loss:0.012126231689013913\n",
      "train loss:0.00196826137501793\n",
      "train loss:0.002283332585395794\n",
      "train loss:0.0021442271882592704\n",
      "train loss:0.006273450142870145\n",
      "train loss:0.0008743668207417195\n",
      "train loss:0.013008412731526342\n",
      "train loss:0.001683466545584661\n",
      "train loss:0.002092779193889002\n",
      "train loss:0.005842589529966319\n",
      "train loss:0.003227061894006799\n",
      "train loss:0.0018941850557139194\n",
      "train loss:0.00034243101121757047\n",
      "train loss:0.0017460064723914296\n",
      "train loss:0.010806795997365497\n",
      "train loss:0.016787866887871546\n",
      "train loss:0.0014705598819354073\n",
      "train loss:0.0019459192871662237\n",
      "train loss:0.0009623979199397007\n",
      "train loss:0.0033710246610718225\n",
      "train loss:0.002944029444189264\n",
      "train loss:0.004565941006511649\n",
      "train loss:0.000594751405111451\n",
      "train loss:0.001035907822545845\n",
      "train loss:0.004762929211425844\n",
      "train loss:0.0014136095740463828\n",
      "train loss:0.0021203237770436715\n",
      "train loss:0.01832929445927257\n",
      "train loss:0.0019389370412301768\n",
      "train loss:0.0018889962600536026\n",
      "train loss:0.0026797367006618877\n",
      "train loss:0.002833024007331589\n",
      "train loss:0.0017617610877653173\n",
      "train loss:0.00034308920673832176\n",
      "train loss:0.000992297160186785\n",
      "train loss:0.004921726045837286\n",
      "train loss:0.0024948147832276747\n",
      "train loss:0.0011717431232402596\n",
      "train loss:0.00579104991176801\n",
      "train loss:0.00012848848577261225\n",
      "train loss:0.0003331676876516749\n",
      "train loss:0.0011727927196108644\n",
      "train loss:0.011091964647303987\n",
      "train loss:0.0003044210201151125\n",
      "train loss:0.0003053069763250229\n",
      "train loss:0.002347365121204937\n",
      "train loss:0.009576898232670255\n",
      "train loss:0.017366444557835495\n",
      "train loss:0.0008775168818542189\n",
      "train loss:0.0016831726671141542\n",
      "train loss:0.0014545079100249637\n",
      "train loss:0.0038960744858949907\n",
      "train loss:0.0028763829946707644\n",
      "train loss:0.002265862858055201\n",
      "train loss:0.0002864024993285027\n",
      "train loss:0.001446089839501044\n",
      "train loss:8.424573612348716e-05\n",
      "train loss:0.0025921671371498737\n",
      "train loss:0.001504253892887667\n",
      "train loss:0.0018760963762609923\n",
      "train loss:0.005286042736894298\n",
      "train loss:0.002292563303822526\n",
      "train loss:0.009039076428118886\n",
      "train loss:0.0038873060271801207\n",
      "train loss:0.014300989680283992\n",
      "train loss:0.0018662954960646267\n",
      "train loss:0.0014970532125837199\n",
      "train loss:0.010160969189953194\n",
      "train loss:0.008617601359415838\n",
      "train loss:0.0016393179126595184\n",
      "train loss:0.00045496405840031706\n",
      "train loss:0.002972569100232587\n",
      "train loss:0.019725678280569786\n",
      "train loss:0.0021040997337763673\n",
      "train loss:0.0023079276557477226\n",
      "train loss:0.0001538105692020213\n",
      "train loss:0.00011592059841192216\n",
      "train loss:0.0006892085653844749\n",
      "train loss:0.0027619940861095434\n",
      "train loss:0.0007243887639309533\n",
      "train loss:0.0020974471532784664\n",
      "train loss:0.0008102056430913116\n",
      "train loss:0.0034831028631921663\n",
      "train loss:0.0030567153809672536\n",
      "train loss:0.0012856457221339013\n",
      "train loss:0.0035626149324851364\n",
      "train loss:0.001195663562332431\n",
      "train loss:0.0009531903438390299\n",
      "train loss:0.0011911868329086731\n",
      "train loss:0.000260704403001597\n",
      "train loss:0.009477285014116833\n",
      "train loss:0.017503038316935057\n",
      "train loss:0.001675786180119093\n",
      "train loss:0.004989937796363749\n",
      "train loss:0.0011579721942699824\n",
      "train loss:0.003250034547538015\n",
      "train loss:0.0010833476356111565\n",
      "train loss:0.004954549575489837\n",
      "train loss:0.005854288429132429\n",
      "train loss:0.003580480248316246\n",
      "train loss:6.888342289070184e-05\n",
      "train loss:0.004447611867561674\n",
      "train loss:0.004515144398175526\n",
      "train loss:0.00019777847381354232\n",
      "train loss:0.00039259337658948887\n",
      "train loss:0.005701132272176609\n",
      "train loss:0.0014135515735953707\n",
      "train loss:0.0002464563159223678\n",
      "train loss:0.0007602823907459213\n",
      "train loss:0.003982295781755323\n",
      "train loss:0.0025582805078531667\n",
      "train loss:0.008638659251613121\n",
      "train loss:0.0002765695909215498\n",
      "train loss:0.0002747407106920049\n",
      "train loss:0.0011543727402406397\n",
      "train loss:0.000578383392588051\n",
      "train loss:0.0007664526492382495\n",
      "train loss:0.03220707291409502\n",
      "train loss:0.004932131114040682\n",
      "train loss:0.0018226752738809062\n",
      "train loss:0.0016245392437318712\n",
      "train loss:0.0016362335925976521\n",
      "train loss:0.0003173757414561432\n",
      "train loss:0.0011899955287370495\n",
      "train loss:0.008488800329191531\n",
      "train loss:0.005029467750931491\n",
      "train loss:0.0004044504038830063\n",
      "train loss:0.016555007157300006\n",
      "train loss:4.856526795965584e-05\n",
      "train loss:0.0025112342133408803\n",
      "train loss:0.005430204350846856\n",
      "train loss:0.002973979412696555\n",
      "train loss:0.005096200384061469\n",
      "train loss:0.0034079966119359073\n",
      "train loss:0.0013369092798486497\n",
      "train loss:0.007964845341368128\n",
      "train loss:0.00039383093310731593\n",
      "train loss:0.0041545498145771275\n",
      "train loss:0.0020973324020505\n",
      "train loss:0.0008213131400359966\n",
      "train loss:0.0025471520768404533\n",
      "train loss:0.00013251257038772695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005859188020482052\n",
      "train loss:0.007228050014549463\n",
      "train loss:0.00027309535361814605\n",
      "train loss:0.0003067365320130472\n",
      "train loss:0.001421281012211487\n",
      "train loss:0.00017731127817354863\n",
      "train loss:0.0006480745140248546\n",
      "train loss:0.0067116071952597785\n",
      "train loss:0.00011843777490182172\n",
      "train loss:0.001415099169501884\n",
      "train loss:0.0007311575970206144\n",
      "train loss:0.0006808912582481028\n",
      "train loss:0.0012155643614244302\n",
      "train loss:0.0006648439069212546\n",
      "train loss:0.0007005461269175171\n",
      "train loss:0.0027226072573813607\n",
      "train loss:0.008017260117565145\n",
      "train loss:0.0019735633249450763\n",
      "train loss:0.011894561215737455\n",
      "train loss:0.014104279710698595\n",
      "train loss:0.004497727655542689\n",
      "train loss:0.0007092969939462004\n",
      "train loss:0.007747266701191746\n",
      "train loss:0.0030296328239687808\n",
      "train loss:0.0006174436611926261\n",
      "train loss:0.0016908139563457463\n",
      "train loss:0.0027204460841106885\n",
      "train loss:0.00011369955286085348\n",
      "train loss:0.011105084314797755\n",
      "train loss:0.0019138261024033633\n",
      "train loss:0.0026591108866190504\n",
      "train loss:0.0036595401262824612\n",
      "train loss:0.0020105924230546714\n",
      "train loss:0.002382568692168731\n",
      "train loss:0.003210709297866928\n",
      "train loss:0.010372020544336695\n",
      "train loss:0.00048458158270777633\n",
      "train loss:0.0016973093092540047\n",
      "train loss:0.0017786599618321384\n",
      "train loss:2.2055480476615086e-05\n",
      "train loss:0.007111473681483195\n",
      "train loss:0.0008197735303070737\n",
      "train loss:0.0010987326598824705\n",
      "train loss:0.0005349218554227924\n",
      "train loss:0.005879035411314653\n",
      "train loss:0.001422354986048682\n",
      "train loss:0.0007080859868300275\n",
      "train loss:0.008700301686042826\n",
      "train loss:0.0023925697257851687\n",
      "train loss:0.0007336603785737234\n",
      "train loss:0.0002202626019187383\n",
      "train loss:0.0012304028544419326\n",
      "train loss:0.0007054343192634805\n",
      "train loss:0.0008311004483053966\n",
      "train loss:0.000555562647033413\n",
      "train loss:0.002649407825259157\n",
      "train loss:0.0003306663446221422\n",
      "train loss:0.00028613989395071427\n",
      "train loss:0.0041239229813422144\n",
      "train loss:0.0004733222948120168\n",
      "train loss:0.003292709729383343\n",
      "train loss:0.00034995725453562947\n",
      "train loss:0.0013665265900926118\n",
      "train loss:0.0020818709359752777\n",
      "train loss:0.0035239470844316808\n",
      "train loss:0.000320091231627637\n",
      "train loss:0.0026362327195553208\n",
      "train loss:0.0024094836654454306\n",
      "train loss:0.0012019576985120614\n",
      "train loss:0.002821612892615907\n",
      "train loss:0.0020944278556131292\n",
      "train loss:0.0017089593870721058\n",
      "train loss:0.0022292218259964245\n",
      "train loss:0.005175291253740817\n",
      "train loss:0.0027962420318557485\n",
      "train loss:0.0003794621316777829\n",
      "train loss:0.004489905371727484\n",
      "train loss:0.00017971522074195173\n",
      "train loss:0.0015084841118936775\n",
      "train loss:0.00043973771793315845\n",
      "train loss:0.0022325982687334232\n",
      "train loss:0.022208471424782005\n",
      "train loss:0.0004907198039463056\n",
      "train loss:0.0013950279724565893\n",
      "train loss:0.0005695421319246834\n",
      "train loss:0.0003002775863414157\n",
      "train loss:0.0009397616493831868\n",
      "train loss:0.007828650621993739\n",
      "train loss:0.0023504288933581226\n",
      "train loss:0.002635674474245011\n",
      "train loss:0.0004509497164544559\n",
      "train loss:0.002744515419417777\n",
      "train loss:0.0015363047350265852\n",
      "train loss:0.00020278993504191023\n",
      "train loss:0.002962529235122609\n",
      "train loss:0.0011861576145864184\n",
      "train loss:0.0022282589046487824\n",
      "train loss:0.001053303140818906\n",
      "train loss:0.0016099788427360975\n",
      "train loss:0.0007794883402114683\n",
      "train loss:0.0011175965167704556\n",
      "train loss:0.002475077124317822\n",
      "train loss:0.0008747626323711721\n",
      "train loss:0.0006088781595147428\n",
      "train loss:0.00046963373911495013\n",
      "train loss:0.00022680251477198623\n",
      "train loss:0.0001802768689488014\n",
      "train loss:0.0005347537736274555\n",
      "train loss:0.00039094618049456795\n",
      "train loss:0.00029133672283294617\n",
      "train loss:0.0007281150679735297\n",
      "train loss:7.517412989299628e-05\n",
      "train loss:0.0007771469060908222\n",
      "train loss:0.0004276483380426648\n",
      "train loss:0.0019684949808083992\n",
      "train loss:0.0013275630653734485\n",
      "train loss:0.0004627023119111349\n",
      "train loss:0.0015758141570203343\n",
      "train loss:0.00016837884377430198\n",
      "train loss:0.00034655348812975877\n",
      "train loss:0.0023361144069521077\n",
      "train loss:0.0012693478729940532\n",
      "train loss:0.0015615129257548638\n",
      "train loss:0.0024002953995956662\n",
      "train loss:0.004767465947356185\n",
      "train loss:0.0002078906306104089\n",
      "train loss:0.0012594949391752993\n",
      "train loss:0.000494253229734178\n",
      "train loss:0.000838103671499332\n",
      "train loss:0.00020511937529979694\n",
      "train loss:0.001760163221773606\n",
      "train loss:0.005589497191423518\n",
      "train loss:0.0009015353080979638\n",
      "train loss:0.007540346626427365\n",
      "train loss:0.0017417725979584544\n",
      "train loss:0.00116701393001621\n",
      "train loss:0.00027029677269899117\n",
      "train loss:0.0004130564417444636\n",
      "train loss:0.0004406070970839132\n",
      "train loss:0.00038035729550360754\n",
      "train loss:0.001628468647034784\n",
      "train loss:0.00011749761018794226\n",
      "train loss:0.0009557902958236727\n",
      "train loss:0.0006253879490105697\n",
      "train loss:0.0010388778237570627\n",
      "train loss:0.003724492352892323\n",
      "train loss:0.0013232976874416405\n",
      "train loss:0.0002789431790635396\n",
      "train loss:0.00010186091247768468\n",
      "train loss:0.0007494490014094677\n",
      "train loss:0.0008488900066251244\n",
      "train loss:0.0017550963166304688\n",
      "train loss:0.0011594156950584403\n",
      "train loss:0.00023020837005269715\n",
      "train loss:0.0016907226457618001\n",
      "train loss:0.0021953461298249506\n",
      "train loss:0.0008018289069929394\n",
      "train loss:0.0015183762587034177\n",
      "train loss:0.0022399046559697\n",
      "train loss:0.0009781808461071446\n",
      "train loss:0.007490990359329887\n",
      "train loss:0.0001306706167346976\n",
      "train loss:0.000488357948723342\n",
      "train loss:0.0006867533164818852\n",
      "train loss:0.004296078681665442\n",
      "train loss:0.001362116333556893\n",
      "train loss:0.000278663172000716\n",
      "train loss:0.000819405952648847\n",
      "train loss:0.006544784293361158\n",
      "train loss:0.003249910570224289\n",
      "train loss:0.006374099740944813\n",
      "train loss:0.004338482083098931\n",
      "train loss:0.0068720526923037005\n",
      "train loss:0.0008446657099494173\n",
      "train loss:0.0034141933877950836\n",
      "train loss:0.004729986374595916\n",
      "train loss:0.001312750330122258\n",
      "train loss:0.005492920247555012\n",
      "train loss:0.0022051848746709544\n",
      "train loss:0.003801512154905135\n",
      "train loss:0.000997593923566023\n",
      "train loss:0.005492067296001616\n",
      "train loss:0.004801290381912698\n",
      "train loss:0.005101505985498077\n",
      "train loss:0.0035353907433995735\n",
      "train loss:0.0006559368842643709\n",
      "train loss:0.0010950670905855355\n",
      "train loss:0.0016065655281913011\n",
      "train loss:0.004192151470549218\n",
      "train loss:0.002367955274296501\n",
      "train loss:0.0013170441032905517\n",
      "train loss:0.0001994986975992681\n",
      "train loss:0.0008440307306701837\n",
      "train loss:0.0003168186539038797\n",
      "train loss:0.008036471910226037\n",
      "train loss:0.004386004458215884\n",
      "train loss:0.00012581730970111194\n",
      "train loss:0.002304715993309447\n",
      "train loss:0.00017059038218814276\n",
      "train loss:0.001205329108630269\n",
      "train loss:0.0013556108531948702\n",
      "train loss:0.0002344716965995867\n",
      "train loss:0.003058755874155869\n",
      "train loss:0.0027682442632592573\n",
      "train loss:0.0002344413077199675\n",
      "train loss:0.005937472001022403\n",
      "train loss:0.002522701541698419\n",
      "train loss:0.007329833519896224\n",
      "train loss:0.0005121504254639618\n",
      "train loss:0.022240042460280784\n",
      "train loss:0.0009883390090644414\n",
      "train loss:0.00042131307609416155\n",
      "train loss:0.0011623546231247246\n",
      "train loss:0.0038412493498607113\n",
      "train loss:0.003508143678039245\n",
      "train loss:0.0005740502535346134\n",
      "train loss:0.00010069314640870804\n",
      "train loss:0.00013558843219089263\n",
      "train loss:0.007554923832467034\n",
      "train loss:0.0021250167373896177\n",
      "train loss:0.01586599972427474\n",
      "train loss:0.0006840626555841451\n",
      "train loss:0.0013223642707277262\n",
      "train loss:0.002272746760985477\n",
      "train loss:0.0015349978927068383\n",
      "train loss:0.002549430178555226\n",
      "train loss:0.0019749020189364975\n",
      "train loss:0.0011375402874867389\n",
      "train loss:0.00030498899202505077\n",
      "train loss:0.0033717701937294757\n",
      "train loss:0.003927148171363987\n",
      "train loss:0.032595064587028134\n",
      "train loss:9.787460265748269e-06\n",
      "train loss:4.956066272276397e-05\n",
      "train loss:0.003201067540308371\n",
      "train loss:0.00036068051760407125\n",
      "train loss:0.0013704243117918869\n",
      "train loss:0.009311466328925513\n",
      "train loss:0.00021049345539559276\n",
      "train loss:0.004050617668793847\n",
      "=== epoch:16, train acc:0.995, test acc:0.981 ===\n",
      "train loss:0.0007378749466490531\n",
      "train loss:0.000801566103339929\n",
      "train loss:0.013572332987599158\n",
      "train loss:0.0012777895897374022\n",
      "train loss:0.000800046123652958\n",
      "train loss:0.0022351256380547775\n",
      "train loss:0.003959894258876234\n",
      "train loss:0.0013056599039056348\n",
      "train loss:0.00578898947746629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00435511547398651\n",
      "train loss:0.0018063040355529836\n",
      "train loss:0.0020599865927246365\n",
      "train loss:0.0020401145723221875\n",
      "train loss:0.0010459720599464313\n",
      "train loss:0.0066087845637005285\n",
      "train loss:0.00015541071640658082\n",
      "train loss:0.013874983337838685\n",
      "train loss:0.002557917175748658\n",
      "train loss:0.007384731211531503\n",
      "train loss:0.0011604781982019325\n",
      "train loss:0.003780410057641562\n",
      "train loss:0.01101520947251423\n",
      "train loss:0.0006287708748763912\n",
      "train loss:0.002592525462661651\n",
      "train loss:0.001835278392706174\n",
      "train loss:0.002567912209450195\n",
      "train loss:0.001843352363035722\n",
      "train loss:0.0007514410339130252\n",
      "train loss:0.0051467898463322505\n",
      "train loss:0.009393672264195041\n",
      "train loss:0.0019875345784682234\n",
      "train loss:0.00187763247166052\n",
      "train loss:0.0005886228146541254\n",
      "train loss:0.0021335936269543106\n",
      "train loss:0.00017504439381008585\n",
      "train loss:0.0023929526266718774\n",
      "train loss:0.000778821353978971\n",
      "train loss:0.006864059694404973\n",
      "train loss:0.0003551877641538571\n",
      "train loss:0.001381587364732391\n",
      "train loss:0.0002186509774118695\n",
      "train loss:0.0022546068037880675\n",
      "train loss:0.022942187365745905\n",
      "train loss:0.0224987673811493\n",
      "train loss:0.014016783358294203\n",
      "train loss:0.014356628956540282\n",
      "train loss:0.002268701782873667\n",
      "train loss:0.00019598056306517305\n",
      "train loss:0.001155068239427868\n",
      "train loss:0.003983905357410868\n",
      "train loss:0.003947457866082957\n",
      "train loss:0.02044039190571777\n",
      "train loss:0.004735940064287638\n",
      "train loss:0.005841325874119824\n",
      "train loss:0.004535537367010571\n",
      "train loss:0.006683516943723639\n",
      "train loss:0.003059109608428415\n",
      "train loss:0.00039111058848455103\n",
      "train loss:0.0002880544399409933\n",
      "train loss:0.0011488191319849652\n",
      "train loss:0.002388401433778318\n",
      "train loss:0.0014072095984143968\n",
      "train loss:0.0005562426543552708\n",
      "train loss:0.01498294151957174\n",
      "train loss:0.002824276673625906\n",
      "train loss:0.0021785982965471123\n",
      "train loss:0.00052081058517196\n",
      "train loss:0.0012339432886048181\n",
      "train loss:0.0021379854150381764\n",
      "train loss:0.0005883792213634014\n",
      "train loss:0.0017094613729409474\n",
      "train loss:0.0022069819835907507\n",
      "train loss:0.0016675386701034836\n",
      "train loss:0.0005130878694268379\n",
      "train loss:0.0009482959011108801\n",
      "train loss:0.00035821218121543833\n",
      "train loss:0.00011181634349391204\n",
      "train loss:0.0021438608074740694\n",
      "train loss:0.00014167983193978914\n",
      "train loss:0.0026600616040946224\n",
      "train loss:8.868939553921812e-05\n",
      "train loss:0.002175964111747486\n",
      "train loss:0.0013349040004193248\n",
      "train loss:0.0030747228890802333\n",
      "train loss:0.0028287605226288747\n",
      "train loss:0.00031298730063416836\n",
      "train loss:0.0012200046869351928\n",
      "train loss:0.00034926939990980626\n",
      "train loss:0.0008073871125519837\n",
      "train loss:0.001442516379006088\n",
      "train loss:0.0027855488695806042\n",
      "train loss:0.008872157099064476\n",
      "train loss:0.001808630449817545\n",
      "train loss:0.00035468245049108193\n",
      "train loss:0.0015222265910559926\n",
      "train loss:0.0011735186906635013\n",
      "train loss:0.008172591513056897\n",
      "train loss:0.0035512373749315177\n",
      "train loss:0.004051305281068716\n",
      "train loss:0.00029948520312417617\n",
      "train loss:0.004068773096792358\n",
      "train loss:0.0010487485363589553\n",
      "train loss:0.001225791759741629\n",
      "train loss:0.0017264650107586075\n",
      "train loss:0.04745070139751126\n",
      "train loss:0.0016628177213537554\n",
      "train loss:0.0013618099484571434\n",
      "train loss:0.0004007290199854402\n",
      "train loss:0.0009438527113898354\n",
      "train loss:0.0014143215948084072\n",
      "train loss:0.00013851074725895364\n",
      "train loss:0.0009620604348714426\n",
      "train loss:0.0015004738949404473\n",
      "train loss:0.0035530830065918645\n",
      "train loss:0.0010144162078340121\n",
      "train loss:0.002494130329761591\n",
      "train loss:0.00024755055722415064\n",
      "train loss:0.0008943744553038589\n",
      "train loss:0.002923461365579481\n",
      "train loss:0.0015222752269025577\n",
      "train loss:0.0003100344052589765\n",
      "train loss:0.00029846520979620003\n",
      "train loss:0.0009563084158688669\n",
      "train loss:0.002144810791238257\n",
      "train loss:0.0015617678573994443\n",
      "train loss:0.000592546093574816\n",
      "train loss:0.0001133838320219701\n",
      "train loss:0.002155802187518257\n",
      "train loss:0.004443540735130003\n",
      "train loss:0.000184648354191656\n",
      "train loss:0.0004843847701208654\n",
      "train loss:0.0001519823147765158\n",
      "train loss:0.0031199091295537693\n",
      "train loss:0.0027549280307558634\n",
      "train loss:0.0020802276566217\n",
      "train loss:0.00044707109448533427\n",
      "train loss:0.0004720860434477504\n",
      "train loss:0.002103309236255477\n",
      "train loss:0.0035506971728955145\n",
      "train loss:0.001573490366100693\n",
      "train loss:0.0018706821356241513\n",
      "train loss:0.0022382730757658895\n",
      "train loss:0.00041587350248226644\n",
      "train loss:0.00428968139459617\n",
      "train loss:0.0014262432251429644\n",
      "train loss:0.0004989921114679196\n",
      "train loss:0.0018499742396613512\n",
      "train loss:0.00016296147114996148\n",
      "train loss:0.0005469180694115775\n",
      "train loss:0.0017621235640897953\n",
      "train loss:0.0010290840844719973\n",
      "train loss:0.001975164890044644\n",
      "train loss:0.0005743700180075174\n",
      "train loss:0.005767084722678132\n",
      "train loss:0.0020249820789923255\n",
      "train loss:0.0015851900178585016\n",
      "train loss:0.0042649520091019195\n",
      "train loss:0.0041541701187185\n",
      "train loss:0.0011721882638464358\n",
      "train loss:0.0043132705077984865\n",
      "train loss:0.0008319143060086963\n",
      "train loss:0.0023813462550345966\n",
      "train loss:0.0016454115076121186\n",
      "train loss:0.00043285990052245127\n",
      "train loss:0.00028617105718786864\n",
      "train loss:0.00033774233899871867\n",
      "train loss:8.51096903040522e-05\n",
      "train loss:0.0006787387883684403\n",
      "train loss:0.00019702076738260026\n",
      "train loss:0.0022444777787327336\n",
      "train loss:0.0022504771106264133\n",
      "train loss:0.004149560454040559\n",
      "train loss:0.0015733179360754908\n",
      "train loss:0.0020832841514760825\n",
      "train loss:0.00039975381774011583\n",
      "train loss:0.0013777753500643177\n",
      "train loss:0.0023482632876717477\n",
      "train loss:0.001801727021979605\n",
      "train loss:2.0528955725126786e-05\n",
      "train loss:0.0006866981236767172\n",
      "train loss:0.006013039225367295\n",
      "train loss:0.0007841879459886378\n",
      "train loss:0.00030618190915512845\n",
      "train loss:0.0017705167850523495\n",
      "train loss:0.0003449039603247773\n",
      "train loss:0.0001044382552707584\n",
      "train loss:0.002423245029850517\n",
      "train loss:0.0014144466322275812\n",
      "train loss:0.0007225214352904513\n",
      "train loss:0.0009981486265998798\n",
      "train loss:0.004491855201273261\n",
      "train loss:0.0005612263863721465\n",
      "train loss:0.004715820393688194\n",
      "train loss:0.00032183763151117517\n",
      "train loss:0.006697441791551068\n",
      "train loss:0.0005659888688939749\n",
      "train loss:0.00204388535420076\n",
      "train loss:0.0002858925016864704\n",
      "train loss:7.158921184285846e-05\n",
      "train loss:0.0005392032200655963\n",
      "train loss:0.00023884782518063765\n",
      "train loss:0.005192262991367133\n",
      "train loss:0.00029573591279151006\n",
      "train loss:0.0007587870343366044\n",
      "train loss:0.0003551076738378489\n",
      "train loss:0.0002795906372251007\n",
      "train loss:0.00038603926144960054\n",
      "train loss:0.018313303114344058\n",
      "train loss:0.0011553483477027464\n",
      "train loss:0.006340852412983884\n",
      "train loss:0.000456061759807942\n",
      "train loss:0.0006155360059140821\n",
      "train loss:0.0009712232116526506\n",
      "train loss:0.0020726284720352798\n",
      "train loss:0.0002010734674732877\n",
      "train loss:0.00022800618915075333\n",
      "train loss:0.0028309827369159047\n",
      "train loss:0.0018392218657319942\n",
      "train loss:0.0008075133021601641\n",
      "train loss:0.0013766349457457361\n",
      "train loss:0.00024102844940251115\n",
      "train loss:0.001366176941434566\n",
      "train loss:0.0014768618401804986\n",
      "train loss:0.004196878881895117\n",
      "train loss:0.0008188759590485753\n",
      "train loss:0.0018757045280697376\n",
      "train loss:0.0011332075331898102\n",
      "train loss:0.0007346186188441657\n",
      "train loss:0.0034176498948045105\n",
      "train loss:0.0003112333981608348\n",
      "train loss:0.0004335166008237674\n",
      "train loss:0.0008864702559874043\n",
      "train loss:0.0009076121963333277\n",
      "train loss:0.0031782447444035538\n",
      "train loss:0.00428492859139617\n",
      "train loss:0.0025765188497047058\n",
      "train loss:0.00010308346178967226\n",
      "train loss:0.002559746918867577\n",
      "train loss:0.000673489746235942\n",
      "train loss:5.7559096151449e-05\n",
      "train loss:0.0007796734230035962\n",
      "train loss:0.0008621309084042479\n",
      "train loss:0.004555695680058929\n",
      "train loss:0.0012207999965958946\n",
      "train loss:0.00324361004532321\n",
      "train loss:7.407881912028631e-05\n",
      "train loss:0.0001631948900537565\n",
      "train loss:0.009213843492277845\n",
      "train loss:0.0023380569409871686\n",
      "train loss:0.00035655968883843074\n",
      "train loss:0.0012982665636993465\n",
      "train loss:0.00013142268258363042\n",
      "train loss:0.00021192972447530643\n",
      "train loss:0.001539270385157673\n",
      "train loss:0.00032137695855214066\n",
      "train loss:7.058301582528822e-05\n",
      "train loss:0.0030339774900501344\n",
      "train loss:0.004324446389732004\n",
      "train loss:0.004945902277726724\n",
      "train loss:0.0001651089115519481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0021001529669681124\n",
      "train loss:0.00032496638162859384\n",
      "train loss:0.0005580354944086175\n",
      "train loss:0.0005367994701166553\n",
      "train loss:0.003108543861580515\n",
      "train loss:0.000266793343815359\n",
      "train loss:0.0007527550277074067\n",
      "train loss:0.029328054902048883\n",
      "train loss:0.006265768349367231\n",
      "train loss:0.0007725633462121136\n",
      "train loss:9.187715484524279e-05\n",
      "train loss:0.0017897014667223982\n",
      "train loss:0.0015537773245940306\n",
      "train loss:0.0016197313316035026\n",
      "train loss:0.0020036360791551\n",
      "train loss:0.0009677466206360956\n",
      "train loss:0.0028056959634559938\n",
      "train loss:0.0002017443469842101\n",
      "train loss:0.0022002091152815316\n",
      "train loss:0.0005704995752668263\n",
      "train loss:0.005689768691068306\n",
      "train loss:0.0026761381713950884\n",
      "train loss:0.001974378174412735\n",
      "train loss:0.0006437478069937586\n",
      "train loss:0.0017120338801127838\n",
      "train loss:0.0001421069113141928\n",
      "train loss:0.001370086117794025\n",
      "train loss:0.0014164327506528316\n",
      "train loss:0.0005698712258345461\n",
      "train loss:0.0012395699932986936\n",
      "train loss:0.006222361029913616\n",
      "train loss:0.00041423214345350943\n",
      "train loss:0.0013980805059523901\n",
      "train loss:0.00019955221896142354\n",
      "train loss:0.003722316080127161\n",
      "train loss:0.000957294326732169\n",
      "train loss:0.0001775722706325669\n",
      "train loss:0.0016186088466231465\n",
      "train loss:0.009864126543739608\n",
      "train loss:0.0009242806300799767\n",
      "train loss:0.005998532543910973\n",
      "train loss:0.00037787021450164945\n",
      "train loss:0.00036847650346191735\n",
      "train loss:0.0019281133430619963\n",
      "train loss:0.000458104943883661\n",
      "train loss:0.000684093290270605\n",
      "train loss:0.0054000104914620995\n",
      "train loss:0.00024537645763965236\n",
      "train loss:0.00019442837916394537\n",
      "train loss:0.0005060024703769664\n",
      "train loss:2.8994615818163143e-05\n",
      "train loss:0.0012878124585038965\n",
      "train loss:0.00045019065450631535\n",
      "train loss:0.0003057568780930992\n",
      "train loss:0.0038249456730429098\n",
      "train loss:9.093009326222101e-05\n",
      "train loss:0.001163320440428129\n",
      "train loss:0.0002995888278965384\n",
      "train loss:0.0007877740595614083\n",
      "train loss:0.0008071807577536803\n",
      "train loss:0.00014157033992421458\n",
      "train loss:0.0033875060550054518\n",
      "train loss:0.001159855399663998\n",
      "train loss:0.008920952218232128\n",
      "train loss:0.0002405315111755739\n",
      "train loss:0.0012525242108201015\n",
      "train loss:0.0004944928435136357\n",
      "train loss:3.673841514107228e-05\n",
      "train loss:0.004611829393523328\n",
      "train loss:0.001963501658242399\n",
      "train loss:0.004069161461305547\n",
      "train loss:0.00016245116427167936\n",
      "train loss:0.0025830725144217245\n",
      "train loss:0.0058923275695703355\n",
      "train loss:5.96713189776074e-05\n",
      "train loss:0.0010985398551500972\n",
      "train loss:0.0006310799320438005\n",
      "train loss:0.023883843974262332\n",
      "train loss:0.00036593067121449\n",
      "train loss:8.280679428296745e-05\n",
      "train loss:0.0008145888254611577\n",
      "train loss:0.0044784758105798714\n",
      "train loss:0.00011680940160512165\n",
      "train loss:0.0044657701660159805\n",
      "train loss:0.0031800062656877027\n",
      "train loss:0.00435268741517256\n",
      "train loss:0.004043704797489441\n",
      "train loss:0.002162189884996295\n",
      "train loss:0.0006113459587355667\n",
      "train loss:0.001199151221379343\n",
      "train loss:0.0004333120514165473\n",
      "train loss:0.00037448092549850846\n",
      "train loss:0.006720084107503153\n",
      "train loss:0.0001908599239188858\n",
      "train loss:0.013130252024886144\n",
      "train loss:0.00047337869685545777\n",
      "train loss:0.004388671803335102\n",
      "train loss:1.914055520331847e-05\n",
      "train loss:0.002111632756644546\n",
      "train loss:0.00175268189103847\n",
      "train loss:0.0008269122493424205\n",
      "train loss:0.0008311811636057032\n",
      "train loss:0.001024286667859169\n",
      "train loss:0.00032369668714623547\n",
      "train loss:0.0026401961320973418\n",
      "train loss:0.005074060372298007\n",
      "train loss:0.00016370465392378267\n",
      "train loss:0.00010257820919734432\n",
      "train loss:0.004803488156301186\n",
      "train loss:0.0008110639290804415\n",
      "train loss:0.0037344205012902554\n",
      "train loss:0.0008659436754983908\n",
      "train loss:0.00015960157365264526\n",
      "train loss:0.0001093468847571805\n",
      "train loss:0.003764914593319705\n",
      "train loss:0.0030162666621876854\n",
      "train loss:0.0023303152996804024\n",
      "train loss:0.0014646290537102607\n",
      "train loss:0.004814589209144881\n",
      "train loss:0.0012414284546478447\n",
      "train loss:0.004896343656616944\n",
      "train loss:0.0004248927664478718\n",
      "train loss:0.0008282967313459881\n",
      "train loss:5.4463995313722015e-05\n",
      "train loss:0.0001315653843913525\n",
      "train loss:0.001323357751315145\n",
      "train loss:0.00044839495473221713\n",
      "train loss:0.0014003600854519947\n",
      "train loss:0.00046973765430236773\n",
      "train loss:0.0012443187738906507\n",
      "train loss:0.004457921988694099\n",
      "train loss:0.00030833430769807097\n",
      "train loss:0.006220709779834854\n",
      "train loss:0.00024970525707592513\n",
      "train loss:0.004103747593525247\n",
      "train loss:0.0008460567192397745\n",
      "train loss:0.0011893369650086978\n",
      "train loss:0.00034399574355678986\n",
      "train loss:0.0035360745544451\n",
      "train loss:0.002559161757348518\n",
      "train loss:0.0004284567172270969\n",
      "train loss:0.002450867556029471\n",
      "train loss:0.001064086883943838\n",
      "train loss:0.0023836236494294096\n",
      "train loss:0.003667228000581735\n",
      "train loss:0.0013849738733279196\n",
      "train loss:0.0009644843672759426\n",
      "train loss:0.0009784575831375643\n",
      "train loss:0.0014271986690853216\n",
      "train loss:0.00013561291979850734\n",
      "train loss:0.0013791280499871152\n",
      "train loss:0.0035064153703146116\n",
      "train loss:0.0017918076244129943\n",
      "train loss:0.0013937386573519047\n",
      "train loss:0.00018932063872293835\n",
      "train loss:0.0026070064082742627\n",
      "train loss:0.0010565920936094772\n",
      "train loss:0.0003722650782208478\n",
      "train loss:0.016310697391953045\n",
      "train loss:0.001975728511952425\n",
      "train loss:0.0019488364578673606\n",
      "train loss:0.00013440355878071016\n",
      "train loss:0.010866891654202137\n",
      "train loss:0.0004168060976569559\n",
      "train loss:0.0012909080656646407\n",
      "train loss:0.0029660568837138242\n",
      "train loss:0.0010439615222716688\n",
      "train loss:0.0012800778749602088\n",
      "train loss:0.017920135174454354\n",
      "train loss:0.0004045843009975425\n",
      "train loss:0.00283935558288642\n",
      "train loss:0.00014243081402462443\n",
      "train loss:0.013241742983817955\n",
      "train loss:0.0010394700737363597\n",
      "train loss:0.0019904897629208786\n",
      "train loss:0.00010517523307301919\n",
      "train loss:0.00024042565002256095\n",
      "train loss:8.302204734348581e-05\n",
      "train loss:0.0021821782424344617\n",
      "train loss:0.0001308734522675499\n",
      "train loss:0.01611592330394708\n",
      "train loss:0.0022452749461810916\n",
      "train loss:0.0013052632845926527\n",
      "train loss:0.0005023038789522394\n",
      "train loss:0.0012027194784785286\n",
      "train loss:0.0006802986782879564\n",
      "train loss:0.010683162900490406\n",
      "train loss:0.0005437249075505191\n",
      "train loss:0.0013799689500191856\n",
      "train loss:0.04607665568225373\n",
      "train loss:0.0002300034076671802\n",
      "train loss:7.645464449531e-05\n",
      "train loss:0.008270463998505641\n",
      "train loss:0.0026620949997136763\n",
      "train loss:0.0026024963795179728\n",
      "train loss:0.0007746107041040864\n",
      "train loss:0.0017734617894407789\n",
      "train loss:0.019215169643000907\n",
      "train loss:0.0006142942210608251\n",
      "train loss:8.88597910765488e-05\n",
      "train loss:0.00067689221446419\n",
      "train loss:0.0016902572640432154\n",
      "train loss:0.005292195549310469\n",
      "train loss:0.011554072204188259\n",
      "train loss:0.01922138033418197\n",
      "train loss:0.022102040730574472\n",
      "train loss:0.004120815941694187\n",
      "train loss:0.00023789908456377262\n",
      "train loss:0.006049444792692792\n",
      "train loss:0.0002719837007681287\n",
      "train loss:0.00036564564962529133\n",
      "train loss:0.0008366185454044605\n",
      "train loss:0.00146781766081492\n",
      "train loss:0.03644888311837637\n",
      "train loss:0.0201202237761264\n",
      "train loss:0.001101853152331243\n",
      "train loss:0.0020095495537268797\n",
      "train loss:0.0022476746591727835\n",
      "train loss:0.00369879274625914\n",
      "train loss:0.005001964506747894\n",
      "train loss:0.0008329484283059296\n",
      "train loss:0.005687506103525884\n",
      "train loss:0.004024919306492255\n",
      "train loss:4.4784365355715364e-05\n",
      "train loss:0.0002976202365096252\n",
      "train loss:0.0003047223125636643\n",
      "train loss:0.0004707883785074996\n",
      "train loss:0.0007814456363589895\n",
      "train loss:0.0002736731073208154\n",
      "train loss:0.0053755768075217595\n",
      "train loss:0.0038447274821919604\n",
      "train loss:0.0008370340974153638\n",
      "train loss:0.0031386175214166913\n",
      "train loss:0.00046606579966226115\n",
      "train loss:0.0013584203153346917\n",
      "train loss:0.00674770508609045\n",
      "train loss:0.00046800542511348864\n",
      "train loss:0.002300724779915666\n",
      "train loss:0.0026902233282217244\n",
      "train loss:0.003118870007846941\n",
      "train loss:0.0015590018538506006\n",
      "train loss:0.00015318575792067684\n",
      "train loss:0.0028364601539076313\n",
      "train loss:0.0004405549229851384\n",
      "train loss:0.0014658452299350483\n",
      "train loss:0.002350532380447391\n",
      "train loss:0.0004731424042806967\n",
      "train loss:0.0017813022057610397\n",
      "train loss:3.981560198704199e-05\n",
      "train loss:0.0008161666813234075\n",
      "train loss:0.0011081900912227835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.019708533826937644\n",
      "train loss:3.665690706927926e-05\n",
      "train loss:0.0008606355942984887\n",
      "train loss:0.0015380307262292917\n",
      "train loss:0.0017427888471926406\n",
      "train loss:0.004416382084072698\n",
      "train loss:0.008051015520499711\n",
      "train loss:0.0012854278409347463\n",
      "train loss:0.003885680049897054\n",
      "train loss:0.003992249350982533\n",
      "train loss:0.0015190332556572542\n",
      "train loss:0.0019465920505015838\n",
      "train loss:0.0008247186969826353\n",
      "train loss:0.00044352054516019903\n",
      "train loss:0.0005701693522916415\n",
      "train loss:0.0021006252267649047\n",
      "train loss:0.00020153329335756962\n",
      "train loss:0.0006074870377695639\n",
      "train loss:0.0010027065686415149\n",
      "train loss:0.0021856164861740386\n",
      "train loss:0.0022044823293990924\n",
      "train loss:0.022211107787705294\n",
      "train loss:0.0021695230188773433\n",
      "train loss:0.0011446167520979236\n",
      "train loss:0.0009224619539303723\n",
      "train loss:0.009081398568612663\n",
      "train loss:0.0020997878951102933\n",
      "train loss:0.0007689123717610497\n",
      "train loss:0.014372904315209262\n",
      "train loss:0.001279320687300943\n",
      "train loss:0.0015256232253612447\n",
      "train loss:0.0012056074617343422\n",
      "train loss:0.0004941320219555716\n",
      "train loss:0.0010492381509909368\n",
      "train loss:0.0018985694254518293\n",
      "train loss:0.0004285243363795659\n",
      "train loss:0.005285216288256897\n",
      "train loss:0.005178090241304335\n",
      "train loss:0.009711264570336716\n",
      "train loss:0.001197682891873429\n",
      "train loss:0.003482826831281173\n",
      "train loss:0.002602933349823923\n",
      "train loss:0.0030621247243634462\n",
      "train loss:0.0008636607308631605\n",
      "train loss:0.000918067894446219\n",
      "train loss:0.0012561604741546236\n",
      "train loss:0.014441090672289\n",
      "train loss:0.0050273152275898654\n",
      "train loss:0.000986175077049384\n",
      "train loss:0.0015694480337560951\n",
      "train loss:0.005874094648690702\n",
      "train loss:0.002796584157787663\n",
      "train loss:0.006678818164597713\n",
      "train loss:0.001472669724536615\n",
      "train loss:0.012482257717112024\n",
      "train loss:0.012053858851847534\n",
      "train loss:0.00403973045485399\n",
      "train loss:0.00042094049108143037\n",
      "train loss:0.00017798760211326574\n",
      "train loss:0.0008660975547931069\n",
      "train loss:0.00016147927594113435\n",
      "train loss:0.002854149386595984\n",
      "train loss:0.0005087917339410937\n",
      "train loss:0.0008347622659585356\n",
      "train loss:0.0005562471636219327\n",
      "train loss:0.0014480062355308977\n",
      "train loss:0.004907478964249045\n",
      "train loss:0.00774985510013699\n",
      "train loss:0.0032540734375177526\n",
      "train loss:0.0018638854899839241\n",
      "train loss:0.0056166075591671406\n",
      "train loss:0.032860640400365425\n",
      "train loss:0.0013641952981868716\n",
      "train loss:0.0025545034048969247\n",
      "train loss:0.010915671029844611\n",
      "train loss:0.003957178423954666\n",
      "train loss:0.022752237372265584\n",
      "train loss:0.003978133453369267\n",
      "train loss:0.0005312391059075325\n",
      "train loss:0.001324796652730103\n",
      "train loss:0.001928321860720913\n",
      "train loss:0.0032752421618366845\n",
      "train loss:0.0007046816808391296\n",
      "train loss:0.0073188332975569195\n",
      "train loss:0.0037998786851727345\n",
      "train loss:0.004748399478953492\n",
      "train loss:0.004875987772959015\n",
      "train loss:0.0005577918144553508\n",
      "train loss:0.0002884658118378614\n",
      "=== epoch:17, train acc:0.997, test acc:0.983 ===\n",
      "train loss:0.0030156292944942937\n",
      "train loss:0.002497384303289701\n",
      "train loss:0.0002839077169038591\n",
      "train loss:0.013000851498656039\n",
      "train loss:0.0016160220367652384\n",
      "train loss:0.0005969388433260294\n",
      "train loss:0.0006913157151492742\n",
      "train loss:0.0071985922935298985\n",
      "train loss:0.0002970653568242925\n",
      "train loss:0.0031434630733537527\n",
      "train loss:0.0030716411671068726\n",
      "train loss:0.0013964361144197883\n",
      "train loss:0.001021313289034818\n",
      "train loss:0.0069154075055060426\n",
      "train loss:0.0010366408752274596\n",
      "train loss:0.002840022306858274\n",
      "train loss:0.0011919557096563246\n",
      "train loss:0.000771633453890476\n",
      "train loss:0.0022743852632595776\n",
      "train loss:0.0014332634397131447\n",
      "train loss:0.0051588719817791595\n",
      "train loss:0.011705323007413393\n",
      "train loss:0.001012980520120942\n",
      "train loss:0.0030606206619764108\n",
      "train loss:0.000741709874497896\n",
      "train loss:0.0007564640201723023\n",
      "train loss:0.002127280025751538\n",
      "train loss:0.033649026370938244\n",
      "train loss:0.0014865208784858586\n",
      "train loss:0.0010651845723106436\n",
      "train loss:0.0017735305957957898\n",
      "train loss:0.0012570434013489062\n",
      "train loss:0.0010754636669651249\n",
      "train loss:0.0001200759521966632\n",
      "train loss:0.0003330662280201017\n",
      "train loss:0.0006014652804589423\n",
      "train loss:0.00022930410492395567\n",
      "train loss:0.003852761564459331\n",
      "train loss:0.0025182339421334706\n",
      "train loss:0.0019549590257873896\n",
      "train loss:0.006260749691713731\n",
      "train loss:0.0012252722385661151\n",
      "train loss:0.0037070170651105783\n",
      "train loss:0.00829852533517521\n",
      "train loss:0.0005403425052618708\n",
      "train loss:0.0018313928655595301\n",
      "train loss:0.0007729176545456126\n",
      "train loss:0.000670492149403704\n",
      "train loss:0.0027156348050069285\n",
      "train loss:0.011240030303735932\n",
      "train loss:0.0007505631528483658\n",
      "train loss:9.928595239527264e-05\n",
      "train loss:0.0019610969420827836\n",
      "train loss:0.0009190247806791606\n",
      "train loss:0.014145734339123696\n",
      "train loss:0.0016422061631469586\n",
      "train loss:0.002325677747074203\n",
      "train loss:0.0003579706613933737\n",
      "train loss:0.0007955783906583115\n",
      "train loss:0.00031453829787882084\n",
      "train loss:0.004101104561720576\n",
      "train loss:0.001826279910615564\n",
      "train loss:0.0001779254787365594\n",
      "train loss:0.0003620646276503084\n",
      "train loss:0.0014164451232561892\n",
      "train loss:0.0028967807328011273\n",
      "train loss:0.0021449274394147832\n",
      "train loss:7.805534110904803e-05\n",
      "train loss:0.000241744534348067\n",
      "train loss:0.0013694259803760272\n",
      "train loss:0.0002890537830392468\n",
      "train loss:0.00012970833427048916\n",
      "train loss:9.583045676084218e-05\n",
      "train loss:0.0007576203780567224\n",
      "train loss:0.00015519426117560712\n",
      "train loss:0.00021011882918095084\n",
      "train loss:0.006864229825478333\n",
      "train loss:0.008111446509489932\n",
      "train loss:7.197608853122465e-05\n",
      "train loss:0.0013650392152429363\n",
      "train loss:0.0028523596306376017\n",
      "train loss:0.0004546195380569786\n",
      "train loss:0.008206422635308252\n",
      "train loss:0.00026666128174228284\n",
      "train loss:0.00011414491972807958\n",
      "train loss:0.00038536565311550133\n",
      "train loss:0.0027031718112287564\n",
      "train loss:0.000612486658573972\n",
      "train loss:0.0015308324431624442\n",
      "train loss:0.0014956193446664062\n",
      "train loss:0.0011312281968002013\n",
      "train loss:0.003629248089510417\n",
      "train loss:0.006830687351045266\n",
      "train loss:0.0008811970595825557\n",
      "train loss:0.0010211703419365043\n",
      "train loss:0.00016537859488934077\n",
      "train loss:0.002180064365514891\n",
      "train loss:0.0001651539261042016\n",
      "train loss:0.000255605885545742\n",
      "train loss:0.0012644929266864518\n",
      "train loss:0.0060222075218649375\n",
      "train loss:0.0016978156883349265\n",
      "train loss:0.00010333912195130246\n",
      "train loss:0.0006676744944696708\n",
      "train loss:0.0006649695053315077\n",
      "train loss:0.0034176453207126114\n",
      "train loss:0.0013097714003740797\n",
      "train loss:0.0006884264137747873\n",
      "train loss:0.0001677298759158871\n",
      "train loss:0.0005471801203056028\n",
      "train loss:0.0051671087964770554\n",
      "train loss:0.0001178004519016882\n",
      "train loss:7.700806391838276e-05\n",
      "train loss:0.0019476348406940807\n",
      "train loss:0.006265007643005984\n",
      "train loss:0.00013050203930725272\n",
      "train loss:0.0014537742311372538\n",
      "train loss:0.0016578049529223727\n",
      "train loss:0.0008469843135021889\n",
      "train loss:0.0028108545289011427\n",
      "train loss:0.0015638841843270178\n",
      "train loss:0.0009053224056268725\n",
      "train loss:0.003981666421064367\n",
      "train loss:0.0031958188715656465\n",
      "train loss:0.0008584013645565598\n",
      "train loss:0.0034161306319686487\n",
      "train loss:0.0031458627328654633\n",
      "train loss:0.0032934966293926378\n",
      "train loss:0.0015153969517140299\n",
      "train loss:0.0027823943608067015\n",
      "train loss:0.004245843940134\n",
      "train loss:0.0012866568921600134\n",
      "train loss:0.001118905839902466\n",
      "train loss:0.0012100130116241804\n",
      "train loss:0.002488491431995525\n",
      "train loss:0.0002719588785766014\n",
      "train loss:0.00014036010290461763\n",
      "train loss:0.0016747596602379408\n",
      "train loss:0.0017773680172868647\n",
      "train loss:0.002315743537859114\n",
      "train loss:0.0008335075323997491\n",
      "train loss:0.006581400299904746\n",
      "train loss:0.001926944817382798\n",
      "train loss:0.001461929962546197\n",
      "train loss:0.0009642144197368901\n",
      "train loss:0.0012015739252095178\n",
      "train loss:0.004298104605948899\n",
      "train loss:0.0012550927569967753\n",
      "train loss:0.00039812789076429904\n",
      "train loss:0.0010538919955745834\n",
      "train loss:0.0027911125795262353\n",
      "train loss:0.0014842134563885678\n",
      "train loss:0.00014252864611615228\n",
      "train loss:0.0010620657455454575\n",
      "train loss:0.0016682779536734468\n",
      "train loss:0.0009723517458433131\n",
      "train loss:0.0014155340151694204\n",
      "train loss:0.0013591874151010132\n",
      "train loss:0.0010283222470461918\n",
      "train loss:0.0027139552850476163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0017159639483376927\n",
      "train loss:0.009928272054276965\n",
      "train loss:0.000571914771517167\n",
      "train loss:3.673887537822256e-05\n",
      "train loss:0.0022055720854284215\n",
      "train loss:0.002020354837679741\n",
      "train loss:0.0003057770495855063\n",
      "train loss:0.003765227038826255\n",
      "train loss:7.801661643843101e-05\n",
      "train loss:0.0008252534862599232\n",
      "train loss:0.0013903410661865831\n",
      "train loss:0.00030170961100165107\n",
      "train loss:0.0006809295867457775\n",
      "train loss:0.004531100652466784\n",
      "train loss:0.0029410147379518524\n",
      "train loss:0.00016231017482050137\n",
      "train loss:0.00014239777364533567\n",
      "train loss:0.0017003772521956583\n",
      "train loss:0.00032290460701378683\n",
      "train loss:0.0019500915693551495\n",
      "train loss:0.002249035933552474\n",
      "train loss:0.0014792527235711604\n",
      "train loss:0.0002904448988650218\n",
      "train loss:0.0008343772390621444\n",
      "train loss:0.0014530341344060078\n",
      "train loss:0.002210433063743105\n",
      "train loss:0.0017954928689172653\n",
      "train loss:0.0013098268484434412\n",
      "train loss:0.0017665749767866697\n",
      "train loss:1.5885991100870073e-05\n",
      "train loss:0.000560061806518163\n",
      "train loss:0.000585839826542469\n",
      "train loss:0.004320850627030725\n",
      "train loss:0.0012357898912584275\n",
      "train loss:0.003421651954424607\n",
      "train loss:0.004142712048806732\n",
      "train loss:0.0001756680089646195\n",
      "train loss:0.0005380441889724078\n",
      "train loss:0.03511254561052486\n",
      "train loss:0.00025375390145341003\n",
      "train loss:0.000335054979837439\n",
      "train loss:0.0003439714179752013\n",
      "train loss:0.0006073587906896587\n",
      "train loss:0.00024432420844509536\n",
      "train loss:0.003967435322428073\n",
      "train loss:0.002668393439822771\n",
      "train loss:0.0011504199504821656\n",
      "train loss:0.0026900764665946895\n",
      "train loss:0.0012602912489719951\n",
      "train loss:0.002191015674451539\n",
      "train loss:0.00300758359619727\n",
      "train loss:0.0006336031417056883\n",
      "train loss:0.0034291873396196542\n",
      "train loss:0.0008291219747201817\n",
      "train loss:0.005832612219594873\n",
      "train loss:0.0004078083649756263\n",
      "train loss:0.0007900593467996334\n",
      "train loss:0.0004912608892898108\n",
      "train loss:0.001658982109102193\n",
      "train loss:0.0003407506150611796\n",
      "train loss:0.002930504383787189\n",
      "train loss:0.0005266034206847471\n",
      "train loss:0.000294231828137833\n",
      "train loss:0.0006170544873130085\n",
      "train loss:0.0012226421858282156\n",
      "train loss:0.0005098123271965683\n",
      "train loss:0.00025087240787972464\n",
      "train loss:0.0014077229398785538\n",
      "train loss:0.00036403809831742263\n",
      "train loss:0.0002629115820248459\n",
      "train loss:0.00044533999083063336\n",
      "train loss:0.00020519773580135177\n",
      "train loss:0.00018401924947435578\n",
      "train loss:0.001666950347126938\n",
      "train loss:0.0002801454465230406\n",
      "train loss:0.0002528224677933863\n",
      "train loss:0.0008443231147834992\n",
      "train loss:0.0002491693829955358\n",
      "train loss:0.0021458817574641883\n",
      "train loss:0.0004399845366682038\n",
      "train loss:0.0008936077196269099\n",
      "train loss:0.00017192583148105723\n",
      "train loss:3.086605276175601e-05\n",
      "train loss:0.0015087619447890824\n",
      "train loss:0.005214331107126653\n",
      "train loss:0.0002855612307988757\n",
      "train loss:0.0009109169515291405\n",
      "train loss:0.0005962624899022158\n",
      "train loss:0.0001221997528852324\n",
      "train loss:0.0013206133081561837\n",
      "train loss:0.0001526885628804569\n",
      "train loss:0.001841719178608881\n",
      "train loss:7.38365420213419e-05\n",
      "train loss:0.0019536957986356004\n",
      "train loss:0.02485224769187086\n",
      "train loss:0.002937047259936642\n",
      "train loss:0.00118028384005621\n",
      "train loss:0.00028076919902218935\n",
      "train loss:0.0003240562931321786\n",
      "train loss:0.0011048978722531606\n",
      "train loss:0.00013650480670362542\n",
      "train loss:0.0005135487469125518\n",
      "train loss:0.000753945279017847\n",
      "train loss:0.002273505172385987\n",
      "train loss:0.002237062552832113\n",
      "train loss:0.0009329340137592504\n",
      "train loss:0.002662073324069076\n",
      "train loss:0.00034849831999502254\n",
      "train loss:0.00022176352103059745\n",
      "train loss:0.0021475795136274415\n",
      "train loss:0.0013932914935539068\n",
      "train loss:5.330274578816304e-05\n",
      "train loss:0.0005914506217649253\n",
      "train loss:0.002297465192746883\n",
      "train loss:0.005376393938185624\n",
      "train loss:4.5572299078530194e-05\n",
      "train loss:0.0011510269467694025\n",
      "train loss:6.834986534471154e-05\n",
      "train loss:0.008453001441596915\n",
      "train loss:3.841653620729924e-05\n",
      "train loss:0.00042637531154010415\n",
      "train loss:0.003771386990480874\n",
      "train loss:0.0012985202302191743\n",
      "train loss:0.0019458717311992707\n",
      "train loss:0.0025797983482804014\n",
      "train loss:0.0022501785714108204\n",
      "train loss:0.0009005553611088282\n",
      "train loss:0.0005026868637586939\n",
      "train loss:0.0031289840906783433\n",
      "train loss:0.0007354122755797958\n",
      "train loss:0.0001700073408789971\n",
      "train loss:0.0021644727359793536\n",
      "train loss:0.08232718050598545\n",
      "train loss:0.00191131256095456\n",
      "train loss:0.0006532118202646344\n",
      "train loss:0.0006953906766262878\n",
      "train loss:0.00040194027141486453\n",
      "train loss:0.0008079395158302354\n",
      "train loss:0.00047938649712733885\n",
      "train loss:0.003404204879731153\n",
      "train loss:0.0021741818588609414\n",
      "train loss:0.002815320854077373\n",
      "train loss:0.00018237044738302733\n",
      "train loss:0.00014752846078914627\n",
      "train loss:0.0017944097719203719\n",
      "train loss:0.0006973138746028597\n",
      "train loss:0.0028094846716042853\n",
      "train loss:0.00025564108160685254\n",
      "train loss:0.0017507914274986311\n",
      "train loss:0.00022469800745234878\n",
      "train loss:0.0011750605579020062\n",
      "train loss:0.013648310499579328\n",
      "train loss:0.000535495223127833\n",
      "train loss:0.001035985508935496\n",
      "train loss:0.00034797774804869066\n",
      "train loss:0.00123789221784555\n",
      "train loss:0.003648304127778121\n",
      "train loss:0.000655383822042003\n",
      "train loss:0.00023235674444524606\n",
      "train loss:0.0015914137121352343\n",
      "train loss:4.95946390806549e-06\n",
      "train loss:0.00010859339351142326\n",
      "train loss:0.00012151170652395926\n",
      "train loss:0.00042531299748785426\n",
      "train loss:0.0004101104388574849\n",
      "train loss:0.00037457439402198694\n",
      "train loss:0.0037952822801816206\n",
      "train loss:0.0003519345470803405\n",
      "train loss:0.0005714442796299766\n",
      "train loss:0.0028691010636901332\n",
      "train loss:0.0025704710649129096\n",
      "train loss:0.0004651047148479795\n",
      "train loss:0.0016270344271464047\n",
      "train loss:0.0002653811222513146\n",
      "train loss:0.0008511193174735401\n",
      "train loss:0.000982351179587301\n",
      "train loss:0.00100636236435836\n",
      "train loss:0.004604850558562517\n",
      "train loss:0.0012681064267703757\n",
      "train loss:0.0017673599519563968\n",
      "train loss:0.0005413063299886223\n",
      "train loss:0.0009677375856202866\n",
      "train loss:0.0005815869022117573\n",
      "train loss:0.003718516614829\n",
      "train loss:0.0007433374995937594\n",
      "train loss:0.0001744197299162767\n",
      "train loss:0.00586447078606658\n",
      "train loss:0.0003069287366153756\n",
      "train loss:0.0011701539460638047\n",
      "train loss:0.001966931489185189\n",
      "train loss:0.0008040930337963365\n",
      "train loss:0.00137622596847537\n",
      "train loss:0.0008610235502105835\n",
      "train loss:0.0020487170671431468\n",
      "train loss:0.0013850867142412107\n",
      "train loss:0.00013107327960845146\n",
      "train loss:0.0017913289483177809\n",
      "train loss:0.00010212881384698942\n",
      "train loss:0.0002223495847021539\n",
      "train loss:0.001848098113033828\n",
      "train loss:0.00027522087180789265\n",
      "train loss:0.00022500881085554133\n",
      "train loss:0.0018888295553559193\n",
      "train loss:0.0017382385852613492\n",
      "train loss:0.0021248188346651557\n",
      "train loss:0.0002862439599892987\n",
      "train loss:0.00013763183603229587\n",
      "train loss:0.0011009899047398199\n",
      "train loss:0.0003233997499920021\n",
      "train loss:0.0002635355065092314\n",
      "train loss:0.000749336365888823\n",
      "train loss:0.0005413811177354319\n",
      "train loss:0.003185841663552064\n",
      "train loss:0.0005542198403359825\n",
      "train loss:0.002638538757972943\n",
      "train loss:0.0001332744553171483\n",
      "train loss:0.002754058546782673\n",
      "train loss:0.000479466513235288\n",
      "train loss:0.008700990807951127\n",
      "train loss:0.00023398732584063419\n",
      "train loss:0.00044545697120318547\n",
      "train loss:0.0013283069852987523\n",
      "train loss:0.0008816840385409593\n",
      "train loss:0.0017089549026307691\n",
      "train loss:0.0029937812543758104\n",
      "train loss:0.0032024333977929355\n",
      "train loss:0.00013235698927040881\n",
      "train loss:0.0021325950365679736\n",
      "train loss:0.0012386012103772403\n",
      "train loss:0.0002125394322532971\n",
      "train loss:0.0013446121825311367\n",
      "train loss:0.009047457598340016\n",
      "train loss:0.0019961930879028216\n",
      "train loss:0.019695749501937174\n",
      "train loss:0.00037607995705836493\n",
      "train loss:0.00016647069554224362\n",
      "train loss:0.00015727872852554147\n",
      "train loss:0.003978526554236087\n",
      "train loss:3.8239381540043094e-05\n",
      "train loss:0.0005811952862586509\n",
      "train loss:0.017659715030397455\n",
      "train loss:0.005307704022843172\n",
      "train loss:0.0004757333526119215\n",
      "train loss:0.017772552577727484\n",
      "train loss:0.0008907481400041653\n",
      "train loss:0.00011800228518296375\n",
      "train loss:0.0003327096631643424\n",
      "train loss:0.0011743655828022775\n",
      "train loss:0.0015241747897019333\n",
      "train loss:0.0002226763435890275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000447278359602528\n",
      "train loss:0.00043741080004509165\n",
      "train loss:0.01384654360183857\n",
      "train loss:0.0003016303919025948\n",
      "train loss:0.0012277351491609247\n",
      "train loss:0.00019014412806783273\n",
      "train loss:0.0033603710238581308\n",
      "train loss:0.0009809197178562703\n",
      "train loss:0.000566116381214907\n",
      "train loss:0.00027939659399284184\n",
      "train loss:0.00033881083472587543\n",
      "train loss:0.0001283174437848632\n",
      "train loss:0.004445838025162807\n",
      "train loss:0.0010421933513349527\n",
      "train loss:0.004506869681067204\n",
      "train loss:0.002098656488482896\n",
      "train loss:0.0006195420279011667\n",
      "train loss:0.00044839913036932925\n",
      "train loss:0.000851703036205238\n",
      "train loss:0.0013771121650484274\n",
      "train loss:0.0010625139455257796\n",
      "train loss:0.0006980611155192656\n",
      "train loss:0.007681097496662815\n",
      "train loss:0.002445840546076778\n",
      "train loss:0.001731848684951648\n",
      "train loss:0.0001039028152518936\n",
      "train loss:0.009348297419396957\n",
      "train loss:0.000672273475195467\n",
      "train loss:0.0011996720626346919\n",
      "train loss:0.0012941991303664386\n",
      "train loss:0.0041217205144611635\n",
      "train loss:0.002570439394188218\n",
      "train loss:0.0012669466243508956\n",
      "train loss:0.0012831220621684633\n",
      "train loss:0.0010418312770015543\n",
      "train loss:0.0004607567864893213\n",
      "train loss:0.00018744225800818682\n",
      "train loss:0.004076091356939772\n",
      "train loss:0.0005210451675121695\n",
      "train loss:0.0027336611614859913\n",
      "train loss:0.00011271885357856905\n",
      "train loss:0.0006037496323543815\n",
      "train loss:0.0024050333512201194\n",
      "train loss:0.0002393333002162371\n",
      "train loss:0.0008199642769135555\n",
      "train loss:0.0004138521774940348\n",
      "train loss:0.0002653270093710983\n",
      "train loss:0.007721617736226226\n",
      "train loss:0.00025416357387242274\n",
      "train loss:0.0004259755461313203\n",
      "train loss:0.00584115259694008\n",
      "train loss:0.00043139678999356364\n",
      "train loss:0.000575946695422668\n",
      "train loss:0.0007862842764002742\n",
      "train loss:0.0016205363396759878\n",
      "train loss:0.00037611365787248204\n",
      "train loss:0.0005279806923331879\n",
      "train loss:0.0006175267021783693\n",
      "train loss:0.00014775512686972838\n",
      "train loss:9.095028445408706e-05\n",
      "train loss:5.9763231862925713e-05\n",
      "train loss:0.00020269829831525834\n",
      "train loss:0.0019464563140021165\n",
      "train loss:0.000824550943734816\n",
      "train loss:0.0007238131163958908\n",
      "train loss:0.000972492147422081\n",
      "train loss:0.00014426373274928616\n",
      "train loss:8.331308304707117e-05\n",
      "train loss:0.004245271939990662\n",
      "train loss:0.0010093445062987311\n",
      "train loss:0.0005381984070423665\n",
      "train loss:0.0046279720689942115\n",
      "train loss:0.00021903482842691832\n",
      "train loss:0.0017557775557858\n",
      "train loss:0.0008020509625299105\n",
      "train loss:0.00030039931606123905\n",
      "train loss:5.251156579313061e-05\n",
      "train loss:6.312616305408344e-05\n",
      "train loss:0.0023397701982380893\n",
      "train loss:0.0029778215298604943\n",
      "train loss:0.002246901616234604\n",
      "train loss:0.004425465107085589\n",
      "train loss:0.003078655059901913\n",
      "train loss:0.053944688858888236\n",
      "train loss:0.00807025472921085\n",
      "train loss:0.0017528639636208128\n",
      "train loss:0.0025273550864116645\n",
      "train loss:0.00654624774531563\n",
      "train loss:0.0002474591938037079\n",
      "train loss:0.00543889046688077\n",
      "train loss:0.00044358510907897814\n",
      "train loss:0.0024602645643551305\n",
      "train loss:0.00408679061853799\n",
      "train loss:0.005543204580576513\n",
      "train loss:0.0005424159457461424\n",
      "train loss:0.0015272348416915792\n",
      "train loss:0.0017209914657376158\n",
      "train loss:0.011587497208777421\n",
      "train loss:0.0006516027471920004\n",
      "train loss:0.0004539115015787744\n",
      "train loss:0.0015065514724105522\n",
      "train loss:0.0018272553614857928\n",
      "train loss:0.0019795442272657975\n",
      "train loss:0.0012668914557492595\n",
      "train loss:0.004028043290653186\n",
      "train loss:0.009716713878485142\n",
      "train loss:0.0015659684341171245\n",
      "train loss:0.0031618725459728807\n",
      "train loss:0.0007933991262946297\n",
      "train loss:0.0018781576089037593\n",
      "train loss:0.00036173292999523715\n",
      "train loss:0.0015854642021706196\n",
      "train loss:0.0063273513173067505\n",
      "train loss:7.90447196033264e-05\n",
      "train loss:0.0026562445335529716\n",
      "train loss:0.00016275713966243686\n",
      "train loss:0.0008387295463280027\n",
      "train loss:0.004494756490873418\n",
      "train loss:0.020134073700228572\n",
      "train loss:0.0002361849160442988\n",
      "train loss:0.0013457538211615518\n",
      "train loss:0.0002293661423221105\n",
      "train loss:0.002000658711339167\n",
      "train loss:0.0010028013884744217\n",
      "train loss:5.519783499501557e-05\n",
      "train loss:0.0009681399456802035\n",
      "train loss:0.0020096332303379625\n",
      "train loss:0.0012983856833866103\n",
      "train loss:0.0009339061130838412\n",
      "train loss:0.0008035556826837935\n",
      "train loss:0.0010083105260057384\n",
      "train loss:0.002737357551865529\n",
      "train loss:0.00039746467526054273\n",
      "train loss:0.00044698436053584536\n",
      "train loss:0.000720083952380396\n",
      "train loss:0.008094589287739344\n",
      "train loss:0.0022553498019155997\n",
      "train loss:0.0031669346107012194\n",
      "train loss:0.005348667852334109\n",
      "train loss:0.0006087450858954204\n",
      "train loss:0.0013260187012380947\n",
      "train loss:0.004715735786637076\n",
      "train loss:0.0011405254774723885\n",
      "train loss:0.0002742579572523407\n",
      "train loss:0.0005789554689016105\n",
      "train loss:0.0018296808731626455\n",
      "train loss:0.0030195692030172204\n",
      "train loss:0.00024735205375567905\n",
      "train loss:0.00012522251592521298\n",
      "train loss:0.00014928225154111613\n",
      "train loss:0.001546160258514513\n",
      "train loss:0.020229616786743274\n",
      "train loss:0.002510066632498025\n",
      "train loss:0.0008950744068224429\n",
      "train loss:0.0011704605359802239\n",
      "train loss:0.0021759669015539275\n",
      "train loss:0.0014545201129566251\n",
      "train loss:0.0006551015616707933\n",
      "train loss:0.0025705891380058167\n",
      "train loss:0.002856256020702348\n",
      "train loss:0.001802455099301504\n",
      "train loss:0.006401959377686491\n",
      "train loss:0.0006821110950675309\n",
      "train loss:0.0028609635634185794\n",
      "train loss:0.0012490445208403218\n",
      "train loss:0.00021298696704826235\n",
      "train loss:0.000536521457481431\n",
      "train loss:0.00022730289612810293\n",
      "train loss:0.0012374590237269505\n",
      "train loss:0.005954210739927535\n",
      "train loss:0.0030533938353713872\n",
      "train loss:0.003272104561292688\n",
      "train loss:0.0010840799652801923\n",
      "train loss:0.0007338689589256504\n",
      "train loss:0.0019403521055802375\n",
      "train loss:0.00014382784397932189\n",
      "train loss:0.0005170079368277157\n",
      "train loss:8.627199786429942e-05\n",
      "train loss:0.002026731495125075\n",
      "train loss:0.0009579930836424624\n",
      "train loss:0.0007302212927874774\n",
      "train loss:0.003429374360639984\n",
      "train loss:0.0017482836424322753\n",
      "train loss:0.0013281686755035086\n",
      "train loss:0.0006521162101681425\n",
      "train loss:0.0006070976252434306\n",
      "train loss:0.0007658724871517739\n",
      "train loss:5.793856011811199e-05\n",
      "train loss:0.001253095677352545\n",
      "train loss:5.363649584398607e-05\n",
      "=== epoch:18, train acc:0.997, test acc:0.983 ===\n",
      "train loss:0.00027378808419395163\n",
      "train loss:0.016311246941093795\n",
      "train loss:0.0032043144792949334\n",
      "train loss:4.9353329476946065e-05\n",
      "train loss:0.0002834544265997264\n",
      "train loss:0.00014243551061117186\n",
      "train loss:0.0011984810362581032\n",
      "train loss:0.002264845701962986\n",
      "train loss:0.0014753125849603815\n",
      "train loss:0.0020453335337492144\n",
      "train loss:0.00619596228822959\n",
      "train loss:0.0016740952760172841\n",
      "train loss:0.0002192672025179747\n",
      "train loss:0.00149224148354729\n",
      "train loss:0.001567217453722467\n",
      "train loss:0.0035216835047341497\n",
      "train loss:0.0006505516801844314\n",
      "train loss:0.0011504420876511721\n",
      "train loss:0.0020097288250260905\n",
      "train loss:0.0010962398893083645\n",
      "train loss:0.0008698997850093415\n",
      "train loss:0.005638340414861255\n",
      "train loss:0.00217781961437394\n",
      "train loss:0.006508581517482641\n",
      "train loss:0.0014905035864638222\n",
      "train loss:0.004209977132272144\n",
      "train loss:0.001548887783989271\n",
      "train loss:0.00024046939192916124\n",
      "train loss:0.0002502540297314324\n",
      "train loss:0.00198360994941984\n",
      "train loss:0.0002422619452447761\n",
      "train loss:0.0018268925722077789\n",
      "train loss:0.002202077339534114\n",
      "train loss:0.00037440054156180033\n",
      "train loss:0.00018540753153234088\n",
      "train loss:0.00013998766329502137\n",
      "train loss:0.0017502261118398327\n",
      "train loss:0.0029185342337796627\n",
      "train loss:0.0014022759001959717\n",
      "train loss:0.012083413301674322\n",
      "train loss:0.0005936171411678829\n",
      "train loss:0.003445491738024898\n",
      "train loss:0.0009584339319233902\n",
      "train loss:0.0015082009491589176\n",
      "train loss:0.004454332324489523\n",
      "train loss:0.004343712170000843\n",
      "train loss:0.0005241588913761835\n",
      "train loss:0.00576252000560936\n",
      "train loss:0.0001736235945595468\n",
      "train loss:0.002609130025371619\n",
      "train loss:0.007314843227800259\n",
      "train loss:0.0018592404573878252\n",
      "train loss:0.0008230445485296611\n",
      "train loss:0.012406876145843532\n",
      "train loss:0.0021919772496160404\n",
      "train loss:0.0003807466063677905\n",
      "train loss:0.0006779699841023786\n",
      "train loss:0.0004303996616489938\n",
      "train loss:0.0006977460826765015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00047055078965857646\n",
      "train loss:0.0001634351094302091\n",
      "train loss:0.004643968664556582\n",
      "train loss:0.0005818459790368713\n",
      "train loss:0.0013012834451356357\n",
      "train loss:0.0012746601423448234\n",
      "train loss:0.0033411009984704297\n",
      "train loss:0.0022927194109901173\n",
      "train loss:0.0037611205832764998\n",
      "train loss:0.0006165433833484492\n",
      "train loss:0.005267398233702251\n",
      "train loss:0.0004612840363052545\n",
      "train loss:0.003614899450312407\n",
      "train loss:0.007708028652642002\n",
      "train loss:0.006190626523055965\n",
      "train loss:0.0034833223058997474\n",
      "train loss:0.0014085423855832598\n",
      "train loss:0.03703091564149962\n",
      "train loss:0.0025185183342001493\n",
      "train loss:0.0006589728559610532\n",
      "train loss:0.0009602383538075092\n",
      "train loss:0.0026559567580053873\n",
      "train loss:0.0005536952480029726\n",
      "train loss:0.0013736953282211118\n",
      "train loss:0.004080205602159856\n",
      "train loss:0.00011996777598933705\n",
      "train loss:0.0012360052421078473\n",
      "train loss:0.0006442845868150661\n",
      "train loss:0.0023366900817832045\n",
      "train loss:0.0017676046879281627\n",
      "train loss:0.001014577131405868\n",
      "train loss:0.0004648915396101675\n",
      "train loss:0.0017358573742040013\n",
      "train loss:0.027282639127240448\n",
      "train loss:0.03496074149243832\n",
      "train loss:0.009217001562423414\n",
      "train loss:0.0024326352001981964\n",
      "train loss:0.006658822760225174\n",
      "train loss:0.0008799709926007925\n",
      "train loss:0.00397747463432943\n",
      "train loss:0.0002654524006580853\n",
      "train loss:0.00037568873516632235\n",
      "train loss:0.002696832170694351\n",
      "train loss:0.005696528736809299\n",
      "train loss:0.00594868514689555\n",
      "train loss:0.0026946220389568844\n",
      "train loss:0.002652763496248248\n",
      "train loss:0.00384449411666641\n",
      "train loss:0.0004429418205456002\n",
      "train loss:0.0020690655356455103\n",
      "train loss:0.0002632556040482027\n",
      "train loss:0.0009635892279798379\n",
      "train loss:0.006057968864917532\n",
      "train loss:9.043982855215456e-05\n",
      "train loss:0.0024537475659993225\n",
      "train loss:0.000876404862393379\n",
      "train loss:0.00017945592957220016\n",
      "train loss:0.00012563884947217407\n",
      "train loss:0.0007544956560111674\n",
      "train loss:0.0006179882599673115\n",
      "train loss:0.0005898252553636088\n",
      "train loss:0.0018001910218262713\n",
      "train loss:0.00037376573228334006\n",
      "train loss:0.0005614383207622351\n",
      "train loss:0.0001782306749530246\n",
      "train loss:0.0005174070342150166\n",
      "train loss:0.0011921428059221077\n",
      "train loss:0.0002947420973520935\n",
      "train loss:0.0012538291324887935\n",
      "train loss:0.00029230674515453756\n",
      "train loss:0.002079564459236119\n",
      "train loss:0.004159145193649132\n",
      "train loss:2.1743138220048185e-05\n",
      "train loss:0.00015711082042080607\n",
      "train loss:0.0004237100701425895\n",
      "train loss:0.0006303267868613316\n",
      "train loss:0.0005647962400722403\n",
      "train loss:0.03278140203198301\n",
      "train loss:0.00012204664568406416\n",
      "train loss:0.000468364570909323\n",
      "train loss:0.0005508966368036192\n",
      "train loss:0.0017950675256930126\n",
      "train loss:0.000425782243766569\n",
      "train loss:0.00010339121157328282\n",
      "train loss:0.0003449681844656031\n",
      "train loss:0.0013130044624297297\n",
      "train loss:0.001673386529570977\n",
      "train loss:0.0015468692332834153\n",
      "train loss:0.0008698560934096563\n",
      "train loss:0.0023747087917703534\n",
      "train loss:0.005135921331601494\n",
      "train loss:0.0012417239086370399\n",
      "train loss:0.0008843742238069515\n",
      "train loss:0.0003146994916178073\n",
      "train loss:0.00392694284978531\n",
      "train loss:0.0013019151979236467\n",
      "train loss:0.001779392293103939\n",
      "train loss:0.0003325801733184875\n",
      "train loss:0.002094839213534169\n",
      "train loss:0.0004089745122433357\n",
      "train loss:0.00021196714556044531\n",
      "train loss:0.0014049074640277435\n",
      "train loss:0.000327310855754426\n",
      "train loss:0.002686033537228613\n",
      "train loss:0.0010515859971948786\n",
      "train loss:0.0014478815794862182\n",
      "train loss:0.0003878239735148728\n",
      "train loss:0.00016876171746976125\n",
      "train loss:0.0023842319524856022\n",
      "train loss:0.0001465608937423096\n",
      "train loss:0.00019115007738726867\n",
      "train loss:0.0003810408565920215\n",
      "train loss:3.565822040499343e-05\n",
      "train loss:0.0028784809294115452\n",
      "train loss:0.0007285512872527511\n",
      "train loss:0.00036508534250725267\n",
      "train loss:0.0007534938370129773\n",
      "train loss:0.0027026751198110936\n",
      "train loss:0.00028258202125395945\n",
      "train loss:0.0014084051424316033\n",
      "train loss:0.0015904211761444713\n",
      "train loss:0.001677404917357833\n",
      "train loss:3.4600588436134347e-05\n",
      "train loss:0.0028604149449547255\n",
      "train loss:0.00046802656333370935\n",
      "train loss:0.00042338771279125484\n",
      "train loss:0.002221095026405602\n",
      "train loss:0.001783089458202452\n",
      "train loss:0.0013716667963791366\n",
      "train loss:0.0004606490464507819\n",
      "train loss:0.004616116952962701\n",
      "train loss:0.0006922620124567791\n",
      "train loss:0.0010934352546708105\n",
      "train loss:0.0033370193579023277\n",
      "train loss:0.0008945019853850643\n",
      "train loss:0.001738554971815409\n",
      "train loss:0.00013428409009152558\n",
      "train loss:0.0009171032624695346\n",
      "train loss:0.00011877016897820886\n",
      "train loss:0.001686585075165095\n",
      "train loss:2.6068590232156385e-05\n",
      "train loss:0.00010072175667562166\n",
      "train loss:0.0013159954082714326\n",
      "train loss:0.004012097487650429\n",
      "train loss:0.0008697851250058715\n",
      "train loss:0.0033095866000418133\n",
      "train loss:0.0008442668215289006\n",
      "train loss:0.0007292714759132824\n",
      "train loss:0.0030430134261159336\n",
      "train loss:0.0002721302743217602\n",
      "train loss:0.00424608877618418\n",
      "train loss:0.0014282669638851092\n",
      "train loss:0.0006117216755702179\n",
      "train loss:0.0013295794153120731\n",
      "train loss:0.00038128554782820205\n",
      "train loss:0.0014238820315666109\n",
      "train loss:0.0013563067880588337\n",
      "train loss:0.00137518141523992\n",
      "train loss:0.005070333931866805\n",
      "train loss:0.0010560419479515141\n",
      "train loss:0.018985340926076535\n",
      "train loss:0.0008478309792857911\n",
      "train loss:0.0005832607557861437\n",
      "train loss:0.0005731627757404661\n",
      "train loss:0.0023992170092582287\n",
      "train loss:0.0016207098333755484\n",
      "train loss:0.0007616510405106288\n",
      "train loss:0.000437595328398905\n",
      "train loss:0.00881457656550181\n",
      "train loss:0.00447994351520283\n",
      "train loss:0.00030596116802810027\n",
      "train loss:0.000615848861475253\n",
      "train loss:0.0018838117984304134\n",
      "train loss:0.00015987600372430725\n",
      "train loss:0.000844031331337627\n",
      "train loss:0.0010917788685352692\n",
      "train loss:0.022117810357751386\n",
      "train loss:0.0010648806205850207\n",
      "train loss:0.0008341247288263302\n",
      "train loss:0.029754904662711135\n",
      "train loss:0.005288996974226391\n",
      "train loss:0.0034272346586948473\n",
      "train loss:0.0011265130504166038\n",
      "train loss:0.0003741671875326745\n",
      "train loss:0.00028284775264362177\n",
      "train loss:0.001657181272676718\n",
      "train loss:0.0022263315077921983\n",
      "train loss:0.0030002762183454056\n",
      "train loss:0.001154183704230399\n",
      "train loss:0.0002866449550421107\n",
      "train loss:0.0008691519717953034\n",
      "train loss:0.0005209472913018057\n",
      "train loss:0.00858357169343851\n",
      "train loss:0.003931105374241236\n",
      "train loss:8.752996092136931e-05\n",
      "train loss:0.0007935739434699712\n",
      "train loss:0.0035446470684694443\n",
      "train loss:0.005996126762764642\n",
      "train loss:0.02200924820393917\n",
      "train loss:0.00034571154159121806\n",
      "train loss:0.001002050968273413\n",
      "train loss:0.0032823047333484247\n",
      "train loss:0.002225550920860592\n",
      "train loss:0.003886003191355585\n",
      "train loss:0.0038527434293606265\n",
      "train loss:0.005072021174929037\n",
      "train loss:0.002513750830468741\n",
      "train loss:8.174017801708875e-05\n",
      "train loss:0.006272161496853138\n",
      "train loss:3.7553000688745235e-05\n",
      "train loss:0.0002560786094904318\n",
      "train loss:0.004765984451235449\n",
      "train loss:0.013622714179264174\n",
      "train loss:0.005718690032967559\n",
      "train loss:0.00025176663354741245\n",
      "train loss:0.007368808265813662\n",
      "train loss:0.0030480537395391645\n",
      "train loss:0.0002969690750647265\n",
      "train loss:0.0009078933234265834\n",
      "train loss:0.000611209463074054\n",
      "train loss:0.0004141334856177371\n",
      "train loss:0.001423735189455275\n",
      "train loss:0.0027521027370374217\n",
      "train loss:0.00043727117382416983\n",
      "train loss:0.003456069619721938\n",
      "train loss:0.04806200694054575\n",
      "train loss:0.010072656438086185\n",
      "train loss:0.0034187555433633473\n",
      "train loss:3.452293317278155e-05\n",
      "train loss:0.0003036030959605101\n",
      "train loss:0.0017487934320997104\n",
      "train loss:0.00029945262908393123\n",
      "train loss:7.406832018826671e-05\n",
      "train loss:0.00010444803906124626\n",
      "train loss:0.0003692710808527873\n",
      "train loss:0.002237647388578465\n",
      "train loss:0.01268530420251878\n",
      "train loss:8.864773637860349e-05\n",
      "train loss:0.0006858985213505911\n",
      "train loss:0.0007447206041201727\n",
      "train loss:0.0054451551884053765\n",
      "train loss:0.0001534344736224463\n",
      "train loss:0.00038312753759716316\n",
      "train loss:0.000667426232593802\n",
      "train loss:0.0073384514851421445\n",
      "train loss:0.000261598595084475\n",
      "train loss:0.0006485434109154187\n",
      "train loss:0.0012523680408831597\n",
      "train loss:0.0020425991265801877\n",
      "train loss:0.0004951861584471276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0013487643426000609\n",
      "train loss:0.008141586317049823\n",
      "train loss:0.002357685666159236\n",
      "train loss:0.0007806871265196529\n",
      "train loss:0.0020236531057160746\n",
      "train loss:0.0010239227949985\n",
      "train loss:0.0005567161877866315\n",
      "train loss:0.0026664311235321475\n",
      "train loss:0.0004709244872158494\n",
      "train loss:0.0014492300705986208\n",
      "train loss:0.027175579787727572\n",
      "train loss:0.0004866521961122505\n",
      "train loss:0.0002544905870189927\n",
      "train loss:0.0002953276471506931\n",
      "train loss:0.00048366207356109276\n",
      "train loss:0.0009758344354533988\n",
      "train loss:6.598019845776978e-05\n",
      "train loss:0.01409703452640822\n",
      "train loss:0.001579113054664371\n",
      "train loss:0.029061975757291556\n",
      "train loss:0.004647351108104006\n",
      "train loss:0.0032110001773516072\n",
      "train loss:0.003927260252648465\n",
      "train loss:0.0011228851001050452\n",
      "train loss:0.0008261480714936541\n",
      "train loss:0.005569917323257637\n",
      "train loss:0.0026002959874149275\n",
      "train loss:0.0008549653851676205\n",
      "train loss:0.0013119756263335848\n",
      "train loss:0.011874430514990465\n",
      "train loss:0.0007707845284080684\n",
      "train loss:0.005819646494381579\n",
      "train loss:0.002409219599713681\n",
      "train loss:0.00037549601232477777\n",
      "train loss:0.00842291573355737\n",
      "train loss:0.005502378946146326\n",
      "train loss:0.0021110844857384144\n",
      "train loss:0.00042804941905153957\n",
      "train loss:0.01171009404669747\n",
      "train loss:0.0022052838335644316\n",
      "train loss:0.0004934597414576376\n",
      "train loss:0.0005662792799412971\n",
      "train loss:0.0050386429224878885\n",
      "train loss:0.0014914819286894494\n",
      "train loss:0.0031701076866202426\n",
      "train loss:0.000905128226710065\n",
      "train loss:0.0014892757867333046\n",
      "train loss:0.00023791436340705018\n",
      "train loss:0.00102410022741647\n",
      "train loss:0.00350031166030084\n",
      "train loss:0.00019738787855262153\n",
      "train loss:0.0006390070228488473\n",
      "train loss:0.002315557650568152\n",
      "train loss:0.0001016157579676088\n",
      "train loss:0.0032480786178897087\n",
      "train loss:0.00013134862079757414\n",
      "train loss:0.003198655928638427\n",
      "train loss:0.0006360415263914005\n",
      "train loss:0.0002622382042251757\n",
      "train loss:0.005296517649070077\n",
      "train loss:0.0010509543712890418\n",
      "train loss:0.003234581433111578\n",
      "train loss:0.002880317543432007\n",
      "train loss:0.0014563159137016715\n",
      "train loss:0.003157548752012266\n",
      "train loss:0.00044322060545188435\n",
      "train loss:0.0023183497877112924\n",
      "train loss:0.00043773831234338257\n",
      "train loss:8.4364764184428e-05\n",
      "train loss:0.00022880692919547647\n",
      "train loss:0.0030947827361365167\n",
      "train loss:0.0004615488322051444\n",
      "train loss:0.001232083666400929\n",
      "train loss:0.00024853676204621654\n",
      "train loss:0.0013514000079716485\n",
      "train loss:0.00020915166938782333\n",
      "train loss:0.00013291372633214007\n",
      "train loss:0.000742850483618649\n",
      "train loss:0.0030539362740238823\n",
      "train loss:0.003181774367188629\n",
      "train loss:0.0007952833630642158\n",
      "train loss:0.0008279508407413572\n",
      "train loss:0.0008566538694984427\n",
      "train loss:9.4041835743554e-05\n",
      "train loss:0.002027555911625939\n",
      "train loss:0.0008202939278967095\n",
      "train loss:0.0003175995694270273\n",
      "train loss:0.0001967722404296744\n",
      "train loss:0.005925305118437863\n",
      "train loss:0.0015777657468113257\n",
      "train loss:4.914838411048041e-05\n",
      "train loss:0.002587392335687379\n",
      "train loss:0.0009522086471103102\n",
      "train loss:9.590939429483199e-05\n",
      "train loss:0.00018221725080675246\n",
      "train loss:0.0002972747645721548\n",
      "train loss:0.001481093474517116\n",
      "train loss:0.00026832533589925435\n",
      "train loss:0.002809370129589125\n",
      "train loss:0.0003032529619607783\n",
      "train loss:0.0015457520849583494\n",
      "train loss:0.002451773997727221\n",
      "train loss:0.001977044379171792\n",
      "train loss:0.0004855125376326767\n",
      "train loss:0.007529642221171814\n",
      "train loss:0.0022420676117867566\n",
      "train loss:0.0013824036643094494\n",
      "train loss:0.004967169600161257\n",
      "train loss:0.0006561374833842572\n",
      "train loss:0.000970826914490913\n",
      "train loss:0.00031053419356463985\n",
      "train loss:7.341269421339296e-05\n",
      "train loss:0.0010141209877655606\n",
      "train loss:0.001409661632454088\n",
      "train loss:0.0012488714202074397\n",
      "train loss:0.0005956858004115079\n",
      "train loss:8.046364806122098e-05\n",
      "train loss:0.0004381989427602584\n",
      "train loss:0.002547193972601895\n",
      "train loss:0.0015327130034207786\n",
      "train loss:0.00019000170997096933\n",
      "train loss:0.0003219840600740178\n",
      "train loss:6.162580748771747e-05\n",
      "train loss:0.018186603043336292\n",
      "train loss:0.0006215714850408903\n",
      "train loss:0.0006071810698512664\n",
      "train loss:0.0019133854437690567\n",
      "train loss:0.00552186198105781\n",
      "train loss:0.001041637312842765\n",
      "train loss:0.00030427512665843164\n",
      "train loss:0.001550964008852848\n",
      "train loss:0.003079632702260596\n",
      "train loss:0.0007384603058710752\n",
      "train loss:0.001367920262134007\n",
      "train loss:0.000605697081006897\n",
      "train loss:3.798414221536492e-05\n",
      "train loss:0.0035386567113082014\n",
      "train loss:0.0014986234232999013\n",
      "train loss:0.0006418225133563034\n",
      "train loss:0.0003988014033711345\n",
      "train loss:0.0003524553396325413\n",
      "train loss:0.003790790960854777\n",
      "train loss:0.0004213083388562275\n",
      "train loss:0.018233550337414396\n",
      "train loss:0.0031638928218607316\n",
      "train loss:0.0014610977264766878\n",
      "train loss:0.004608394454076818\n",
      "train loss:0.0031566398069416413\n",
      "train loss:0.0008690802348237271\n",
      "train loss:0.0011512418801696038\n",
      "train loss:0.00020364860793987887\n",
      "train loss:0.0012472218372540677\n",
      "train loss:0.003935862314366084\n",
      "train loss:0.0007530911178544731\n",
      "train loss:0.0008770729314331679\n",
      "train loss:0.0021683997266922304\n",
      "train loss:0.008789806319331706\n",
      "train loss:0.0013768912836120612\n",
      "train loss:0.0004587744861362156\n",
      "train loss:0.000458208445425199\n",
      "train loss:0.001753715813025968\n",
      "train loss:0.000688912632418253\n",
      "train loss:0.0077983498416749645\n",
      "train loss:0.00035329311331706013\n",
      "train loss:0.00019929861849309386\n",
      "train loss:0.00034452126114155974\n",
      "train loss:0.005156898483056322\n",
      "train loss:0.0028851894878054317\n",
      "train loss:0.005691152935794066\n",
      "train loss:0.00039785541894224994\n",
      "train loss:0.00016413395295593973\n",
      "train loss:0.00026894173502906417\n",
      "train loss:0.0026815254284192807\n",
      "train loss:0.0012949529370157825\n",
      "train loss:0.001594510799036851\n",
      "train loss:0.00034555624561960767\n",
      "train loss:0.002934516506511099\n",
      "train loss:0.00041266983971106517\n",
      "train loss:0.0019716456141495257\n",
      "train loss:0.0006236215296901545\n",
      "train loss:2.3944925134670873e-05\n",
      "train loss:0.0011200449988494577\n",
      "train loss:0.002384854165768707\n",
      "train loss:0.002378504089460279\n",
      "train loss:0.00021493838961553867\n",
      "train loss:0.0009516555227806509\n",
      "train loss:0.0002077508657661288\n",
      "train loss:0.0012110123719977362\n",
      "train loss:0.0018703976213653572\n",
      "train loss:0.0028552928763524933\n",
      "train loss:0.00040859652617198245\n",
      "train loss:0.009144984455840636\n",
      "train loss:0.0007966255010365657\n",
      "train loss:0.0005694118262515051\n",
      "train loss:0.0004043257813545284\n",
      "train loss:0.00013934171359638835\n",
      "train loss:0.006004444947779058\n",
      "train loss:0.00308051402633814\n",
      "train loss:0.0038946485347722587\n",
      "train loss:0.0012064256081239812\n",
      "train loss:0.0060532440078631174\n",
      "train loss:0.00036430122775437486\n",
      "train loss:0.000870451502237898\n",
      "train loss:0.00022726047787073592\n",
      "train loss:0.0019750440366444926\n",
      "train loss:0.0015354859059983558\n",
      "train loss:5.853166898686324e-05\n",
      "train loss:0.00017209074714695803\n",
      "train loss:0.0017542686112425403\n",
      "train loss:0.0006701946469516223\n",
      "train loss:0.00028329488611403725\n",
      "train loss:0.0005518284119518418\n",
      "train loss:0.00271382115442705\n",
      "train loss:5.048151525018342e-05\n",
      "train loss:4.2980762547253774e-05\n",
      "train loss:0.0030846094879228613\n",
      "train loss:0.0022142024578741828\n",
      "train loss:0.0005832590640943614\n",
      "train loss:0.0014747899103159609\n",
      "train loss:2.6259885938123167e-05\n",
      "train loss:0.002274643337946877\n",
      "train loss:0.00446268082124377\n",
      "train loss:0.00016449752720879406\n",
      "train loss:0.0007209649848481474\n",
      "train loss:0.002807735867776118\n",
      "train loss:5.378791393482887e-05\n",
      "train loss:0.002949465213428229\n",
      "train loss:0.0017058093421305931\n",
      "train loss:0.0008809817832784152\n",
      "train loss:0.004425342518193983\n",
      "train loss:0.002111760509947897\n",
      "train loss:0.008601013825701909\n",
      "train loss:0.0021994242028480406\n",
      "train loss:0.008194928012684224\n",
      "train loss:0.0003090129581065396\n",
      "train loss:0.005134844734756112\n",
      "train loss:0.0007627631281890335\n",
      "train loss:0.0010666487395094393\n",
      "train loss:0.002765237880985659\n",
      "train loss:0.001068885521350312\n",
      "train loss:0.0035313223236739743\n",
      "train loss:0.00014480072886578654\n",
      "train loss:0.001456517755277378\n",
      "train loss:0.0008663324425655927\n",
      "train loss:0.0034427204175955066\n",
      "train loss:0.0012400273034275603\n",
      "train loss:0.006735882580224114\n",
      "train loss:0.002980761879242402\n",
      "train loss:8.303858513987492e-05\n",
      "train loss:0.001290087202063024\n",
      "train loss:0.0021644519046193898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:9.290593343678362e-05\n",
      "train loss:0.000850751506212975\n",
      "train loss:0.0007327114124681251\n",
      "train loss:0.0006426203770688404\n",
      "train loss:0.0007500438084169999\n",
      "train loss:0.0013873843765074933\n",
      "train loss:0.0008490022533571309\n",
      "train loss:0.00028833615793313053\n",
      "train loss:0.00031138116434846415\n",
      "train loss:0.010424861546493745\n",
      "train loss:0.0003890616180716518\n",
      "train loss:0.0064952777544833185\n",
      "train loss:0.0006949467212361028\n",
      "train loss:0.0008132274277645495\n",
      "train loss:0.0010779791149332803\n",
      "train loss:0.00039963630177110353\n",
      "train loss:0.00027599454236587747\n",
      "train loss:0.0049225551565783635\n",
      "train loss:0.0019760467708558093\n",
      "train loss:0.00048480827340338976\n",
      "train loss:0.00022053843077608323\n",
      "train loss:0.0009795385017161778\n",
      "train loss:0.00042176785076839527\n",
      "train loss:0.00023268422577717523\n",
      "train loss:0.0002587883862999923\n",
      "train loss:0.0002514419861307775\n",
      "train loss:0.0023026220543607887\n",
      "train loss:0.00213693131437639\n",
      "train loss:0.0016018338336601474\n",
      "train loss:8.726735486089116e-05\n",
      "train loss:0.00042017154661051374\n",
      "train loss:0.0027311914437490132\n",
      "train loss:0.0002528771958569459\n",
      "train loss:0.0015106790079193642\n",
      "train loss:0.0011621670716799699\n",
      "train loss:6.3032142652610865e-06\n",
      "train loss:0.00444620618808919\n",
      "train loss:0.0008740508665984743\n",
      "train loss:0.00015412323422637903\n",
      "train loss:0.0021177678654735344\n",
      "=== epoch:19, train acc:0.996, test acc:0.99 ===\n",
      "train loss:0.00041141947735248507\n",
      "train loss:0.001659846177878676\n",
      "train loss:0.0010603626596812153\n",
      "train loss:0.0015276708100843252\n",
      "train loss:0.000548918102125345\n",
      "train loss:0.0012144955869714921\n",
      "train loss:0.00020365604311812008\n",
      "train loss:0.0034664851015888316\n",
      "train loss:0.0015858381543115935\n",
      "train loss:0.0008297959278496826\n",
      "train loss:0.0013189642899257797\n",
      "train loss:0.0032493122520271885\n",
      "train loss:0.0005023200186778882\n",
      "train loss:0.000560462311048994\n",
      "train loss:0.0005826359133505563\n",
      "train loss:0.0007488196473324429\n",
      "train loss:0.0015635406853817264\n",
      "train loss:0.015513272623076377\n",
      "train loss:0.00010347886284511194\n",
      "train loss:0.0009068046076669689\n",
      "train loss:0.0003792386877161675\n",
      "train loss:0.0002586924936005139\n",
      "train loss:0.002185237008567453\n",
      "train loss:0.00019024418028196061\n",
      "train loss:0.0006778191637343713\n",
      "train loss:0.00029267210022648353\n",
      "train loss:0.00388783975082673\n",
      "train loss:0.0018808700871634893\n",
      "train loss:0.002961980007760446\n",
      "train loss:0.001138667581037401\n",
      "train loss:0.0009696165154991632\n",
      "train loss:0.0007144373805723987\n",
      "train loss:0.0002849401650965903\n",
      "train loss:0.0006816493041454028\n",
      "train loss:0.0018407752017649207\n",
      "train loss:0.0004178020678208254\n",
      "train loss:0.0002577939878053362\n",
      "train loss:0.0005061945692621192\n",
      "train loss:0.000948453445197072\n",
      "train loss:0.00122890187853391\n",
      "train loss:0.00027460862160350535\n",
      "train loss:0.004925896287661637\n",
      "train loss:0.0008363300055069009\n",
      "train loss:9.392848878928623e-05\n",
      "train loss:0.0008181031732031949\n",
      "train loss:0.0011785910037015188\n",
      "train loss:4.607705333170684e-05\n",
      "train loss:2.148284754717625e-05\n",
      "train loss:0.0005471379485811972\n",
      "train loss:5.694182299700607e-05\n",
      "train loss:0.0033900401434006954\n",
      "train loss:0.0035124207483074616\n",
      "train loss:0.00019124462236598232\n",
      "train loss:0.002271737343121478\n",
      "train loss:0.0023771871923095465\n",
      "train loss:0.0006043217868377545\n",
      "train loss:0.0004992250711795211\n",
      "train loss:0.00034017247781359676\n",
      "train loss:0.0007977762160563644\n",
      "train loss:0.005586796739804446\n",
      "train loss:0.0008635420262474759\n",
      "train loss:0.0005264192085860378\n",
      "train loss:0.002015624647472091\n",
      "train loss:0.0004332160171241408\n",
      "train loss:0.0022759280070241603\n",
      "train loss:0.0011275028471425042\n",
      "train loss:0.0005284243403520328\n",
      "train loss:0.012608807168894166\n",
      "train loss:0.0009257975973620086\n",
      "train loss:0.0006034687725942658\n",
      "train loss:0.0005556179241755689\n",
      "train loss:0.0008470594665726974\n",
      "train loss:0.007920152967884942\n",
      "train loss:0.004438452213098989\n",
      "train loss:0.0014750119090734893\n",
      "train loss:0.0010013876992361415\n",
      "train loss:0.002298511013606319\n",
      "train loss:0.002550666422211955\n",
      "train loss:0.00011513928944568073\n",
      "train loss:0.0018439716325470176\n",
      "train loss:0.00034816378173512246\n",
      "train loss:0.0009666099135070221\n",
      "train loss:0.0004135349220406171\n",
      "train loss:0.002069334094925421\n",
      "train loss:0.001048926096002633\n",
      "train loss:0.0010413019607270477\n",
      "train loss:0.0004345762416056859\n",
      "train loss:0.00033066900782195604\n",
      "train loss:0.0028945195536136154\n",
      "train loss:0.00019128108339663537\n",
      "train loss:0.011167979060368207\n",
      "train loss:0.0006163390994694542\n",
      "train loss:0.0013660712670241254\n",
      "train loss:0.0029616112390399296\n",
      "train loss:0.0017684537606621816\n",
      "train loss:0.0018775835329276549\n",
      "train loss:0.00022464107532209246\n",
      "train loss:0.001481363059375006\n",
      "train loss:0.0010922963226978196\n",
      "train loss:8.160986411456149e-05\n",
      "train loss:0.0007074417851807275\n",
      "train loss:0.001392432398326445\n",
      "train loss:0.000594857435970993\n",
      "train loss:3.1133239992876505e-05\n",
      "train loss:0.002622961043577\n",
      "train loss:0.01647794532594352\n",
      "train loss:7.258117207591314e-05\n",
      "train loss:0.007470549840643532\n",
      "train loss:0.0021436735408426476\n",
      "train loss:0.0010906628664869376\n",
      "train loss:0.0018184254835924838\n",
      "train loss:0.002496799177449608\n",
      "train loss:0.0005028521636262195\n",
      "train loss:0.00012873729718623086\n",
      "train loss:0.004594997594755738\n",
      "train loss:4.7612721078087605e-05\n",
      "train loss:0.0004620522337804793\n",
      "train loss:0.0002710507828018337\n",
      "train loss:0.012519875474459494\n",
      "train loss:0.00969640907237661\n",
      "train loss:0.0005635907823532146\n",
      "train loss:0.002024172280232857\n",
      "train loss:0.0001524195935952578\n",
      "train loss:0.0002813115562659459\n",
      "train loss:0.0006560452983633097\n",
      "train loss:0.00010545409612404633\n",
      "train loss:0.027000021993344468\n",
      "train loss:0.00021223718821186438\n",
      "train loss:0.0039532145692151984\n",
      "train loss:0.0015486825843332164\n",
      "train loss:0.0025726235564210863\n",
      "train loss:2.2520999004589987e-05\n",
      "train loss:0.0008748477166469372\n",
      "train loss:0.0019483159563712718\n",
      "train loss:0.0024361975551836935\n",
      "train loss:0.0012977613850869813\n",
      "train loss:0.0002807937831153162\n",
      "train loss:0.0023143085817197966\n",
      "train loss:0.002669236544736737\n",
      "train loss:0.002107259099599376\n",
      "train loss:0.0012552343776533353\n",
      "train loss:0.007496527067212889\n",
      "train loss:0.005885838637639097\n",
      "train loss:0.0006108723563741363\n",
      "train loss:0.0011669933157294277\n",
      "train loss:0.00028905317932631486\n",
      "train loss:0.0016440989176469281\n",
      "train loss:0.002114880650552046\n",
      "train loss:0.0031752104352505135\n",
      "train loss:0.001881809309638032\n",
      "train loss:0.00017441647496610794\n",
      "train loss:0.0003560073087736554\n",
      "train loss:0.0026647968795454136\n",
      "train loss:0.0009409952699882876\n",
      "train loss:0.0002542903292842315\n",
      "train loss:0.0013024545613612463\n",
      "train loss:0.004025595574271224\n",
      "train loss:0.00020486690844432058\n",
      "train loss:0.006084055331311994\n",
      "train loss:0.00030619338285438493\n",
      "train loss:0.0008958720485601285\n",
      "train loss:0.0004382662187893384\n",
      "train loss:0.0006695772273547914\n",
      "train loss:0.0011583224228597512\n",
      "train loss:0.005381313908735188\n",
      "train loss:0.0010351706530586065\n",
      "train loss:0.0010212383762963362\n",
      "train loss:0.0006336020732645663\n",
      "train loss:0.0006414254967924124\n",
      "train loss:0.0005342809944702414\n",
      "train loss:0.0014309161347427926\n",
      "train loss:0.0005470980683406196\n",
      "train loss:0.0028556293954440475\n",
      "train loss:0.0002705746365324341\n",
      "train loss:0.0007656432356444136\n",
      "train loss:0.005400613535398594\n",
      "train loss:0.0007779283029900406\n",
      "train loss:0.0034785262849541913\n",
      "train loss:0.00029365478571200215\n",
      "train loss:0.0014121306757029933\n",
      "train loss:0.0033211775267350434\n",
      "train loss:0.0002662415615628099\n",
      "train loss:0.0004324922752582855\n",
      "train loss:0.005703481929262165\n",
      "train loss:0.0013397414785954473\n",
      "train loss:0.0019426011797976722\n",
      "train loss:0.0049338738934136565\n",
      "train loss:0.0011174435972015233\n",
      "train loss:0.00124749351691752\n",
      "train loss:0.0003079197684439443\n",
      "train loss:0.0020775429995358104\n",
      "train loss:0.001470100985564623\n",
      "train loss:0.0014448699177398259\n",
      "train loss:0.0027763488943020505\n",
      "train loss:0.00023309382244592367\n",
      "train loss:0.0009888891821209585\n",
      "train loss:0.0004422559047206623\n",
      "train loss:0.0005435644163040702\n",
      "train loss:0.0016888120504744387\n",
      "train loss:0.004655011483455806\n",
      "train loss:0.0008410595981327669\n",
      "train loss:0.000762489842617181\n",
      "train loss:0.0019594574758226486\n",
      "train loss:0.0004951025447474112\n",
      "train loss:0.0011457087412109562\n",
      "train loss:0.0016419555913117845\n",
      "train loss:0.0002458457544370596\n",
      "train loss:0.004799505369237489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0008447761844075489\n",
      "train loss:7.005477056652777e-05\n",
      "train loss:0.00021735378259401744\n",
      "train loss:4.100000892631664e-05\n",
      "train loss:0.0014807475700244666\n",
      "train loss:0.000492546485850873\n",
      "train loss:0.001969798247489225\n",
      "train loss:0.0005521576271439874\n",
      "train loss:0.00021007915471088473\n",
      "train loss:0.001001351123470125\n",
      "train loss:0.001335824572715731\n",
      "train loss:0.0002697602494734188\n",
      "train loss:0.000471557931754904\n",
      "train loss:0.0005275664560863984\n",
      "train loss:0.0013363409079443429\n",
      "train loss:0.0003117613647629306\n",
      "train loss:0.015789115985538706\n",
      "train loss:0.0005388289700388716\n",
      "train loss:0.0022246045979637235\n",
      "train loss:0.00016013056641752893\n",
      "train loss:0.00036470879992590144\n",
      "train loss:0.0003065733820684028\n",
      "train loss:0.005842510263960859\n",
      "train loss:0.00015020220110528425\n",
      "train loss:0.0003317673167363389\n",
      "train loss:0.0038831942057596684\n",
      "train loss:0.002525130521906545\n",
      "train loss:0.0015238518873750492\n",
      "train loss:0.003382714460637489\n",
      "train loss:0.00019773228583438516\n",
      "train loss:0.003314759403702066\n",
      "train loss:0.0002196059917479611\n",
      "train loss:0.00027085478667459076\n",
      "train loss:0.0017568054040392688\n",
      "train loss:0.00038017331372988786\n",
      "train loss:0.0009563933491520941\n",
      "train loss:0.00020109778769650713\n",
      "train loss:0.001704369970778287\n",
      "train loss:0.0003360384648921182\n",
      "train loss:0.002371616717809226\n",
      "train loss:0.0009174873527061231\n",
      "train loss:0.0005307554011786029\n",
      "train loss:0.009200635159438197\n",
      "train loss:0.0006025627303762298\n",
      "train loss:0.0016591875870367444\n",
      "train loss:0.0012039898806621453\n",
      "train loss:0.0016746253399591343\n",
      "train loss:0.002009102049855952\n",
      "train loss:0.0013086055734525524\n",
      "train loss:8.094486014868015e-05\n",
      "train loss:0.0017839154247463614\n",
      "train loss:0.0010152152139669558\n",
      "train loss:0.0010065576787042054\n",
      "train loss:0.004303858014608452\n",
      "train loss:0.00529245752038003\n",
      "train loss:0.00028120322900774766\n",
      "train loss:0.00020511277540218107\n",
      "train loss:0.005118500461367493\n",
      "train loss:0.0002803432893285849\n",
      "train loss:0.0009578595477123497\n",
      "train loss:0.0024850553900263627\n",
      "train loss:0.0035506060810751305\n",
      "train loss:0.0001971058432264516\n",
      "train loss:0.00057751200228526\n",
      "train loss:0.0009123831948892037\n",
      "train loss:0.001310306881839689\n",
      "train loss:0.000923796256109928\n",
      "train loss:0.0003443682222439328\n",
      "train loss:0.0015592149714628001\n",
      "train loss:0.0013667024828111682\n",
      "train loss:0.00028114795795039396\n",
      "train loss:7.705962942650681e-05\n",
      "train loss:0.0006300929281720919\n",
      "train loss:0.00590148268821898\n",
      "train loss:0.003363866250342464\n",
      "train loss:0.0008386737991458925\n",
      "train loss:0.00021863295140386822\n",
      "train loss:5.025329244705641e-05\n",
      "train loss:0.0003054958186805012\n",
      "train loss:0.0021981642961339466\n",
      "train loss:0.0018631114038108268\n",
      "train loss:0.00033566245465346643\n",
      "train loss:0.00030203347319164494\n",
      "train loss:0.0002447872445304992\n",
      "train loss:0.0003104175316267015\n",
      "train loss:0.0005036291171053268\n",
      "train loss:0.002372255927318729\n",
      "train loss:0.0006628524595432462\n",
      "train loss:0.00017157369059887732\n",
      "train loss:0.0008886354872354252\n",
      "train loss:0.000578906324528515\n",
      "train loss:0.0010386858833703557\n",
      "train loss:0.0012963962611054047\n",
      "train loss:0.0006197035555454468\n",
      "train loss:0.000703313357677095\n",
      "train loss:0.0006401731468378445\n",
      "train loss:0.0011289071134708878\n",
      "train loss:0.00019089947837383205\n",
      "train loss:0.0015992333077226263\n",
      "train loss:0.002724146825862452\n",
      "train loss:6.822200606079043e-05\n",
      "train loss:0.005186965293297227\n",
      "train loss:0.0005128179552915409\n",
      "train loss:0.0001578572086733965\n",
      "train loss:0.002732991299518837\n",
      "train loss:0.000560697761456959\n",
      "train loss:0.0009172660134615329\n",
      "train loss:0.0002080590324249651\n",
      "train loss:3.303137819490682e-05\n",
      "train loss:0.0006235291218807308\n",
      "train loss:0.0022349086599134493\n",
      "train loss:0.002317494095574151\n",
      "train loss:0.001213042638610153\n",
      "train loss:0.00020114143948162162\n",
      "train loss:0.00037996976084245823\n",
      "train loss:0.0021545929752497255\n",
      "train loss:0.00045512530394586985\n",
      "train loss:0.0011162766801479094\n",
      "train loss:0.0009713094974969032\n",
      "train loss:0.0011190208095327898\n",
      "train loss:0.0006714804155936325\n",
      "train loss:0.001521411708426632\n",
      "train loss:0.000163104279053618\n",
      "train loss:0.0001193035988489194\n",
      "train loss:0.005065142771818789\n",
      "train loss:5.24087484392078e-05\n",
      "train loss:0.001965919540418565\n",
      "train loss:0.0006778088485362227\n",
      "train loss:0.0008767865968407279\n",
      "train loss:0.000730393151716876\n",
      "train loss:6.732504382728259e-05\n",
      "train loss:0.0015224243273621698\n",
      "train loss:0.00016362601518855405\n",
      "train loss:0.0005871003300429077\n",
      "train loss:0.0003926619466137288\n",
      "train loss:0.007253540569485994\n",
      "train loss:0.0028510234124006924\n",
      "train loss:0.0035839286453723585\n",
      "train loss:0.00045938857759549457\n",
      "train loss:0.002187371449336543\n",
      "train loss:2.2791473156606248e-05\n",
      "train loss:0.0001115610398600093\n",
      "train loss:0.0005965721580807182\n",
      "train loss:0.00025254846721427195\n",
      "train loss:7.2201691260714e-05\n",
      "train loss:0.00017872639105782028\n",
      "train loss:5.296661985684247e-05\n",
      "train loss:0.004247466032758332\n",
      "train loss:0.002947193408715378\n",
      "train loss:0.0010205861487721018\n",
      "train loss:0.0007312594396545564\n",
      "train loss:0.0012267698450301844\n",
      "train loss:4.865675100015582e-05\n",
      "train loss:0.0013283914694353866\n",
      "train loss:0.0015171621616945038\n",
      "train loss:0.0005515501367389755\n",
      "train loss:0.00046362001117238407\n",
      "train loss:0.0007325388927024355\n",
      "train loss:0.0006148811991479551\n",
      "train loss:0.0017468497027827681\n",
      "train loss:0.0005070689316956083\n",
      "train loss:0.0015726809681028962\n",
      "train loss:0.0041196413374259755\n",
      "train loss:0.0010874522485209786\n",
      "train loss:0.0013329611433294435\n",
      "train loss:0.00026998978101064363\n",
      "train loss:0.0014425660234843557\n",
      "train loss:0.0006785221436180281\n",
      "train loss:4.4310258285238155e-05\n",
      "train loss:0.0008616629158083246\n",
      "train loss:0.0007888521205384319\n",
      "train loss:0.0004926426670379974\n",
      "train loss:0.005631032271195402\n",
      "train loss:0.000559676452057372\n",
      "train loss:0.0014789035198829546\n",
      "train loss:0.00018035960611093816\n",
      "train loss:9.60498466781364e-05\n",
      "train loss:5.7533496538970584e-05\n",
      "train loss:0.002313106240966673\n",
      "train loss:0.0005762724723274285\n",
      "train loss:0.0001661558430982018\n",
      "train loss:0.0016064988293875882\n",
      "train loss:0.0028491295081970024\n",
      "train loss:0.01410595933561956\n",
      "train loss:0.0005785044278785166\n",
      "train loss:0.0019856731649286518\n",
      "train loss:0.001275908877783488\n",
      "train loss:0.0015325652607381432\n",
      "train loss:6.413782998738356e-05\n",
      "train loss:0.00016829858669696035\n",
      "train loss:0.0004282633498644136\n",
      "train loss:2.871801879739977e-05\n",
      "train loss:0.00018848805289607703\n",
      "train loss:0.002204865229003707\n",
      "train loss:0.003008544915058325\n",
      "train loss:0.0007517948606901819\n",
      "train loss:0.0012002998507508133\n",
      "train loss:0.006305308356500704\n",
      "train loss:0.0010239718923627057\n",
      "train loss:0.0007590202068255168\n",
      "train loss:0.00637720078102758\n",
      "train loss:5.047291946413693e-05\n",
      "train loss:0.001698278790302776\n",
      "train loss:0.0003838379133843929\n",
      "train loss:0.0017843952360793228\n",
      "train loss:0.002183342631128295\n",
      "train loss:0.003169665499404728\n",
      "train loss:0.00138936990569425\n",
      "train loss:0.0032971210114295254\n",
      "train loss:0.0009861945091799143\n",
      "train loss:0.0002944688616061436\n",
      "train loss:0.00035265486608923217\n",
      "train loss:0.005662376295506244\n",
      "train loss:0.0001002324391494286\n",
      "train loss:0.0004572393558286599\n",
      "train loss:0.000356159889334124\n",
      "train loss:0.0004545303699864121\n",
      "train loss:0.000576530920284043\n",
      "train loss:0.000329628465362677\n",
      "train loss:0.0011372085980437393\n",
      "train loss:0.0014891561768909576\n",
      "train loss:0.0015895356473196365\n",
      "train loss:0.0008725550635696284\n",
      "train loss:0.0015357837263312002\n",
      "train loss:0.00014367980710341868\n",
      "train loss:0.0005687431306450327\n",
      "train loss:0.010618567652580704\n",
      "train loss:7.453749189063775e-05\n",
      "train loss:0.0006301029020611483\n",
      "train loss:0.002172433972832231\n",
      "train loss:0.0004116981077737463\n",
      "train loss:8.39543923167306e-05\n",
      "train loss:0.0005314154131661858\n",
      "train loss:0.0014489691099430428\n",
      "train loss:0.0003234633945484468\n",
      "train loss:0.0030130180964931647\n",
      "train loss:0.0014237767995163198\n",
      "train loss:0.0027616102885522596\n",
      "train loss:0.004459940833239388\n",
      "train loss:0.001354473916117742\n",
      "train loss:0.0008026240585507603\n",
      "train loss:0.00013698321018168708\n",
      "train loss:0.0035076166147812488\n",
      "train loss:0.0004795957574912323\n",
      "train loss:9.825469395933966e-05\n",
      "train loss:0.0002497777219321005\n",
      "train loss:0.005725007822256903\n",
      "train loss:0.0006333171599329055\n",
      "train loss:0.0024044292861798208\n",
      "train loss:0.0006940670491625609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007676501473700986\n",
      "train loss:0.0028741534746394687\n",
      "train loss:0.005814628564231955\n",
      "train loss:0.001265038428757852\n",
      "train loss:0.00014519378206467938\n",
      "train loss:0.00028086380556853246\n",
      "train loss:0.0011065690871037493\n",
      "train loss:0.0017208480886774591\n",
      "train loss:0.0012576787577263041\n",
      "train loss:0.0013527823897315344\n",
      "train loss:0.00036349345824802015\n",
      "train loss:0.0003059960169810444\n",
      "train loss:0.00011576674467768123\n",
      "train loss:0.00019733489125391232\n",
      "train loss:0.006013410390428086\n",
      "train loss:7.096668298413386e-05\n",
      "train loss:0.0001850049926120265\n",
      "train loss:0.00021717640515305888\n",
      "train loss:0.0010155608012848826\n",
      "train loss:0.0008349612474330837\n",
      "train loss:0.0007353748106442327\n",
      "train loss:0.0019932375365799273\n",
      "train loss:0.0012076000690560793\n",
      "train loss:0.000339855034274707\n",
      "train loss:0.0003049753738825759\n",
      "train loss:0.00016122158099632903\n",
      "train loss:3.339659934065058e-05\n",
      "train loss:4.59612927215439e-06\n",
      "train loss:0.0006560082406603207\n",
      "train loss:0.001309083867970237\n",
      "train loss:0.0003221333723137735\n",
      "train loss:0.0013107593146701678\n",
      "train loss:0.0003047796448899015\n",
      "train loss:0.0006936677122156475\n",
      "train loss:0.00030027405956960506\n",
      "train loss:0.01900138094804353\n",
      "train loss:0.0018947466265855008\n",
      "train loss:0.0011330551249587872\n",
      "train loss:6.647219944829663e-05\n",
      "train loss:0.003010908947253324\n",
      "train loss:0.0044165489930271425\n",
      "train loss:0.000874438886715333\n",
      "train loss:0.00022298829375867326\n",
      "train loss:0.001035996893601996\n",
      "train loss:0.0005936844204771575\n",
      "train loss:0.003734104450545454\n",
      "train loss:0.0011745554341602384\n",
      "train loss:0.001476750450677186\n",
      "train loss:0.0018588170752815378\n",
      "train loss:0.0011889409535084383\n",
      "train loss:0.0032310723360360104\n",
      "train loss:0.0002493535986804047\n",
      "train loss:3.414688613065499e-05\n",
      "train loss:0.0005753752631035322\n",
      "train loss:0.0005868655860241219\n",
      "train loss:0.00030153006356758836\n",
      "train loss:0.0023031605453943376\n",
      "train loss:0.0035963912859963186\n",
      "train loss:9.814289586448749e-05\n",
      "train loss:0.001913065166132246\n",
      "train loss:0.003154220183835323\n",
      "train loss:0.0012502301500653212\n",
      "train loss:0.00010769772434184267\n",
      "train loss:5.877323005141607e-05\n",
      "train loss:0.000623380508068047\n",
      "train loss:0.0012678646411639041\n",
      "train loss:0.00033283349503517885\n",
      "train loss:6.625875217891882e-05\n",
      "train loss:0.00018625410175533512\n",
      "train loss:0.001371989281381094\n",
      "train loss:1.3375052051582735e-05\n",
      "train loss:0.002975494969421287\n",
      "train loss:0.0029215386153943683\n",
      "train loss:0.001422427444703628\n",
      "train loss:0.0029584182318196667\n",
      "train loss:7.918133469034547e-06\n",
      "train loss:0.0025984801054063267\n",
      "train loss:0.005628979777745011\n",
      "train loss:0.004316865284392626\n",
      "train loss:0.0006857995566844244\n",
      "train loss:0.00801011682977508\n",
      "train loss:0.00047600501628816433\n",
      "train loss:6.271702997090312e-05\n",
      "train loss:0.0009196601615923237\n",
      "train loss:0.00012523986830382698\n",
      "train loss:0.0020953114114247535\n",
      "train loss:0.0005979438783919723\n",
      "train loss:2.709839358841155e-05\n",
      "train loss:0.0028590446956732515\n",
      "train loss:7.596021667816906e-05\n",
      "train loss:6.303424792820183e-05\n",
      "train loss:0.0061576713311331166\n",
      "train loss:0.008102303437914292\n",
      "train loss:0.0002369402995682749\n",
      "train loss:0.000988555730821987\n",
      "train loss:0.0006086844241491329\n",
      "train loss:0.002569575284534104\n",
      "train loss:0.0019699633860955855\n",
      "train loss:0.0007970573495558617\n",
      "train loss:0.00025523468415223727\n",
      "train loss:0.00013442333224129182\n",
      "train loss:0.005638845330761691\n",
      "train loss:0.0001527545232021805\n",
      "train loss:0.0003363813013447937\n",
      "train loss:0.00010097806515851994\n",
      "train loss:0.0012458237989473014\n",
      "train loss:0.0010120689366098267\n",
      "train loss:0.001035952674842178\n",
      "train loss:0.0012711897065100341\n",
      "train loss:0.0005805121414156895\n",
      "train loss:0.00021992929101379106\n",
      "train loss:0.00021573374330677598\n",
      "train loss:0.0004833612953442442\n",
      "train loss:0.00047003508696613535\n",
      "train loss:0.0006249534317597929\n",
      "train loss:0.0025953503160561454\n",
      "train loss:0.0011633878446310488\n",
      "train loss:0.0004976109563067217\n",
      "train loss:0.0013370201727574704\n",
      "train loss:0.0008929385477717025\n",
      "train loss:2.921782171348159e-05\n",
      "train loss:0.001731167068559024\n",
      "train loss:0.00012199991752808126\n",
      "train loss:8.233160270703698e-05\n",
      "train loss:0.00020626147785207847\n",
      "train loss:0.00011862821404965713\n",
      "train loss:0.00032594097118047343\n",
      "train loss:0.0021067571652588833\n",
      "train loss:0.0010335088281837365\n",
      "train loss:0.0004184473571303001\n",
      "train loss:0.0008928787973907553\n",
      "train loss:0.000259700326210699\n",
      "train loss:0.0002170922302876932\n",
      "train loss:0.0017828694779381809\n",
      "train loss:0.0008252154030570883\n",
      "train loss:0.000245084910359584\n",
      "train loss:0.00019888001116265402\n",
      "train loss:0.0011433564460249603\n",
      "train loss:0.000244925813061868\n",
      "train loss:9.255097326988179e-05\n",
      "train loss:5.09986313153202e-05\n",
      "train loss:0.0023248160349355978\n",
      "=== epoch:20, train acc:0.997, test acc:0.986 ===\n",
      "train loss:0.009158583301014055\n",
      "train loss:0.001302518603585969\n",
      "train loss:0.0006923081203070521\n",
      "train loss:0.0001863737584918226\n",
      "train loss:0.0025992207783334977\n",
      "train loss:0.00016749705122309376\n",
      "train loss:0.0023000854185619337\n",
      "train loss:0.0028244332691506023\n",
      "train loss:7.037525141259172e-05\n",
      "train loss:0.003868942942832658\n",
      "train loss:0.00015371146541971157\n",
      "train loss:0.00010458680600957476\n",
      "train loss:0.0011950189652908377\n",
      "train loss:0.0004571242555806388\n",
      "train loss:0.00010739723597279742\n",
      "train loss:0.002031423991305697\n",
      "train loss:0.000710487340349199\n",
      "train loss:9.822290748522645e-05\n",
      "train loss:0.000528645698296407\n",
      "train loss:0.002128520162876678\n",
      "train loss:4.7308788755003126e-05\n",
      "train loss:0.009554177272593573\n",
      "train loss:0.0007759998667831288\n",
      "train loss:0.001377298167222843\n",
      "train loss:0.004317383976843892\n",
      "train loss:0.0014639017556323734\n",
      "train loss:0.0016133842250279134\n",
      "train loss:0.0011617137604642493\n",
      "train loss:0.0009743951943790556\n",
      "train loss:0.0015565197010894906\n",
      "train loss:0.000557256831775825\n",
      "train loss:0.0011421867151274647\n",
      "train loss:0.004046344384926232\n",
      "train loss:0.000781236893420427\n",
      "train loss:0.0014393999795681795\n",
      "train loss:1.764840869023415e-05\n",
      "train loss:0.00016301877500952177\n",
      "train loss:0.00023241429984365104\n",
      "train loss:8.723257511689093e-05\n",
      "train loss:0.005007878633662664\n",
      "train loss:0.0007835325232916311\n",
      "train loss:0.00559667275354729\n",
      "train loss:2.0539150832216513e-05\n",
      "train loss:0.0008435368795816727\n",
      "train loss:0.0009583160459490429\n",
      "train loss:0.00023826932832505689\n",
      "train loss:0.0005380901038145213\n",
      "train loss:0.00021930666097521738\n",
      "train loss:0.00017047006172650703\n",
      "train loss:0.003095848937129489\n",
      "train loss:0.0007123628563803948\n",
      "train loss:0.00018230310832295876\n",
      "train loss:0.00022288311874477367\n",
      "train loss:0.0002688989164825448\n",
      "train loss:0.0003412996441727554\n",
      "train loss:0.004425467018087327\n",
      "train loss:0.0005952308666069593\n",
      "train loss:0.0005107113766395649\n",
      "train loss:0.00024261512674083642\n",
      "train loss:0.0025548558254921113\n",
      "train loss:0.0009472530253482429\n",
      "train loss:0.0010320844262614328\n",
      "train loss:0.001366836575252824\n",
      "train loss:0.0005194636606963767\n",
      "train loss:0.000355117305999389\n",
      "train loss:0.0007934056138957076\n",
      "train loss:0.006356582023445471\n",
      "train loss:0.00039270233143060294\n",
      "train loss:0.0009446968962801185\n",
      "train loss:0.001083711536730251\n",
      "train loss:0.00038307232255834953\n",
      "train loss:0.0019137786835622566\n",
      "train loss:0.02747641130170086\n",
      "train loss:0.00020726783191402036\n",
      "train loss:0.00159693459072433\n",
      "train loss:0.0005608764834913791\n",
      "train loss:0.021531885511658792\n",
      "train loss:0.0005776932190902284\n",
      "train loss:4.210982893887123e-05\n",
      "train loss:0.0025858470755161346\n",
      "train loss:0.001062936185309401\n",
      "train loss:8.566127318092637e-05\n",
      "train loss:0.00015405196374017858\n",
      "train loss:0.0023593698418613055\n",
      "train loss:0.0017888606486024278\n",
      "train loss:0.00045038834317590634\n",
      "train loss:0.0003124862110417514\n",
      "train loss:0.0003523589858518162\n",
      "train loss:4.905912207170757e-05\n",
      "train loss:0.006018794065005046\n",
      "train loss:0.0004932950104192095\n",
      "train loss:0.008721468493738652\n",
      "train loss:0.00028333298998737844\n",
      "train loss:0.008566866622823875\n",
      "train loss:0.001326425275241301\n",
      "train loss:0.0013464016292149192\n",
      "train loss:0.001370719314791825\n",
      "train loss:0.0006332329668323006\n",
      "train loss:0.0018471729152810534\n",
      "train loss:0.0008408701302948748\n",
      "train loss:0.0002999934011369076\n",
      "train loss:0.0007132918836709439\n",
      "train loss:0.0022662463424599068\n",
      "train loss:0.0014203717827443504\n",
      "train loss:0.011069305341545908\n",
      "train loss:0.0016798822913363246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001288404873385336\n",
      "train loss:0.006676103805056424\n",
      "train loss:0.00041058596923439135\n",
      "train loss:0.0003038314486186908\n",
      "train loss:0.0006944290520145205\n",
      "train loss:0.0017287810403744763\n",
      "train loss:0.0005143365095675902\n",
      "train loss:0.0013384269824528714\n",
      "train loss:0.0033170425780005004\n",
      "train loss:0.0018652784364566277\n",
      "train loss:0.00330387181933946\n",
      "train loss:0.0012789343272314538\n",
      "train loss:0.012906777911773687\n",
      "train loss:0.002077985455694825\n",
      "train loss:0.03825597664859492\n",
      "train loss:0.010997970071592693\n",
      "train loss:0.0009969935450173466\n",
      "train loss:0.0004980083575522688\n",
      "train loss:0.001068164768565246\n",
      "train loss:0.02105582509196078\n",
      "train loss:0.0008408945380586188\n",
      "train loss:0.0007789286822800155\n",
      "train loss:0.0020820569721985553\n",
      "train loss:0.0001276947831736186\n",
      "train loss:0.00018103505665469476\n",
      "train loss:9.27452957008885e-05\n",
      "train loss:0.00015949743798374935\n",
      "train loss:2.8298705111984563e-05\n",
      "train loss:0.00017135823205170813\n",
      "train loss:0.00012205517876975662\n",
      "train loss:0.0001860016108105447\n",
      "train loss:2.5516297212119995e-05\n",
      "train loss:0.0025805899542670103\n",
      "train loss:0.0003868530288960941\n",
      "train loss:0.0008103252246102661\n",
      "train loss:0.0018590468838990946\n",
      "train loss:0.0019462092269876522\n",
      "train loss:0.00012133956467803804\n",
      "train loss:0.0002672162778330819\n",
      "train loss:0.004656357292781687\n",
      "train loss:0.0031190915013642835\n",
      "train loss:0.0034946042077345957\n",
      "train loss:0.0005541617284236222\n",
      "train loss:0.0031081569186300157\n",
      "train loss:4.691888515631007e-05\n",
      "train loss:3.834039742909831e-05\n",
      "train loss:0.0002528294703656564\n",
      "train loss:0.0003997186582151208\n",
      "train loss:0.0003590488131666022\n",
      "train loss:0.00017755863569342102\n",
      "train loss:0.00021170738663450005\n",
      "train loss:5.803084830976725e-05\n",
      "train loss:6.107480889599732e-05\n",
      "train loss:0.0004304592135368409\n",
      "train loss:0.000745077845554221\n",
      "train loss:0.0010229252982270189\n",
      "train loss:0.0006926772569938959\n",
      "train loss:0.000601647898282944\n",
      "train loss:0.0003079821171445289\n",
      "train loss:0.003047542140617811\n",
      "train loss:0.0011580981605824416\n",
      "train loss:0.0005847373786364631\n",
      "train loss:0.0007314764086319148\n",
      "train loss:0.00020153173835376118\n",
      "train loss:0.0021209606426998992\n",
      "train loss:9.534522467311842e-05\n",
      "train loss:0.0018646039167259135\n",
      "train loss:0.0005531410201630192\n",
      "train loss:0.0013436878206008048\n",
      "train loss:0.000491681851471609\n",
      "train loss:0.018784919602584563\n",
      "train loss:0.0006956963409137828\n",
      "train loss:0.002094247743232293\n",
      "train loss:3.39935095930073e-05\n",
      "train loss:0.00017081315961393672\n",
      "train loss:0.0005578182604795477\n",
      "train loss:0.0014699757464059526\n",
      "train loss:0.002348584975930778\n",
      "train loss:0.0004010762366955415\n",
      "train loss:0.0008861486296432312\n",
      "train loss:0.0022159018460231423\n",
      "train loss:0.0004377172026216392\n",
      "train loss:0.0002344450728053108\n",
      "train loss:6.592637363950279e-05\n",
      "train loss:0.003122544758175779\n",
      "train loss:0.0007159254462690442\n",
      "train loss:0.00019692446445987043\n",
      "train loss:0.00014518923974586007\n",
      "train loss:0.0004063676406494675\n",
      "train loss:0.0002162235116241912\n",
      "train loss:0.0002233697458274905\n",
      "train loss:0.007251656966021488\n",
      "train loss:0.0008197156089965042\n",
      "train loss:0.0008803137443770181\n",
      "train loss:0.0015442320217934368\n",
      "train loss:0.0011884507032816857\n",
      "train loss:0.0018042232054617327\n",
      "train loss:0.006985298366456841\n",
      "train loss:0.001351355890957489\n",
      "train loss:0.004936621815367272\n",
      "train loss:0.00018238293397019177\n",
      "train loss:0.0020981272162361336\n",
      "train loss:0.0003645240891953664\n",
      "train loss:0.0001351154879079647\n",
      "train loss:0.001076098501303514\n",
      "train loss:0.0012198211256055072\n",
      "train loss:0.0021640752841940083\n",
      "train loss:0.0010383602323377457\n",
      "train loss:0.00022633895759691442\n",
      "train loss:0.002970625369001283\n",
      "train loss:0.0004238784821687697\n",
      "train loss:0.0049428966154408446\n",
      "train loss:7.201093456086443e-05\n",
      "train loss:4.202746773187885e-05\n",
      "train loss:0.00012220118401014388\n",
      "train loss:0.0023751994411131292\n",
      "train loss:3.943574825268048e-05\n",
      "train loss:0.0020509615852850258\n",
      "train loss:0.004348940721835585\n",
      "train loss:0.00017618016209050758\n",
      "train loss:0.0002320259045666411\n",
      "train loss:0.0170102726771522\n",
      "train loss:0.004709047624819346\n",
      "train loss:0.002776604262840557\n",
      "train loss:0.00031791493315192\n",
      "train loss:0.0012902554364467714\n",
      "train loss:0.0031180084415962928\n",
      "train loss:0.00023017624805149098\n",
      "train loss:0.0019306907136931893\n",
      "train loss:0.0009453684920650993\n",
      "train loss:0.007811468023557272\n",
      "train loss:0.0013972445143249598\n",
      "train loss:0.0005458477720286198\n",
      "train loss:0.0011391316051006697\n",
      "train loss:0.0027507166436223957\n",
      "train loss:0.00041060444982541597\n",
      "train loss:0.004757110036436235\n",
      "train loss:0.0006072895573087872\n",
      "train loss:0.00012700115150107206\n",
      "train loss:0.0004980156256403726\n",
      "train loss:0.0030606711831805632\n",
      "train loss:0.0022774361210614897\n",
      "train loss:0.03923979000265266\n",
      "train loss:0.002466552248234686\n",
      "train loss:0.001015175327331307\n",
      "train loss:0.0028720848577640625\n",
      "train loss:0.00020673204530142957\n",
      "train loss:0.002331854259788552\n",
      "train loss:0.02345794772477867\n",
      "train loss:0.001150904749578381\n",
      "train loss:0.0009091348937591615\n",
      "train loss:0.002441646910632241\n",
      "train loss:0.00019127622246237962\n",
      "train loss:0.00747117347452538\n",
      "train loss:0.0015297558389830248\n",
      "train loss:0.0007248066206768264\n",
      "train loss:0.0028584934659023377\n",
      "train loss:0.0006592371471305304\n",
      "train loss:0.00404813838201211\n",
      "train loss:0.0022053093274297204\n",
      "train loss:0.0045838903206978495\n",
      "train loss:7.737521654687631e-05\n",
      "train loss:0.00022478392072672738\n",
      "train loss:1.7781670429936337e-05\n",
      "train loss:0.0002987623202961118\n",
      "train loss:0.0001389557472613693\n",
      "train loss:0.0024600473786290412\n",
      "train loss:0.0014139084222588355\n",
      "train loss:0.05378334533511414\n",
      "train loss:0.001372949794209512\n",
      "train loss:0.0017703597123817849\n",
      "train loss:0.0005821733035308511\n",
      "train loss:0.0002577468881207068\n",
      "train loss:0.001388711745985968\n",
      "train loss:0.00019275690396410928\n",
      "train loss:0.0027542749125344197\n",
      "train loss:0.0039935630573883305\n",
      "train loss:0.013880545288760522\n",
      "train loss:0.0018437760130614672\n",
      "train loss:0.003489110993899252\n",
      "train loss:0.0001927090018369961\n",
      "train loss:9.254840831944603e-05\n",
      "train loss:9.103836805075352e-05\n",
      "train loss:0.0005388628160382012\n",
      "train loss:0.0004829396252650884\n",
      "train loss:0.0003769533061090848\n",
      "train loss:0.001812882999275335\n",
      "train loss:0.0013069729858804166\n",
      "train loss:0.001096147625751007\n",
      "train loss:2.605431905343691e-05\n",
      "train loss:0.0009147068101454876\n",
      "train loss:0.0007417829272258767\n",
      "train loss:0.0011680213396780684\n",
      "train loss:0.013311295700340432\n",
      "train loss:0.002044069966242275\n",
      "train loss:3.8901695834235554e-05\n",
      "train loss:0.000324874303122305\n",
      "train loss:0.0008492265239290967\n",
      "train loss:0.0042122569395654326\n",
      "train loss:0.0007781450184257486\n",
      "train loss:9.765342785390372e-05\n",
      "train loss:0.001645306618311662\n",
      "train loss:0.001653892579495515\n",
      "train loss:0.001161151458970424\n",
      "train loss:0.0018371873030225288\n",
      "train loss:0.0005941492276138288\n",
      "train loss:0.0031158752654907823\n",
      "train loss:0.003228975456401075\n",
      "train loss:0.001196955911852915\n",
      "train loss:2.073547602948071e-05\n",
      "train loss:0.0011139315523799643\n",
      "train loss:0.004183214434210182\n",
      "train loss:0.005455442462620194\n",
      "train loss:0.002832371242668766\n",
      "train loss:0.004928118993299078\n",
      "train loss:0.00020298127501580792\n",
      "train loss:0.006113917549591539\n",
      "train loss:0.0004246270248041701\n",
      "train loss:0.0005240766762747735\n",
      "train loss:0.00010343070159168848\n",
      "train loss:0.0021277600355752452\n",
      "train loss:0.0010159040824876395\n",
      "train loss:5.429410957577116e-05\n",
      "train loss:0.0004519886806403097\n",
      "train loss:0.00471110162579375\n",
      "train loss:0.0008263750350496476\n",
      "train loss:0.0006480971425540313\n",
      "train loss:0.0006621869049539026\n",
      "train loss:0.00036437454426490413\n",
      "train loss:9.443565802097758e-05\n",
      "train loss:0.001668104045824988\n",
      "train loss:2.9600207054919394e-05\n",
      "train loss:0.0012592634502366507\n",
      "train loss:0.0017895568470024364\n",
      "train loss:0.000128224954729312\n",
      "train loss:0.004430932893835928\n",
      "train loss:9.028757924226788e-05\n",
      "train loss:0.0027409409125776067\n",
      "train loss:0.002197299194535407\n",
      "train loss:0.0008730945861794378\n",
      "train loss:0.00015985540007948433\n",
      "train loss:0.000564975158290052\n",
      "train loss:0.0006295815160016021\n",
      "train loss:0.00027568390239510296\n",
      "train loss:0.0016788680020945804\n",
      "train loss:1.8721185171104527e-05\n",
      "train loss:0.0003763870781537615\n",
      "train loss:0.0038773826749085006\n",
      "train loss:0.00299668069423018\n",
      "train loss:0.0008545067555014625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007656424054210206\n",
      "train loss:0.0015352558310223442\n",
      "train loss:7.295799857080256e-05\n",
      "train loss:0.00023167164860449764\n",
      "train loss:1.887265459709054e-05\n",
      "train loss:0.00022109384373007626\n",
      "train loss:0.0004015167945215104\n",
      "train loss:0.00013815310319323102\n",
      "train loss:0.0004828436130025786\n",
      "train loss:0.034793073112027416\n",
      "train loss:0.0012466881852143603\n",
      "train loss:0.002216586667255494\n",
      "train loss:0.003226075270064012\n",
      "train loss:0.0015440788690056864\n",
      "train loss:0.00015032462455895405\n",
      "train loss:0.0014263979749630457\n",
      "train loss:0.000268722318875264\n",
      "train loss:0.0002799484539515777\n",
      "train loss:0.0009474866189084756\n",
      "train loss:0.001595578747556089\n",
      "train loss:0.0026526483490411407\n",
      "train loss:2.5417889991800076e-05\n",
      "train loss:0.0009194254345849824\n",
      "train loss:0.0015506933345542707\n",
      "train loss:0.00012913678926774894\n",
      "train loss:0.003739401592050073\n",
      "train loss:0.00038553024969419515\n",
      "train loss:0.0015371809241614587\n",
      "train loss:0.0009896852344215609\n",
      "train loss:0.00023587362895895704\n",
      "train loss:0.0011053046664794854\n",
      "train loss:0.00011076160684001314\n",
      "train loss:0.0005074883745546772\n",
      "train loss:0.0012524700127754418\n",
      "train loss:0.0011997219067468275\n",
      "train loss:0.0015916650212802865\n",
      "train loss:0.0035901894501451726\n",
      "train loss:0.0002307284868537888\n",
      "train loss:0.011594966214225932\n",
      "train loss:0.0009736431018635834\n",
      "train loss:0.0013508174640506877\n",
      "train loss:0.002828778245273802\n",
      "train loss:0.0018692372091007015\n",
      "train loss:0.0008109333771330111\n",
      "train loss:0.003621619892450632\n",
      "train loss:0.0002864949854770654\n",
      "train loss:6.470845170056063e-05\n",
      "train loss:4.492902163735476e-05\n",
      "train loss:0.0033197596705599477\n",
      "train loss:0.0051710035875283285\n",
      "train loss:0.0002437572322223975\n",
      "train loss:0.0015399998117925826\n",
      "train loss:0.0001897276780138605\n",
      "train loss:0.00031511319154615475\n",
      "train loss:0.0022215674481981637\n",
      "train loss:0.005131250600791802\n",
      "train loss:0.002964079475405051\n",
      "train loss:0.0003528153073117265\n",
      "train loss:0.0005769642110359948\n",
      "train loss:0.0010889611832571226\n",
      "train loss:0.00015708764439175085\n",
      "train loss:0.0002663356272026467\n",
      "train loss:5.474703715211209e-05\n",
      "train loss:8.27223175256853e-05\n",
      "train loss:0.00012124476711201544\n",
      "train loss:0.00012370305956750188\n",
      "train loss:4.390496089948809e-05\n",
      "train loss:0.0024502843886978526\n",
      "train loss:0.00041996498479126155\n",
      "train loss:0.0026035595558713816\n",
      "train loss:0.0003283418659035995\n",
      "train loss:0.0001146535344953118\n",
      "train loss:0.0008629853550152642\n",
      "train loss:0.0013391369421153795\n",
      "train loss:0.0004387879512980282\n",
      "train loss:0.00043249328324520636\n",
      "train loss:1.562837247917663e-05\n",
      "train loss:0.0018002342554442894\n",
      "train loss:9.287130499652973e-05\n",
      "train loss:0.0013725299737895322\n",
      "train loss:0.0027973459241642\n",
      "train loss:0.0012562764726902816\n",
      "train loss:0.0012772636019713535\n",
      "train loss:0.0005863317166742907\n",
      "train loss:0.001591917100218559\n",
      "train loss:0.0007015846551445745\n",
      "train loss:0.00014844829090405697\n",
      "train loss:0.0008485812941144367\n",
      "train loss:0.0032073073563702063\n",
      "train loss:0.0004744640815122284\n",
      "train loss:0.00045895199726528953\n",
      "train loss:0.0006528428456514931\n",
      "train loss:0.0024376959837939614\n",
      "train loss:0.0003605619338084364\n",
      "train loss:0.0001410273509818868\n",
      "train loss:0.0018536962855364059\n",
      "train loss:0.0003298707815200829\n",
      "train loss:0.0015706739700341026\n",
      "train loss:0.0015728372322882187\n",
      "train loss:0.0013256489029712711\n",
      "train loss:5.8847808439556904e-05\n",
      "train loss:0.0017721596712719332\n",
      "train loss:0.000953167713561532\n",
      "train loss:0.0025199172318753323\n",
      "train loss:0.000190802132353572\n",
      "train loss:0.0010061572793403485\n",
      "train loss:0.0010475953476783348\n",
      "train loss:0.0006937519521241685\n",
      "train loss:0.0003657876506957617\n",
      "train loss:0.004316808796816884\n",
      "train loss:0.0002564394938509688\n",
      "train loss:0.0039610546389655995\n",
      "train loss:0.0014108868377363532\n",
      "train loss:8.807373128796852e-05\n",
      "train loss:0.0023716170193702406\n",
      "train loss:0.002026096666998323\n",
      "train loss:6.90163360623033e-05\n",
      "train loss:0.0009035790176767004\n",
      "train loss:3.1352913366991835e-05\n",
      "train loss:0.00024129532732544752\n",
      "train loss:0.00752528612636396\n",
      "train loss:0.0014018284637340667\n",
      "train loss:0.0010193636933430034\n",
      "train loss:0.00012422448976080888\n",
      "train loss:0.0009658940232055677\n",
      "train loss:0.009566142238613845\n",
      "train loss:0.0021599036903134313\n",
      "train loss:0.0001613173610988257\n",
      "train loss:0.0008983409192596888\n",
      "train loss:0.00025625657206258324\n",
      "train loss:8.123027194151672e-05\n",
      "train loss:7.200836448947962e-05\n",
      "train loss:0.009894429416954004\n",
      "train loss:0.00755764525177685\n",
      "train loss:0.0007691153873249035\n",
      "train loss:0.009720273071040415\n",
      "train loss:0.0020267800996556394\n",
      "train loss:0.000725278646403745\n",
      "train loss:0.00010546539947728822\n",
      "train loss:4.190226418915071e-05\n",
      "train loss:0.0011636032850252385\n",
      "train loss:0.006056930026581645\n",
      "train loss:0.0024411389352481517\n",
      "train loss:0.000805207683065943\n",
      "train loss:8.308079407993822e-05\n",
      "train loss:0.0005116928791882616\n",
      "train loss:0.0013306530929304314\n",
      "train loss:0.003116333154688386\n",
      "train loss:0.00936929168076233\n",
      "train loss:0.000788634542984848\n",
      "train loss:0.0008693052233310136\n",
      "train loss:0.0005939896616039862\n",
      "train loss:1.3947231303538396e-05\n",
      "train loss:0.0007440398380065833\n",
      "train loss:0.000376941524529737\n",
      "train loss:0.0023647020491011556\n",
      "train loss:0.0012943054509783165\n",
      "train loss:0.028415530779609895\n",
      "train loss:0.0015939691687938465\n",
      "train loss:0.00026661525235170203\n",
      "train loss:0.0007168000230927997\n",
      "train loss:0.0012950813541650794\n",
      "train loss:0.0004920068357999308\n",
      "train loss:0.000633984697887864\n",
      "train loss:0.012979524806647644\n",
      "train loss:0.0006008895081321824\n",
      "train loss:0.0002760334760293938\n",
      "train loss:0.0016976766523121997\n",
      "train loss:0.0011944291212968002\n",
      "train loss:0.002448690105580722\n",
      "train loss:4.9355877516151226e-05\n",
      "train loss:0.0010931345202220425\n",
      "train loss:0.0020111508001559664\n",
      "train loss:0.001531564077047213\n",
      "train loss:9.106567368110272e-05\n",
      "train loss:5.5659276238087075e-05\n",
      "train loss:0.00023289400077910688\n",
      "train loss:6.561046991420327e-06\n",
      "train loss:0.0037232901965511293\n",
      "train loss:0.0008411028250110572\n",
      "train loss:0.00013547319640825755\n",
      "train loss:0.00042058971574814486\n",
      "train loss:0.001035124482078034\n",
      "train loss:2.490159199139067e-05\n",
      "train loss:0.0003761846197212373\n",
      "train loss:0.0021247611014268276\n",
      "train loss:0.0017160142091747507\n",
      "train loss:0.0032943811997519644\n",
      "train loss:5.688970047778322e-05\n",
      "train loss:0.0008287804013775505\n",
      "train loss:0.0023049975278887857\n",
      "train loss:0.00042042111462649626\n",
      "train loss:0.0015876216151315065\n",
      "train loss:0.006487156168749605\n",
      "train loss:0.0003537513219430653\n",
      "train loss:0.00010289693479967979\n",
      "train loss:0.0013885892385013762\n",
      "train loss:0.018792419876686645\n",
      "train loss:0.00012754781149722444\n",
      "train loss:0.0009900526377665054\n",
      "train loss:0.00024883089529619104\n",
      "train loss:0.0001816802627520207\n",
      "train loss:0.004256787733306789\n",
      "train loss:0.0008785256801989501\n",
      "train loss:0.0018548074932734587\n",
      "train loss:0.00011491842103415754\n",
      "train loss:0.0012628268583162732\n",
      "train loss:0.000226822149568857\n",
      "train loss:0.0002107279529294963\n",
      "train loss:0.0009469980319403917\n",
      "train loss:0.00097364194871296\n",
      "train loss:0.0003677309410350112\n",
      "train loss:0.00044900673847112583\n",
      "train loss:0.00048427640662987\n",
      "train loss:0.0013193983344051351\n",
      "train loss:0.0003574097189797548\n",
      "train loss:0.00048508024632207443\n",
      "train loss:0.002739046603742185\n",
      "train loss:0.0009049739478372023\n",
      "train loss:0.001249660467456262\n",
      "train loss:2.0340118638299287e-05\n",
      "train loss:0.0005796870139155062\n",
      "train loss:0.0005487391887660818\n",
      "train loss:4.9532344948730576e-05\n",
      "train loss:8.422888790749986e-05\n",
      "train loss:0.00019512143646934364\n",
      "train loss:0.00017413549518235658\n",
      "train loss:0.0017819913044749439\n",
      "train loss:0.005011885839490821\n",
      "train loss:0.00010732402972718988\n",
      "train loss:0.0011932254309796632\n",
      "train loss:0.00012930116759889954\n",
      "train loss:2.3917431307650736e-05\n",
      "train loss:0.00010294461462527133\n",
      "train loss:0.00126294485996636\n",
      "train loss:0.0016049193207350238\n",
      "train loss:0.003945124156057193\n",
      "train loss:0.000437711705099195\n",
      "train loss:0.0019165751466245148\n",
      "train loss:3.697259664493595e-05\n",
      "train loss:0.0025718467518092113\n",
      "train loss:0.00034848220436596794\n",
      "train loss:0.0004330704908911353\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9904\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcdZ3v8fe3qvcl3eklCwlKwBgJLiwZRgdx8DoIYRyJ83gdcBmvM2NkBK/eGXOBZ0bFWR7x5ur1YVQyjJNRRxQXEBiNgCLqzKMICYQtiAmISS9JOp30vlbV9/5xTieVSlV3dadPVafq83qe85xzfmf71unq862z/H7H3B0RESlfsWIHICIixaVEICJS5pQIRETKnBKBiEiZUyIQESlzSgQiImUuskRgZlvN7KCZPZ1jupnZLWa2x8yeNLPzo4pFRERyi/KM4MvA5dNMXw+sDruNwK0RxiIiIjlElgjc/WfA4WlmuRL4qgceBprNbHlU8YiISHYVRdz2CmBf2nhHWNadOaOZbSQ4a6C+vv6CV7ziFQUJUOZP38gk+wfGmEymqIzHWLaohua6yoJtu7NvlFRaLfqYGSuaawsSw2y2n3InmcrSheUAZkbMgr7BccNmhllYRjBcdWgXMU+cEFfKKphsP4cgLCfs4VNj4XC2smPlmWWeMR2WDO7KuW96GtdixtHPFQ5iRjhsx6aH63UHdydF0A/GIYUfnebhvnSHgdFJsrWfYEB99dwOgRbu3+NizVYGLBnZTQXJE9aRIM6ButUw9ZnS93lYxtRnCsuaaitpqa+aU8w7duw45O7t2aYVMxFYlrKs7V24+23AbQDr1q3z7du3RxlXadm8GoYPnlhevwQ27S5ICHc/3smNdz1F2+Sxf4bKyjh/+8evYsN5K+a83lTKGZ5IMDyeZGh8ksGxBEPjCYbGEgyG/aHxBLf97AWWjp94IKyvrWDTFWfTUF1JQ00FDdUVNIb9hpoK6qsqiMeyfU2PcXcmk87oRJLRySQjEwlGJ5Np40ku+PaFtNF/wrI93sQ1y+6gb2SC/tEE/aMTTCZzN/lSYVMHh3DbYZfKMm+MFLWMU8ME22v+Muc6zxj7+2k/31wYKdoZYJkdZpkd5l+qPjvN9j/F1KHgaAKZ9faCrsKgqiJGVTxGVUWc6ooYVRUxvjX4p7Rb9v3/weVfmdW2Ug6JlJNKeVo/FZanSKWCfjIFyVSKZMrZyTtyru+C+OeIxYyKmBEzIz41nFZWEQ/7MWPDeSt492tfOss9FDCz3+aaVsxE0AGcnja+EugqUiyRuvvxTjbf/xxdfaOc1lzLpsvWnNQBcFayJYHpyvPg7ownUoyEB7vRieRxB8KxyWMHwdGJJBsevIRn4/0QP349PXc38Ve/vpfE1C/e5LFfvtl+ESeSKYYnkkcP8ENZDu7ZPFr9l7TXZDkQpJr4nTunvzVVVxU/LjFMJjM+92Ty6C/1XF7Msm2AduunpjLG2UtrWVI1SXtVjJaKcVri4zTHx1gUG6XBxqj3UWp9mKrEMEyOkBofJjUxgk+O4BMjMDmCTYxgiVFscoRYYpRYaiKvffNk+8eZrG5hoqaFRHULiZoWErWtJKtbSNa2kqprJVXbite1Eo9XEidB9WgP1SPdVI4eoGq4m4rhbiqHuokPdRMb2k9sqBtL5fe3+U3TNaQWn0Ui7Cabz2Sy+UzGF60iUVEfHGzdSSSDfkXcwgN9LO2gH/Qr4jmudN+Ue/9/+5rfyyvOE7jD+AAMHYShAzC4/9jw0EEYShsfzr2aHfYeqGqE6kaoboDqReFwZheWL22cW7wzKGYiuBe4zszuAH4X6Hf3Ey4LnerGPnUmG8Z72QBQA4wB98DYfa3U3PgCABOJFP2jk2E3cXS4b2TyWPnIJEPjCSriRnUMmmyYZgZoTg2wyPtpTPXTmOyjPtFPXeIIdZN91EweYfE0sSX/rp3JWA2TsRomYjWMWzVj1DBuVYx4DaNexXDYDaWqGExWMZisZCBZyYhXM0o1o1Qx6tWMUM0Y4XJUMUo141QCxl9McyB89LeHiYe/hIIuRjzGsTKDqliKurhTUemsaopTX11NQ1Ul9TUVNFZXUF8dHKzrqyuO6zdUx6mvrqDy07m3//C1axgenWB0fIzhsQlGxycYHRtnbGKSsfFxxsYnGZuYYGxigomJCWork9TXJ6mNJ6mLJamNJaiNJam2BNWWoMYmqSJBFUG/0ifh17n/Brfv3wCJ0Ty+SUBVA1TVE6+sJV5ZD5W1UF0HDS1QWRd0VXVB+dT0qjr4/l/nXOWiFa+AkV4Yfh56fwmjR3Jvv3oRjA9ywu/2ilpYdFrQnXHRseGp7rZLcq7SXnM18UO7iXc9SvWzdx2/7oZl0PoyaHtZ0G85E+JVkBiH5DgkJjL645CcyOiPT79Pv37V9NPTeSrYP1MH+2x/t1glNCyFxqXQ/BJYuQ52fDn3Oi98f7BP07u+fUGSGR8M+ulJ9fV/BctelX/MeYosEZjZN4BLgDYz6wA+AVQCuPsWYBtwBbAHGAHeF1UsxVQz3puz/HWfepD+0UkmJ8ZpZpBWG6TFBmhlgBYbpMUGaWWAtfEh2mKDtNoAi3yART5IPOsFARjwWg77Irpp5LA38gfxrLMBcNvEZdQyTi0TNMbGqY9NUh8bp86GaKWXGsapYZxqH6cqNUacZPB4QZ6PGLjFgoPRND9O/zP+weCLnkhCKgmeDMZTYX9OFwvyt+xfL5j/lcarIF4NFWF/Ohe+P/y115D9F2B1Y5gAGiA2x2c7pkkEXHX78ePJBIweDpPDIRg5FPZ7YeQw1DaHB/gVxw70Nc0cvZA/W1dsPjY8OQqHfwO9u6F3D/Q+H/R33RvElK9YJVRUB3+Hihn2/0Dn7OKtbYbTLwwO9lNdY9pw7eIT98V0ieDNM1yacw8S2lRSqD7Fzgjc/eoZpjtwbVTbL5ZUyvn1wUF++cJhfvmbXr44zbz3+odorOynJjaUdbpjUNeC1bVCXRvUnxn229L6LVDXhte1MlndQswqWZRIUZNI0ZZIwT/lfhDrT27cSm1lnJrKGJbPP3JiAiZHwm4UJoaDfo4ymyr7xedzr3P1pWBxiFVALOxbLGM8HgxbbG4HnB9+PPe0P7rl2LamtnPcdiuCA/DUtPQD/NF+2kEnXnVijDc15d7+TAeCQotXQMOSoJsv9Uty36dKV1kLS9cGXaaRw0GS8OTx+7qi+vi/RbzqxIQ53f6/5j9n/3kKyQwqa4KuIet93nlRzEtDJSGRTPFs9yA7f/08XXueYKJ7Fysm9/Iy6+Ty+PS3PNpf/trggF7XCvWtJxzkrXZxcPDJgwFVYccMP4KmzPrpg4qqoKttnt1y0yWCt/7T7NY1F9MlggveG/32iy3fA3FU5uOhhLqWoDsVFXv/50GJYDbcmejfz4vPPsb+53cyuf9ZGgdfYBX7eI8NHJ0tUV1LqnU1VcsuhSfvyL2+t2+NPuZT4EtY8or9NyjQ02ELlvb/jJQI8nTo+cepuv1KFqX6eTnwcmCIenrrVzHSfikDL30Vi05/JbSvoWLRymOnp9MlgkJYCF/CYv8jFnv7C+FvUM60/2ekRJCnvU88xPmpfu5bupGWl7+Os85ZR+vS02mY6Zp1sQ9CC0Gx/xGLvX2RBU6JIE/Jvg6SblzyZ/9ATXWeF+FBByERWfDUDHWe4oNd9FjL7JKAiMgpQIkgT7Wj+zkcj+7xLRGRYlEiyFPTxAEGq5cWOwwRkXmnRJAPd1pShxirUyvZIlJ6lAjyMDHQQw0T+KICNRQnIlJASgR5OLI/aBwu3nz6DHOKiJx6lAjyMHjgRQDq2l5S3EBERCKgRJCHsd69ACxavqrIkYiIzD8lgjykjnQw7pUsWbKy2KGIiMw7JYI8xIe62E8Liwr0jl0RkUJSIshDzUgXhyva82uzX0TkFKNEkIdFEwcZqFpW7DBERCKhRDCTVJLFqV7GVZlMREqUEsEMUgPdVJAi1XhasUMREYmEEsEMBg6+CEDFYlUmE5HSpEQwg4H9vwGgpu2lRY5ERCQaSgQzGDu0D4CmZWcUNxARkYgoEcwg1b+PQa9lSXsZvVpSRMqKEsEMYoNddHsLbQ16M5mIlCYlghnUjnRzON5OPKbKZCJSmpQIZrBo4gAD1apMJiKlS4lgOolxmlJ9ejOZiJQ0JYLpDHQCqDKZiJQ0JYJpjPS8CEBFs5qfFpHSpUQwjcEDvwWgpl2VyUSkdCkRTGN06s1kS84obiAiIhFSIphG8sg+er2RZa2Lix2KiEhklAimER/spNtbWbJIlclEpHQpEUyjZnQ/PbF2airjxQ5FRCQySgTTWDRxgMHqpcUOQ0QkUpEmAjO73MyeM7M9ZnZDlulNZvYfZvaEmT1jZu+LMp5ZGR+kLjWsymQiUvIiSwRmFge+AKwH1gJXm9najNmuBXa5+2uAS4DPmFlVVDHNSn9YmaxBlclEpLRFeUZwIbDH3V9w9wngDuDKjHkcaDQzAxqAw0AiwpjyNnEkqEMQ15vJRKTERZkIVgD70sY7wrJ0nwfOBrqAp4APu3sqc0VmttHMtpvZ9p6enqjiPc5QWJmsVm8mE5ESF2UiyNZus2eMXwbsBE4DzgU+b2aLTljI/TZ3X+fu69rb2+c/0ixGe/eSdGPREp0RiEhpizIRdADpR9GVBL/8070PuMsDe4DfAK+IMKa8JY90cJDFLFvcUOxQREQiFWUieBRYbWarwhvAVwH3ZsyzF3gTgJktBdYAL0QYU97ig510eSvLmmqKHYqISKQqolqxuyfM7DrgfiAObHX3Z8zsmnD6FuDvgS+b2VMEl5Kud/dDUcU0GzUj3Ry0lZxfHdkuEhFZECI9yrn7NmBbRtmWtOEu4M1RxjAn7jROHGCw6gKCB5pEREqXahZnM3KYKp9grE6vqBSR0qdEkE1/8NRrsjHzaVcRkdKjRJBFqr8DgHizHh0VkdKnRJDFcM9UZbKXFDkSEZHo6ZGYLMYO7aXKK2hqU4NzIlL6dEaQReJIB/u9hWXNdcUORUQkckoEWcQHO+jyNlUmE5GyoESQRfXIfvbTSlu9XlEpIqVPiSBTKknDRA8DVUuIxVSZTERKnxJBpqEDxEkyqspkIlImlAgyhXUIUo0rixyIiEhhKBFk8DARxJqVCESkPCgRZBjv3QtAbaveTCYi5UEVyjKMHtpLwmtY3NpW7FBERApCiSBD8sg+eryV5c21xQ5FRKQgdGkoQ2ywk25vZdkiVSYTkfKgRJChemQ/Xd7KkkWqTCYi5UGJIF1inPrJXvorl1BdES92NCIiBaFEkG6gE4DROrU6KiLlQ4kgXX+QCJINpxU5EBGRwlEiSBeeEcQWqzKZiJQPJYI0k0eCdxXXtujNZCJSPlSPIM3Yob0MeCNtLc3FDkVEpGB0RpAmeWRfUIdAL6QRkTKiRJDGwspky5UIRKSMKBGkqRnppstbWKpaxSJSRpQIpowPUp0YpDfeTmNNZbGjEREpGCWCKWEdgpFaVSYTkfKiRDBlYOrNZCuKHIiISGEpEUwJzwhiTapMJiLlRfUIQqn+DnCjrlWJQETKixJBaLx3L30spn1xQ7FDEREpKF0aCiWO7KPbW1iuR0dFpMwoEYRiA510qVaxiJShSBOBmV1uZs+Z2R4zuyHHPJeY2U4ze8bMfhplPDm5Uz2yX81LiEhZiuwegZnFgS8AlwIdwKNmdq+770qbpxn4InC5u+81syVRxTOtkcNUpMY4YG201FUVJQQRkWKJ8ozgQmCPu7/g7hPAHcCVGfO8E7jL3fcCuPvBCOPJLaxDMFK7jFjMihKCiEixRJkIVgD70sY7wrJ0LwcWm9lPzGyHmf1pthWZ2UYz225m23t6euY/Ur2ZTETKWJSJINtPa88YrwAuAP4QuAz4mJm9/ISF3G9z93Xuvq69vX3+I516M1nz6fO/bhGRBS6vRGBmd5rZH5rZbBJHB5B+ZF0JdGWZ5z53H3b3Q8DPgNfMYhvzwvs7mPAK6hcvK/SmRUSKLt8D+60E1/N3m9nNZvaKPJZ5FFhtZqvMrAq4Crg3Y557gIvNrMLM6oDfBZ7NM6Z5M3l4L93ewrLmukJvWkSk6PJ6asjdfwT8yMyagKuBH5rZPuBfgK+5+2SWZRJmdh1wPxAHtrr7M2Z2TTh9i7s/a2b3AU8CKeBL7v70vHyyWUgc6aAbPToqIuUp78dHzawVeDfwHuBx4Hbg9cB7gUuyLePu24BtGWVbMsY3A5tnE/R8iw120uWreKkSgYiUoXzvEdwF/CdQB/yRu7/V3b/p7h8CTu3GeVJJqkYO0OWtejOZiJSlfM8IPu/uP842wd3XzWM8hTd0gJgn6PZWljQqEYhI+cn3ZvHZYS1gAMxssZl9MKKYCiusQzBUvYyqCjW9JCLlJ98j3/vdvW9qxN2PAO+PJqQCO/pmMlUmE5HylG8iiJnZ0QpiYTtCpdEoT3hGYHozmYiUqXzvEdwPfMvMthDUDr4GuC+yqAqpv4Nhamha3FbsSEREiiLfRHA98AHgLwmajngA+FJUQRVSsm8fXalWljXXFjsUEZGiyLdCWYqgdvGt0YZTeIkjHUGtYj06KiJlKq9EYGargU8Ba4GjR0x3PzOiuArGBjvp8nM4XZXJRKRM5Xuz+N8IzgYSwBuBrwL/HlVQBZMYp2q0hy5vU/MSIlK28k0Ete7+IGDu/lt3vwn4b9GFVSADQWOo3ejSkIiUr3xvFo+FTVDvDhuS6wSK81rJ+RS+h6Cvcgn11ZG9tVNEZEHL94zgIwTtDP1PghfJvJugsblTW1iHIFGvymQiUr5m/BkcVh57h7tvAoaA90UeVaGEtYpjzapMJiLla8YzAndPAhek1ywuGf0d9NFIS3PzzPOKiJSofC+MPw7cY2bfBoanCt39rkiiKpBUfwedqRaW64khESlj+SaCFqCX458UcuCUTgTJIx3BewiUCESkjOVbs7h07guksYFOuvxCVSYTkbKWb83ifyM4AziOu//ZvEdUKONDVEz00+2trFMdAhEpY/leGvpe2nAN8Daga/7DKaCwDkGXt7K8SQ3OiUj5yvfS0J3p42b2DeBHkURUKP3Bo6OHYm0srqsscjAiIsUz13czrgZeMp+BFFx4RjDZsIJSfDJWRCRf+d4jGOT4ewT7Cd5RcOrq7yCFUdGkWsUiUt7yvTTUGHUgBdffSa8tpr25odiRiIgUVV6XhszsbWbWlDbebGYbogsrej4QVCZT89MiUu7yvUfwCXfvnxpx9z7gE9GEVBipvjAR6NFRESlz+SaCbPOduu02u2MDHXohjYgI+SeC7Wb2WTM7y8zONLP/B+yIMrBIjR4hlhij21tZqjMCESlz+SaCDwETwDeBbwGjwLVRBRW5sA5BUJlMiUBEylu+Tw0NAzdEHEvhhHUI9tNCe2N1kYMRESmufJ8a+qGZNaeNLzaz+6MLK2LhGcF43WlUxudap05EpDTkexRsC58UAsDdj3Aqv7O4v4MEFVQ1LS12JCIiRZdvIkiZ2dEmJczsDLK0RnrKGOikx1pZ2lRX7EhERIou30dA/wb4LzP7aTj+BmBjNCEVQH8nna7KZCIikOcZgbvfB6wDniN4cuivCZ4cOiWl+jvYm2xVIhARIf+bxX8BPEiQAP4a+HfgpjyWu9zMnjOzPWaW86kjM/sdM0ua2dvzC/skpJLYYBfdrlrFIiKQ/z2CDwO/A/zW3d8InAf0TLeAmcWBLwDrgbXA1Wa2Nsd8nwYK8xTS0EEslaDbdUYgIgL5J4Ixdx8DMLNqd/8VsGaGZS4E9rj7C+4+AdwBXJllvg8BdwIH84zl5KS9mUxnBCIi+SeCjrAewd3AD83sHmZ+VeUKYF/6OsKyo8xsBcFrL7dMtyIz22hm281se0/PtCciMztaq1jtDImIQP41i98WDt5kZg8BTcB9MyyW7bVfmY+cfg643t2T070lzN1vA24DWLdu3ck9thomgsHqJdRVnbrt5omIzJdZHwnd/aczzwUEZwCnp42v5MSziHXAHWESaAOuMLOEu98927jyNtDJmNXQ0NgW2SZERE4lUf4kfhRYbWargE7gKuCd6TO4+6qpYTP7MvC9SJMAQH8HPbE2ljbXRroZEZFTRWSJwN0TZnYdwdNAcWCruz9jZteE06e9LxCZgU46U60s141iEREg4pfLuPs2YFtGWdYE4O7/I8pYjm6nv4PfJs5mqW4Ui4gA+T81VBoSEzB0kK6U3kMgIjKlvBLBYBeG04XqEIiITCmvRNCfVplMZwQiIkC5JYKwVnG3ahWLiBxVXomgP6jo3Btvp7mussjBiIgsDGWWCDoZji2iuamJ6Woyi4iUk/JKBAOd9MTadFlIRCRNeSWC/k46daNYROQ4ZZUIvH8fL04uViIQEUlT+s1vbl4Nw8GrDgx4V+wB+OUD8PQS2LS7uLGJiCwApX9GMJzjfTe5ykVEykzpJwIREZmWEoGISJlTIhARKXNKBCIiZa70E0H9ktmVi4iUmdJ/fDTtEdFLP/tTzmpvYMt7LihiQCIiC0vpnxGk2T8wpspkIiIZyiIR3P14J6/71IMMjiW467EO7n68s9ghiYgsGCV/aejuxzu58a6nGJ1MAjAwluDGu54CYMN5K4oZmojIglDyZwSb73/uaBKYMjqZZPP9zxUpIhGRhaXkE0FX3+isykVEyk3JJ4LTmmtnVS4iUm5KPhFsumwNtZXx48pqK+NsumxNkSISEVlYSv5m8dQN4c33P0dX3yinNdey6bI1ulEsIhIq+UQAQTLQgV9EJLuSvzQkIiLTUyIQESlzSgQiImVOiUBEpMwpEYiIlDklAhGRMqdEICJS5pQIRETKXKSJwMwuN7PnzGyPmd2QZfq7zOzJsPu5mb0mynhEROREkSUCM4sDXwDWA2uBq81sbcZsvwF+391fDfw9cFtU8YiISHZRnhFcCOxx9xfcfQK4A7gyfQZ3/7m7HwlHHwZWRhiPiIhkEWUiWAHsSxvvCMty+XPgB9kmmNlGM9tuZtt7enrmMUQREYkyEViWMs86o9kbCRLB9dmmu/tt7r7O3de1t7fPY4giIhJl66MdwOlp4yuBrsyZzOzVwJeA9e7eG2E8IiKSRZRnBI8Cq81slZlVAVcB96bPYGYvAe4C3uPuv44wFhERySGyMwJ3T5jZdcD9QBzY6u7PmNk14fQtwMeBVuCLZgaQcPd1UcUkIiInMvesl+0XrHXr1vn27duLHYaIyCnFzHbk+qFdFm8oExGZnJyko6ODsbGxYocSqZqaGlauXEllZWXeyygRiEhZ6OjooLGxkTPOOIPwUnTJcXd6e3vp6Ohg1apVeS+ntoZEpCyMjY3R2tpaskkAwMxobW2d9VmPEoGIlI1STgJT5vIZlQhERMqcEoGISBZ3P97JRTf/mFU3fJ+Lbv4xdz/eeVLr6+vr44tf/OKsl7viiivo6+s7qW3PRIlARCTD3Y93cuNdT9HZN4oDnX2j3HjXUyeVDHIlgmQyOe1y27Zto7m5ec7bzYeeGhKRsvPJ/3iGXV0DOac/vrePiWTquLLRyST/+ztP8o1H9mZdZu1pi/jEH52Tc5033HADzz//POeeey6VlZU0NDSwfPlydu7cya5du9iwYQP79u1jbGyMD3/4w2zcuBGAM844g+3btzM0NMT69et5/etfz89//nNWrFjBPffcQ21t7Rz2wPF0RiAikiEzCcxUno+bb76Zs846i507d7J582YeeeQR/vEf/5Fdu3YBsHXrVnbs2MH27du55ZZb6O09sem13bt3c+211/LMM8/Q3NzMnXfeOed40umMQETKznS/3AEuuvnHdPaNnlC+ormWb37gdfMSw4UXXnjcs/633HIL3/3udwHYt28fu3fvprW19bhlVq1axbnnngvABRdcwIsvvjgvseiMQEQkw6bL1lBbGT+urLYyzqbL1szbNurr648O/+QnP+FHP/oRv/jFL3jiiSc477zzstYFqK6uPjocj8dJJBLzEovOCEREMmw4L3iH1ub7n6Orb5TTmmvZdNmao+Vz0djYyODgYNZp/f39LF68mLq6On71q1/x8MMPz3k7c6FEICKSxYbzVpzUgT9Ta2srF110Ea985Supra1l6dKlR6ddfvnlbNmyhVe/+tWsWbOG1772tfO23Xyo9VERKQvPPvssZ599drHDKIhsn3W61kd1j0BEpMwpEYiIlDklAhGRMqdEICJS5pQIRETKnBKBiEiZUz0CEZFMm1fD8METy+uXwKbdc1plX18fX//61/ngBz8462U/97nPsXHjRurq6ua07ZnojEBEJFO2JDBdeR7m+j4CCBLByMjInLc9E50RiEj5+cENsP+puS37b3+YvXzZq2D9zTkXS2+G+tJLL2XJkiV861vfYnx8nLe97W188pOfZHh4mHe84x10dHSQTCb52Mc+xoEDB+jq6uKNb3wjbW1tPPTQQ3OLexpKBCIiBXDzzTfz9NNPs3PnTh544AG+853v8Mgjj+DuvPWtb+VnP/sZPT09nHbaaXz/+98HgjaImpqa+OxnP8tDDz1EW1tbJLEpEYhI+ZnmlzsANzXlnva+75/05h944AEeeOABzjvvPACGhobYvXs3F198MR/96Ee5/vrrectb3sLFF1980tvKhxKBiEiBuTs33ngjH/jAB06YtmPHDrZt28aNN97Im9/8Zj7+8Y9HHo9uFouIZKpfMrvyPKQ3Q33ZZZexdetWhoaGAOjs7OTgwYN0dXVRV1fHu9/9bj760Y/y2GOPnbBsFHRGICKSaY6PiE4nvRnq9evX8853vpPXvS5421lDQwNf+9rX2LNnD5s2bSIWi1FZWcmtt94KwMaNG1m/fj3Lly+P5GaxmqEWkbKgZqjVDLWIiOSgRCAiUuaUCESkbJxql8LnYi6fUYlARMpCTU0Nvb29JZ0M3J3e3l5qampmtZyeGhKRsrBy5Uo6Ojro6ekpdiiRqqmpYeXKlbNaRolARMpCZWUlq1atKnYYC1Kkl4bM7HIze87M9pjZDVmmm5ndEk5/0szOjzIeERE5UWSJwMziwBeA9cBa4GozW5sx23pgddhtBG6NKh4REckuyjOCC4E97v6Cu08Ad+VWvL4AAAbFSURBVABXZsxzJfBVDzwMNJvZ8ghjEhGRDFHeI1gB7Esb7wB+N495VgDd6TOZ2UaCMwaAITN7bo4xtQGH5rhsISz0+GDhx6j4To7iOzkLOb6X5poQZSKwLGWZz23lMw/ufhtw20kHZLY9VxXrhWChxwcLP0bFd3IU38lZ6PHlEuWloQ7g9LTxlUDXHOYREZEIRZkIHgVWm9kqM6sCrgLuzZjnXuBPw6eHXgv0u3t35opERCQ6kV0acveEmV0H3A/Ega3u/oyZXRNO3wJsA64A9gAjwPuiiid00peXIrbQ44OFH6PiOzmK7+Qs9PiyOuWaoRYRkfmltoZERMqcEoGISJkryUSwkJu2MLPTzewhM3vWzJ4xsw9nmecSM+s3s51hF/3bq4/f/otm9lS47RNeB1fk/bcmbb/sNLMBM/tIxjwF339mttXMDprZ02llLWb2QzPbHfYX51h22u9rhPFtNrNfhX/D75pZc45lp/0+RBjfTWbWmfZ3vCLHssXaf99Mi+1FM9uZY9nI999Jc/eS6ghuTD8PnAlUAU8AazPmuQL4AUE9htcCvyxgfMuB88PhRuDXWeK7BPheEffhi0DbNNOLtv+y/K33Ay8t9v4D3gCcDzydVvZ/gBvC4RuAT+f4DNN+XyOM781ARTj86Wzx5fN9iDC+m4CP5vEdKMr+y5j+GeDjxdp/J9uV4hnBgm7awt273f2xcHgQeJagNvWpZKE0DfIm4Hl3/20Rtn0cd/8ZcDij+ErgK+HwV4ANWRbN5/saSXzu/oC7J8LRhwnq8RRFjv2Xj6LtvylmZsA7gG/M93YLpRQTQa5mK2Y7T+TM7AzgPOCXWSa/zsyeMLMfmNk5BQ0sqN39gJntCJv3yLQg9h9B3ZRc/3zF3H9TlnpYLybsL8kyz0LZl39GcJaXzUzfhyhdF1662prj0tpC2H8XAwfcfXeO6cXcf3kpxUQwb01bRMnMGoA7gY+4+0DG5McILne8Bvgn4O5CxgZc5O7nE7QOe62ZvSFj+kLYf1XAW4FvZ5lc7P03GwthX/4NkABuzzHLTN+HqNwKnAWcS9D+2GeyzFP0/QdczfRnA8Xaf3krxUSw4Ju2MLNKgiRwu7vflTnd3QfcfSgc3gZUmllboeJz966wfxD4LsHpd7qF0DTIeuAxdz+QOaHY+y/NgalLZmH/YJZ5iv1dfC/wFuBdHl7QzpTH9yES7n7A3ZPungL+Jcd2i73/KoA/Br6Za55i7b/ZKMVEsKCbtgivJ/4r8Ky7fzbHPMvC+TCzCwn+Tr0Fiq/ezBqnhgluKD6dMdtCaBok56+wYu6/DPcC7w2H3wvck2WefL6vkTCzy4Hrgbe6+0iOefL5PkQVX/p9p7fl2G7R9l/oD4BfuXtHtonF3H+zUuy71VF0BE+1/JrgaYK/CcuuAa4Jh43gpTnPA08B6woY2+sJTl2fBHaG3RUZ8V0HPEPwBMTDwO8VML4zw+0+EcawoPZfuP06ggN7U1pZUfcfQVLqBiYJfqX+OdAKPAjsDvst4bynAdum+74WKL49BNfXp76HWzLjy/V9KFB8/x5+v54kOLgvX0j7Lyz/8tT3Lm3egu+/k+3UxISISJkrxUtDIiIyC0oEIiJlTolARKTMKRGIiJQ5JQIRkTKnRCASsbA11O8VOw6RXJQIRETKnBKBSMjM3m1mj4Ttxv+zmcXNbMjMPmNmj5nZg2bWHs57rpk9nNaW/+Kw/GVm9qOwwbvHzOyscPUNZvadsP3/29NqPt9sZrvC9fzfIn10KXNKBCKAmZ0N/AlBA2HnAkngXUA9QZtG5wM/BT4RLvJV4Hp3fzVB7dep8tuBL3jQ4N3vEdRGhaCV2Y8Aawlqm15kZi0ETSecE67nH6L9lCLZKRGIBN4EXAA8Gr5p6k0EB+wUxxoU+xrwejNrAprd/adh+VeAN4Rtyqxw9+8CuPuYH2vD5xF37/CgAbWdwBnAADAGfMnM/hjI2t6PSNSUCEQCBnzF3c8NuzXuflOW+aZrkyVbk8hTxtOGkwRvBksQtER5J8FLa+6bZcwi80KJQCTwIPB2M1sCR983/FKC/5G3h/O8E/gvd+8HjpjZxWH5e4CfevBeiQ4z2xCuo9rM6nJtMHwnRZMHTWV/hKDdfZGCqyh2ACILgbvvMrO/JXiTVIyglclrgWHgHDPbAfQT3EeAoFnpLeGB/gXgfWH5e4B/NrO/C9fx36fZbCNwj5nVEJxN/K95/lgieVHroyLTMLMhd28odhwiUdKlIRGRMqczAhGRMqczAhGRMqdEICJS5pQIRETKnBKBiEiZUyIQESlz/x8CW5WoAtzPyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
